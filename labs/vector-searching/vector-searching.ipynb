{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# APIM ‚ù§Ô∏è OpenAI\n",
    "\n",
    "## Vector Searching lab\n",
    "![flow](../../images/vector-searching.gif)\n",
    "\n",
    "Playground to try the [Retrieval Augmented Generation (RAG) pattern](https://learn.microsoft.com/azure/search/retrieval-augmented-generation-overview) with Azure AI Search, Azure OpenAI embeddings and Azure OpenAI completions. All the endpoints are managed via APIM.\n",
    "\n",
    "> ‚ÑπÔ∏è Reuses the [AI Orchestration with Azure AI Search](https://github.com/Azure/intro-to-intelligent-apps/blob/main/labs/03-orchestration/04-ACS/acs-lc-python.ipynb) notebook from the [intro to intelligent Apps workshop](https://github.com/Azure/intro-to-intelligent-apps/).\n",
    "\n",
    "### Result\n",
    "![result](result.png)\n",
    "\n",
    "### TOC\n",
    "- [0Ô∏è‚É£ Initialize notebook variables](#0)\n",
    "- [1Ô∏è‚É£ Create the Azure Resource Group](#1)\n",
    "- [2Ô∏è‚É£ Create deployment using ü¶æ Bicep](#2)\n",
    "- [3Ô∏è‚É£ Get the deployment outputs](#3)\n",
    "- [4Ô∏è‚É£ Install packages](#4)\n",
    "- [5Ô∏è‚É£ Create an Azure AI Search index and load movie data](#5)\n",
    "- [üß™ Vector store searching using Azure AI Search](#search)\n",
    "- [üß™ Bringing it All Together with Retrieval Augmented Generation (RAG) + Langchain (LC)](#langchain)\n",
    "- [üóëÔ∏è Clean up resources](#clean)\n",
    "\n",
    "### Prerequisites\n",
    "- [Python 3.8 or later version](https://www.python.org/) installed (recommended to use a separate python environment for this lab)\n",
    "- [VS Code](https://code.visualstudio.com/) installed with the [Jupyter notebook extension](https://marketplace.visualstudio.com/items?itemName=ms-toolsai.jupyter) enabled\n",
    "- [Azure CLI](https://learn.microsoft.com/cli/azure/install-azure-cli) installed\n",
    "- [An Azure Subscription](https://azure.microsoft.com/free/) with Contributor permissions\n",
    "- [Access granted to Azure OpenAI](https://aka.ms/oai/access) or just enable the mock service\n",
    "- [Sign in to Azure with Azure CLI](https://learn.microsoft.com/cli/azure/authenticate-azure-cli-interactively)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='0'></a>\n",
    "### 0Ô∏è‚É£ Initialize notebook variables\n",
    "\n",
    "- Resources will be suffixed by a unique string based on your subscription id.\n",
    "- Adjust the location parameters according your preferences and on the [product availability by Azure region.](https://azure.microsoft.com/explore/global-infrastructure/products-by-region/?cdn=disable&products=cognitive-services,api-management) \n",
    "- Adjust the OpenAI model and version according the [availability by region.](https://learn.microsoft.com/azure/ai-services/openai/concepts/models) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import datetime\n",
    "import requests\n",
    "\n",
    "deployment_name = os.path.basename(os.path.dirname(globals()['__vsc_ipynb_file__']))\n",
    "resource_group_name = f\"lab-{deployment_name}\" # change the name to match your naming style\n",
    "resource_group_location = \"westeurope\"\n",
    "apim_resource_name = \"apim\"\n",
    "apim_resource_location = \"westeurope\"\n",
    "apim_resource_sku = \"Basicv2\"\n",
    "openai_resources = [ {\"name\": \"openai1\", \"location\": \"uksouth\"} ] # list of OpenAI resources to deploy.\n",
    "openai_resources_sku = \"S0\"\n",
    "openai_model_name = \"gpt-35-turbo\"\n",
    "openai_model_version = \"0613\"\n",
    "openai_deployment_name = \"gpt-35-turbo\"\n",
    "openai_api_version = \"2024-02-01\"\n",
    "openai_specification_url='https://raw.githubusercontent.com/Azure/azure-rest-api-specs/main/specification/cognitiveservices/data-plane/AzureOpenAI/inference/stable/' + openai_api_version + '/inference.json'\n",
    "openai_backend_pool = \"openai-backend-pool\"\n",
    "mock_backend_pool = \"mock-backend-pool\"\n",
    "mock_webapps = [ ] # mocking is not supported in this lab\n",
    "\n",
    "# variables specific for the vector search lab\n",
    "log_analytics_name = \"workspace\"\n",
    "app_insights_name = 'insights'\n",
    "openai_embeddings_deployment_name = \"text-embedding-ada-002\"\n",
    "openai_embeddings_model_name = \"text-embedding-ada-002\"\n",
    "openai_embeddings_model_version = \"2\"\n",
    "searchservice_resource_name = \"search\"\n",
    "searchservice_sku = \"standard\"\n",
    "searchservice_api_path = \"searchservice\"\n",
    "searchindex_api_path = \"searchindex\"\n",
    "searchindex_name = \"movies\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='1'></a>\n",
    "### 1Ô∏è‚É£ Create the Azure Resource Group\n",
    "All resources deployed in this lab will be created in the specified resource group. Skip this step if you want to use an existing resource group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resource_group_stdout = ! az group create --name {resource_group_name} --location {resource_group_location}\n",
    "if resource_group_stdout.n.startswith(\"ERROR\"):\n",
    "    print(resource_group_stdout)\n",
    "else:\n",
    "    print(\"‚úÖ Azure Resource Group \", resource_group_name, \" created ‚åö \", datetime.datetime.now().time())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='2'></a>\n",
    "### 2Ô∏è‚É£ Create deployment using ü¶æ Bicep\n",
    "\n",
    "This lab uses [Bicep](https://learn.microsoft.com/azure/azure-resource-manager/bicep/overview?tabs=bicep) to declarative define all the resources that will be deployed. Change the parameters or the [main.bicep](main.bicep) directly to try different configurations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if len(openai_resources) > 0:\n",
    "    backend_id = openai_backend_pool if len(openai_resources) > 1 else openai_resources[0].get(\"name\")\n",
    "elif len(mock_webapps) > 0:\n",
    "    backend_id = mock_backend_pool if len(mock_webapps) > 1 else mock_webapps[0].get(\"name\")\n",
    "\n",
    "with open(\"policy.xml\", 'r') as policy_xml_file:\n",
    "    policy_template_xml = policy_xml_file.read()\n",
    "    policy_xml = policy_template_xml.replace(\"{backend-id}\", backend_id)\n",
    "    policy_xml_file.close()\n",
    "open(\"policy.xml\", 'w').write(policy_xml)\n",
    "\n",
    "bicep_parameters = {\n",
    "  \"$schema\": \"https://schema.management.azure.com/schemas/2019-04-01/deploymentParameters.json#\",\n",
    "  \"contentVersion\": \"1.0.0.0\",\n",
    "  \"parameters\": {\n",
    "    \"mockWebApps\": { \"value\": mock_webapps },\n",
    "    \"mockBackendPoolName\": { \"value\": mock_backend_pool },\n",
    "    \"openAIBackendPoolName\": { \"value\": openai_backend_pool },\n",
    "    \"openAIConfig\": { \"value\": openai_resources },\n",
    "    \"openAIDeploymentName\": { \"value\": openai_deployment_name },\n",
    "    \"openAISku\": { \"value\": openai_resources_sku },\n",
    "    \"openAIModelName\": { \"value\": openai_model_name },\n",
    "    \"openAIModelVersion\": { \"value\": openai_model_version },\n",
    "    \"openAIAPISpecURL\": { \"value\": openai_specification_url },\n",
    "    \"apimResourceName\": { \"value\": apim_resource_name},\n",
    "    \"apimResourceLocation\": { \"value\": apim_resource_location},\n",
    "    \"apimSku\": { \"value\": apim_resource_sku},\n",
    "    \"logAnalyticsName\": { \"value\": log_analytics_name },\n",
    "    \"applicationInsightsName\": { \"value\": app_insights_name },\n",
    "    \"openAIEmbeddingsDeploymentName\": { \"value\": openai_embeddings_deployment_name},\n",
    "    \"openAIEmbeddingsModelName\": { \"value\": openai_embeddings_model_name},\n",
    "    \"openAIEmbeddingsModelVersion\": { \"value\": openai_embeddings_model_version},\n",
    "    \"searchServiceName\": { \"value\": searchservice_resource_name},\n",
    "    \"searchServiceSku\": { \"value\": searchservice_sku},\n",
    "    \"searchServiceAPIPath\": { \"value\": searchservice_api_path},\n",
    "    \"searchIndexAPIPath\": { \"value\": searchindex_api_path}\n",
    "  }\n",
    "}\n",
    "with open('params.json', 'w') as bicep_parameters_file:\n",
    "    bicep_parameters_file.write(json.dumps(bicep_parameters))\n",
    "\n",
    "! az deployment group create --name {deployment_name} --resource-group {resource_group_name} --template-file \"main.bicep\" --parameters \"params.json\"\n",
    "\n",
    "open(\"policy.xml\", 'w').write(policy_template_xml)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='3'></a>\n",
    "### 3Ô∏è‚É£ Get the deployment outputs\n",
    "\n",
    "The APIM gateway URL will be used as the OpenAI and AI Search endpoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deployment_stdout = ! az deployment group show --name {deployment_name} -g {resource_group_name} --query properties.outputs.apimSubscriptionKey.value -o tsv\n",
    "apim_subscription_key = deployment_stdout.n\n",
    "deployment_stdout = ! az deployment group show --name {deployment_name} -g {resource_group_name} --query properties.outputs.apimResourceGatewayURL.value -o tsv\n",
    "apim_resource_gateway_url = deployment_stdout.n\n",
    "print(\"üëâüèª API Gateway URL: \", apim_resource_gateway_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='4'></a>\n",
    "### 4Ô∏è‚É£ Install packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install openai==1.55.3 -q\n",
    "! pip install azure-search-documents==11.5.1 -q\n",
    "! pip install azure-identity==1.17.0 -q\n",
    "! pip install langchain==0.2.16 -q\n",
    "! pip install langchain-openai==0.1.23 -q\n",
    "! pip install langchain-community==0.2.16 -q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='5'></a>\n",
    "### 5Ô∏è‚É£ Create an Azure AI Search index and load movie data\n",
    "Next, we'll step through the process of configuring an Azure AI Search index to store sample [movie data](movies.csv) and then loading the data into the index.\n",
    "\n",
    "> ‚ÑπÔ∏è The following code is really well explained in the [intro to AI workshop](https://github.com/Azure/intro-to-intelligent-apps/blob/main/labs/03-orchestration/03-VectorStore/aisearch.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders.csv_loader import CSVLoader\n",
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.search.documents import SearchClient\n",
    "from azure.search.documents.indexes import SearchIndexClient\n",
    "from azure.search.documents.indexes.models import (VectorSearch, VectorSearchProfile, HnswAlgorithmConfiguration, SemanticPrioritizedFields, SemanticSearch, SemanticField, SemanticConfiguration, SimpleField, SearchableField, SearchField, SearchFieldDataType, SearchIndex)\n",
    "from azure.search.documents.models import (VectorizedQuery)\n",
    "\n",
    "\n",
    "loader = CSVLoader(file_path='./movies.csv', source_column='original_title', encoding='utf-8', csv_args={'delimiter':',', 'fieldnames': ['id', 'original_language', 'original_title', 'popularity', 'release_date', 'vote_average', 'vote_count', 'genre', 'overview', 'revenue', 'runtime', 'tagline']})\n",
    "data = loader.load()\n",
    "\n",
    "# Rather than load all 500 movies into Azure AI search, we will use a\n",
    "# smaller subset of movie data to make things quicker. The more movies you load,\n",
    "# the more time it will take for embeddings to be generated.\n",
    "\n",
    "data = data[1:51]\n",
    "print('Loaded %s movies.' % len(data))\n",
    "\n",
    "\n",
    "azure_openai_embeddings = AzureOpenAIEmbeddings(\n",
    "    azure_endpoint = apim_resource_gateway_url,\n",
    "    openai_api_key = apim_subscription_key,\n",
    "    azure_deployment = openai_embeddings_deployment_name,\n",
    "    openai_api_version = openai_api_version,\n",
    "    model= openai_embeddings_model_name\n",
    ")\n",
    "\n",
    "fields = [\n",
    "    SimpleField(name=\"id\", type=SearchFieldDataType.String, key=True, sortable=True, filterable=True, facetable=True),\n",
    "    SearchableField(name=\"title\", type=SearchFieldDataType.String),\n",
    "    SearchableField(name=\"overview\", type=SearchFieldDataType.String),\n",
    "    SearchableField(name=\"genre\", type=SearchFieldDataType.String),\n",
    "    SearchableField(name=\"tagline\", type=SearchFieldDataType.String),\n",
    "    SearchableField(name=\"release_date\", type=SearchFieldDataType.DateTimeOffset, sortable=True),\n",
    "    SearchableField(name=\"popularity\", type=SearchFieldDataType.Double, sortable=True),\n",
    "    SearchableField(name=\"vote_average\", type=SearchFieldDataType.Double, sortable=True),\n",
    "    SearchableField(name=\"vote_count\", type=SearchFieldDataType.Int32, sortable=True),\n",
    "    SearchableField(name=\"runtime\", type=SearchFieldDataType.Int32, sortable=True),\n",
    "    SearchableField(name=\"revenue\", type=SearchFieldDataType.Int64, sortable=True),\n",
    "    SearchableField(name=\"original_language\", type=SearchFieldDataType.String),\n",
    "    SearchField(name=\"vector\", type=SearchFieldDataType.Collection(SearchFieldDataType.Single), searchable=True, vector_search_dimensions=1536, vector_search_profile_name=\"movies-vector-profile\"),\n",
    "]\n",
    "\n",
    "vector_search = VectorSearch(\n",
    "    profiles=[VectorSearchProfile(name=\"movies-vector-profile\", algorithm_configuration_name=\"movies-vector-config\")],\n",
    "    algorithms=[HnswAlgorithmConfiguration(name=\"movies-vector-config\")],\n",
    ")\n",
    "\n",
    "semantic_config = SemanticConfiguration(\n",
    "    name=\"movies-semantic-config\",\n",
    "    prioritized_fields=SemanticPrioritizedFields(\n",
    "        title_field=SemanticField(field_name=\"title\"),\n",
    "        keywords_fields=[SemanticField(field_name=\"genre\")],\n",
    "        content_fields=[SemanticField(field_name=\"title\"),\n",
    "                        SemanticField(field_name=\"overview\"),\n",
    "                        SemanticField(field_name=\"tagline\"),\n",
    "                        SemanticField(field_name=\"genre\"),\n",
    "                        SemanticField(field_name=\"release_date\"),\n",
    "                        SemanticField(field_name=\"popularity\"),\n",
    "                        SemanticField(field_name=\"vote_average\"),\n",
    "                        SemanticField(field_name=\"vote_count\"),\n",
    "                        SemanticField(field_name=\"runtime\"),\n",
    "                        SemanticField(field_name=\"revenue\"),\n",
    "                        SemanticField(field_name=\"original_language\")],\n",
    "    )\n",
    ")\n",
    "\n",
    "semantic_search = SemanticSearch(configurations=[semantic_config])\n",
    "\n",
    "# Create the search index with the desired vector search and semantic configurations\n",
    "index = SearchIndex(\n",
    "    name=searchindex_name,\n",
    "    fields=fields,\n",
    "    vector_search=vector_search,\n",
    "    semantic_search=semantic_search\n",
    ")\n",
    "\n",
    "index_client = SearchIndexClient(\n",
    "    f\"{apim_resource_gateway_url}/{searchservice_api_path}\",\n",
    "    AzureKeyCredential(apim_subscription_key)\n",
    ")\n",
    "\n",
    "result = index_client.create_or_update_index(index)\n",
    "\n",
    "print(f'Index {result.name} created.')\n",
    "\n",
    "# Loop through all of the movies and create a new item for each one.\n",
    "\n",
    "items = []\n",
    "for movie in data:\n",
    "    content = movie.page_content\n",
    "    fields = movie.page_content.split('\\n')\n",
    "    movieId = (fields[0].split(': ')[1])[:-2]\n",
    "    movieTitle = (fields[2].split(': ')[1])\n",
    "    movieOverview = (fields[8].split(': ')[1])\n",
    "    movieGenre = (fields[7].split(': ')[1])[1:-1]\n",
    "    movieTagline = (fields[11].split(': ')[1])\n",
    "    movieReleaseDate = (fields[4].split(': ')[1])\n",
    "    moviePopularity = (fields[3].split(': ')[1])\n",
    "    movieVoteAverage = (fields[5].split(': ')[1])\n",
    "    movieVoteCount = (fields[6].split(': ')[1])\n",
    "    movieRuntime = (fields[10].split(': ')[1])\n",
    "    movieRevenue = (fields[9].split(': ')[1])\n",
    "    movieOriginalLanguage = (fields[1].split(': ')[1])\n",
    "\n",
    "    items.append(dict([\n",
    "        (\"id\", movieId), \n",
    "        (\"title\", movieTitle),\n",
    "        (\"overview\", movieOverview),\n",
    "        (\"genre\", movieGenre),\n",
    "        (\"tagline\", movieTagline),\n",
    "        (\"release_date\", movieReleaseDate),\n",
    "        (\"popularity\", moviePopularity),\n",
    "        (\"vote_average\", movieVoteAverage),\n",
    "        (\"vote_count\", movieVoteCount),\n",
    "        (\"runtime\", movieRuntime),\n",
    "        (\"revenue\", movieRevenue),\n",
    "        (\"original_language\", movieOriginalLanguage),\n",
    "        (\"vector\", azure_openai_embeddings.embed_query(content))\n",
    "    ]))\n",
    "\n",
    "    print(f\"Movie {movieTitle} added.\")\n",
    "\n",
    "print(f\"New items structure with embeddings created for {len(items)} movies.\")\n",
    "\n",
    "from azure.search.documents import SearchClient\n",
    "\n",
    "search_client = SearchClient(\n",
    "    f\"{apim_resource_gateway_url}/{searchindex_api_path}\",\n",
    "    searchindex_name,\n",
    "    AzureKeyCredential(apim_subscription_key)\n",
    ")\n",
    "\n",
    "result = search_client.upload_documents(items)\n",
    "\n",
    "print(f\"Successfully loaded {len(data)} movies into Azure AI Search index.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='search'></a>\n",
    "### üß™ Vector store searching using Azure AI Search\n",
    "We've loaded the movies into Azure AI Search, so now let's experiment with some of the different types of searches you can perform.\n",
    "\n",
    "First we'll just perform a simple keyword search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What are the best movies about superheroes?\"\n",
    "\n",
    "search_client = SearchClient(\n",
    "    f\"{apim_resource_gateway_url}/{searchindex_api_path}\",\n",
    "    searchindex_name,\n",
    "    AzureKeyCredential(apim_subscription_key)\n",
    ")\n",
    "\n",
    "results = list(search_client.search(\n",
    "    search_text=query,\n",
    "    query_type=\"simple\",\n",
    "    include_total_count=True,\n",
    "    top=5\n",
    "))\n",
    "\n",
    "for result in results:\n",
    "    print(\"Movie: {}\".format(result[\"title\"]))\n",
    "    print(\"Genre: {}\".format(result[\"genre\"]))\n",
    "    print(\"----------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='langchain'></a>\n",
    "### üß™ Bringing it All Together with Retrieval Augmented Generation (RAG) + Langchain (LC)\n",
    "Now that we have our Vector Store setup and data loaded, we are now ready to implement the RAG pattern using AI Orchestration. At a high-level, the following steps are required:\n",
    "\n",
    "Ask the question\n",
    "Create Prompt Template with inputs\n",
    "Get Embedding representation of inputted question\n",
    "Use embedded version of the question to search Azure AI Search (ie. The Vector Store)\n",
    "Inject the results of the search into the Prompt Template & Execute the Prompt to get the completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement RAG using Langchain (LC)\n",
    "\n",
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain.chains import LLMChain\n",
    "import uuid\n",
    "\n",
    "UUID = str(uuid.uuid4())\n",
    "print(f\"Request-Id: {UUID} - use this ID to trace the requests in Azure Application Insights.\")\n",
    "\n",
    "azure_openai_embeddings = AzureOpenAIEmbeddings(\n",
    "    azure_endpoint = apim_resource_gateway_url,\n",
    "    openai_api_key = apim_subscription_key,\n",
    "    azure_deployment = openai_embeddings_deployment_name,\n",
    "    openai_api_version = openai_api_version,\n",
    "    model= openai_embeddings_model_name\n",
    ")\n",
    "\n",
    "azure_openai = AzureChatOpenAI(\n",
    "    default_headers = {\"Request-Id\": UUID},\n",
    "    azure_endpoint = apim_resource_gateway_url,\n",
    "    openai_api_key = apim_subscription_key,\n",
    "    azure_deployment = openai_deployment_name,\n",
    "    openai_api_version = openai_api_version,\n",
    "    model= openai_model_name\n",
    ")\n",
    "\n",
    "# Ask the question\n",
    "query = \"What are the best movies about superheroes?\"\n",
    "\n",
    "# Create a prompt template with variables, note the curly braces\n",
    "from langchain.prompts import PromptTemplate\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"original_question\",\"search_results\"],\n",
    "    template=\"\"\"\n",
    "    Question: {original_question}\n",
    "\n",
    "    Do not use any other data.\n",
    "    Only use the movie data below when responding.\n",
    "    Provide detailed information about the synopsis of the movie.\n",
    "    {search_results}\n",
    "    \"\"\",\n",
    ")\n",
    "\n",
    "# Search Vector Store\n",
    "search_client = SearchClient(\n",
    "    f\"{apim_resource_gateway_url}/{searchindex_api_path}\",\n",
    "    searchindex_name,\n",
    "    AzureKeyCredential(apim_subscription_key)    \n",
    ")\n",
    "\n",
    "vector = VectorizedQuery(vector=azure_openai_embeddings.embed_query(query), k_nearest_neighbors=5, fields=\"vector\")\n",
    "\n",
    "results = list(search_client.search(\n",
    "    search_text=query,\n",
    "    query_type=\"semantic\",\n",
    "    semantic_configuration_name=\"movies-semantic-config\",\n",
    "    include_total_count=True,\n",
    "    vector_queries=[vector],\n",
    "    select=[\"title\",\"genre\",\"overview\",\"tagline\",\"release_date\",\"popularity\",\"vote_average\",\"vote_count\",\"runtime\",\"revenue\",\"original_language\"],\n",
    "    top=5,\n",
    "    headers={\"Request-Id\": UUID}\n",
    "))\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "# Build the Prompt and Execute against the Azure OpenAI to get the completion\n",
    "chain = prompt | azure_openai | output_parser\n",
    "response = chain.invoke(input={\"original_question\": query, \"search_results\": results})\n",
    "print (response)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='clean'></a>\n",
    "### üóëÔ∏è Clean up resources\n",
    "\n",
    "When you're finished with the lab, you should remove all your deployed resources from Azure to avoid extra charges and keep your Azure subscription uncluttered.\n",
    "Use the [clean-up-resources notebook](clean-up-resources.ipynb) for that."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
