{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6322e4e",
   "metadata": {},
   "source": [
    "# APIM ‚ù§Ô∏è AI Foundry\n",
    "\n",
    "## Session Awareness lab\n",
    "\n",
    "Playground to demonstrate session awareness capabilities in [Azure API Management backend pools](https://learn.microsoft.com/azure/api-management/backends?tabs=bicep) when using the [OpenAI Responses API](https://learn.microsoft.com/azure/ai-foundry/openai/how-to/responses) for multi-turn conversations.\n",
    "\n",
    "### Overview\n",
    "\n",
    "The OpenAI Responses API requires maintaining conversation state across multiple API calls by using a response ID from previous calls. When using a backend pool without session affinity, requests can be routed to different backend instances, breaking the conversation state. This lab demonstrates:\n",
    "\n",
    "1. **Backend Pool without Session Affinity**: Shows how conversation state breaks when requests are distributed across different backends\n",
    "2. **Backend Pool with Session Affinity**: Shows how session affinity ensures requests from the same conversation stay on the same backend\n",
    "\n",
    "### Key Technologies Demonstrated\n",
    "\n",
    "- **Azure API Management**: Load balancing and backend pool management\n",
    "- **Session Affinity**: Cookie-based session stickiness in APIM\n",
    "- **OpenAI Responses API**: Stateful API requiring conversation continuity\n",
    "- **Multi-region Deployment**: AI Foundry instances in different Azure regions\n",
    "- **Managed Identity**: Secure authentication to AI services\n",
    "\n",
    "### Prerequisites\n",
    "\n",
    "- [Python 3.12 or later version](https://www.python.org/) installed\n",
    "- [VS Code](https://code.visualstudio.com/) installed with the [Jupyter notebook extension](https://marketplace.visualstudio.com/items?itemName=ms-toolsai.jupyter) enabled\n",
    "- [Python environment](https://code.visualstudio.com/docs/python/environments#_creating-environments) with the [requirements.txt](../../requirements.txt) or run `pip install -r requirements.txt` in your terminal\n",
    "- [An Azure Subscription](https://azure.microsoft.com/free/) with [Contributor](https://learn.microsoft.com/en-us/azure/role-based-access-control/built-in-roles/privileged#contributor) + [RBAC Administrator](https://learn.microsoft.com/en-us/azure/role-based-access-control/built-in-roles/privileged#role-based-access-control-administrator) or [Owner](https://learn.microsoft.com/en-us/azure/role-based-access-control/built-in-roles/privileged#owner) roles\n",
    "- [Azure CLI](https://learn.microsoft.com/cli/azure/install-azure-cli) installed and [Signed into your Azure subscription](https://learn.microsoft.com/cli/azure/authenticate-azure-cli-interactively)\n",
    "\n",
    "‚ñ∂Ô∏è Click `Run All` to execute all steps sequentially, or execute them `Step by Step`... "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098133ea",
   "metadata": {},
   "source": [
    "<a id='0'></a>\n",
    "### 0Ô∏è‚É£ Initialize notebook variables\n",
    "\n",
    "- Resources will be suffixed by a unique string based on your subscription id.\n",
    "- Adjust the location parameters according your preferences and on the [product availability by Azure region.](https://azure.microsoft.com/explore/global-infrastructure/products-by-region/?cdn=disable&products=cognitive-services,api-management)\n",
    "- Adjust the models and versions according the [availability by region.](https://learn.microsoft.com/azure/ai-services/openai/concepts/models) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97e4bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, json, requests, time, subprocess\n",
    "sys.path.insert(1, '../../shared')  # add the shared directory to the Python path\n",
    "import utils\n",
    "\n",
    "deployment_name = os.path.basename(os.path.dirname(globals()['__vsc_ipynb_file__']))\n",
    "resource_group_name = f\"lab-{deployment_name}\" # change the name to match your naming style\n",
    "resource_group_location = \"eastus\"\n",
    "\n",
    "aiservices_config = [\n",
    "    {\"name\": \"foundry1\", \"location\": \"eastus\"},\n",
    "    {\"name\": \"foundry2\", \"location\": \"westus\"}\n",
    "]\n",
    "\n",
    "models_config = [\n",
    "    {\"name\": \"gpt-4o-mini\", \"publisher\": \"OpenAI\", \"version\": \"2024-07-18\", \"sku\": \"GlobalStandard\", \"capacity\": 1}\n",
    "]\n",
    "\n",
    "apim_sku = \"Basicv2\"  # Fixed: Use Basicv2 instead of BasicV2_1\n",
    "apim_subscriptions_config = [\n",
    "    {\n",
    "        \"name\": \"session-awareness-subscription\",\n",
    "        \"displayName\": \"Session Awareness Lab Subscription\",\n",
    "        \"allowTracing\": True,\n",
    "        \"state\": \"active\"\n",
    "    }\n",
    "]\n",
    "\n",
    "print(\"‚úÖ Variables initialized\")\n",
    "print(f\"üìç Resource group: {resource_group_name}\")\n",
    "print(f\"üìç Location: {resource_group_location}\")\n",
    "print(f\"ü§ñ AI Services: {len(aiservices_config)} instances\")\n",
    "print(f\"üöÄ APIM SKU: {apim_sku}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a301ac",
   "metadata": {},
   "source": [
    "<a id='1'></a>\n",
    "### 1Ô∏è‚É£ Verify the Azure CLI and the connected Azure subscription\n",
    "\n",
    "The following commands ensure that you have the latest version of the Azure CLI and that the Azure CLI is connected to your Azure subscription."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4df4f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = utils.run(\"az account show\", \"Retrieved az account\", \"Failed to get the current az account\")\n",
    "\n",
    "if output.success and output.json_data:\n",
    "    current_user = output.json_data['user']['name']\n",
    "    tenant_id = output.json_data['tenantId']\n",
    "    subscription_id = output.json_data['id']\n",
    "\n",
    "    print(f\"‚úÖ Current user: {current_user}\")\n",
    "    print(f\"‚úÖ Tenant ID: {tenant_id}\")\n",
    "    print(f\"‚úÖ Subscription ID: {subscription_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b46f984",
   "metadata": {},
   "source": [
    "<a id='2'></a>\n",
    "### 2Ô∏è‚É£ Create deployment using ü¶æ Bicep\n",
    "\n",
    "This lab uses [Bicep](https://learn.microsoft.com/azure/azure-resource-manager/bicep/overview?tabs=bicep) to declaratively define all the resources that will be deployed in the specified resource group. This will create:\n",
    "- 2 AI Foundry instances in different regions (eastus, westus)\n",
    "- Each with a gpt-4o-mini model deployment\n",
    "- Azure API Management instance\n",
    "- Backend pool (initially without session affinity)\n",
    "- Inference API with load balancing policies\n",
    "\n",
    "The lab initially deploys with a standard backend pool. We'll enable session affinity later to demonstrate the difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223b331d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the resource group if it doesn't exist\n",
    "utils.create_resource_group(resource_group_name, resource_group_location)\n",
    "\n",
    "# Set up deployment parameters\n",
    "bicep_parameters_file = \"params.json\"\n",
    "\n",
    "# Create the parameters for the Bicep template (ARM deployment parameters format)\n",
    "bicep_parameters = {\n",
    "    \"$schema\": \"https://schema.management.azure.com/schemas/2019-04-01/deploymentParameters.json#\",\n",
    "    \"contentVersion\": \"1.0.0.0\",\n",
    "    \"parameters\": {\n",
    "        \"aiServicesConfig\": {\"value\": aiservices_config},\n",
    "        \"modelsConfig\": {\"value\": models_config},\n",
    "        \"apimSku\": {\"value\": apim_sku},\n",
    "        \"apimSubscriptionsConfig\": {\"value\": apim_subscriptions_config},\n",
    "        \"inferenceAPIType\": {\"value\": \"AzureOpenAI\"},\n",
    "        \"inferenceAPIPath\": {\"value\": \"inference\"},\n",
    "        \"foundryProjectName\": {\"value\": deployment_name}\n",
    "    }\n",
    "}\n",
    "\n",
    "# Write the parameters to the params.json file\n",
    "with open('params.json', 'w') as bicep_parameters_file:\n",
    "    bicep_parameters_file.write(json.dumps(bicep_parameters))\n",
    "\n",
    "print(\"‚úÖ Parameters file created successfully\")\n",
    "print(f\"üìÑ Parameters file: {bicep_parameters_file}\")\n",
    "print(f\"üéØ Using APIM SKU: {apim_sku}\")\n",
    "\n",
    "# Run the deployment\n",
    "output = utils.run(f\"az deployment group create --name {deployment_name} --resource-group {resource_group_name} --template-file main.bicep --parameters params.json\",\n",
    "    f\"Deployment '{deployment_name}' succeeded\", f\"Deployment '{deployment_name}' failed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8260372b",
   "metadata": {},
   "source": [
    "<a id='3'></a>\n",
    "### 3Ô∏è‚É£ Get the deployment outputs\n",
    "\n",
    "Retrieve the required outputs from the Bicep deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17deb5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain all of the outputs from the deployment\n",
    "output = utils.run(f\"az deployment group show --name {deployment_name} -g {resource_group_name}\", f\"Retrieved deployment: {deployment_name}\", f\"Failed to retrieve deployment: {deployment_name}\")\n",
    "\n",
    "if output.success and output.json_data:\n",
    "    deployment_outputs = output.json_data['properties']['outputs']\n",
    "    \n",
    "    # Extract values safely\n",
    "    apim_service_id = deployment_outputs.get('apimServiceId', {}).get('value', 'not-found')\n",
    "    apim_resource_gateway_url = deployment_outputs.get('apimResourceGatewayURL', {}).get('value', 'not-found')\n",
    "    apim_subscriptions = deployment_outputs.get('apimSubscriptions', {}).get('value', [])\n",
    "    foundry_instances = deployment_outputs.get('foundryInstances', {}).get('value', [])\n",
    "    apim_service_name = deployment_outputs.get('apimServiceName', {}).get('value', 'not-found')\n",
    "    \n",
    "    # Get the subscription key for testing\n",
    "    subscription_key = 'not-found'\n",
    "    if apim_subscriptions and len(apim_subscriptions) > 0:\n",
    "        if isinstance(apim_subscriptions[0], dict):\n",
    "            subscription_key = apim_subscriptions[0].get('key', 'unknown')\n",
    "        else:\n",
    "            print(f\"Warning: Unexpected subscription structure: {type(apim_subscriptions[0])}\")\n",
    "    \n",
    "    print(f\"üì° APIM Gateway URL: {apim_resource_gateway_url}\")\n",
    "    print(f\"üîß APIM Service Name: {apim_service_name}\")\n",
    "    print(f\"üîë Subscription Count: {len(apim_subscriptions) if apim_subscriptions else 0}\")\n",
    "    print(f\"üß† Foundry Instances: {len(foundry_instances) if foundry_instances else 0}\")\n",
    "    print(f\"üóùÔ∏è  Subscription Key: {subscription_key[:8]}...\" if subscription_key != 'not-found' and subscription_key != 'unknown' else \"‚ùå No subscription key found\")\n",
    "    \n",
    "    if subscription_key != 'not-found' and apim_resource_gateway_url != 'not-found':\n",
    "        print(\"\\n‚úÖ Ready to test session affinity behavior!\")\n",
    "    else:\n",
    "        print(\"\\n‚ùå Missing required deployment outputs\")\n",
    "else:\n",
    "    print(\"‚ùå Failed to retrieve deployment outputs\")\n",
    "    raise Exception(\"Could not get deployment outputs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc1105a",
   "metadata": {},
   "source": [
    "<a id='4'></a>\n",
    "### 4Ô∏è‚É£ Test Session Awareness Without Affinity\n",
    "\n",
    "First, let's test the backend pool **without session affinity**. We'll use the OpenAI Responses API to start a conversation and then try to continue it. When requests hit different backends, the conversation state breaks because the `previous_response_id` only exists on the original backend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26e3a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import httpx\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "# Custom transport to log backend routing info (like the demo)\n",
    "class BackendLoggingTransport(httpx.HTTPTransport):\n",
    "    def handle_request(self, request):\n",
    "        cookies = request.headers.get('cookie', 'None')\n",
    "        print(f\"üç™ Request cookies: {cookies}\")\n",
    "        \n",
    "        response = super().handle_request(request)\n",
    "        \n",
    "        # Log session affinity cookies\n",
    "        set_cookies = response.headers.get_list('set-cookie')\n",
    "        for cookie in set_cookies:\n",
    "                print(f\"üç™ Session cookie: {cookie}\")\n",
    "        \n",
    "        # Log backend info from APIM policy\n",
    "        request_id = response.headers.get('x-request-id', 'unknown')\n",
    "        backend_region = response.headers.get('x-backend-region', 'unknown')\n",
    "        \n",
    "        print(f\"üÜî Request ID: {request_id}\")\n",
    "        print(f\"üåç Backend Region: {backend_region}\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        return response\n",
    "\n",
    "def get_response_text(response):\n",
    "    \"\"\"Extract text from the OpenAI Responses API response structure\"\"\"\n",
    "    try:\n",
    "        return response.output[0].content[0].text\n",
    "    except (IndexError, AttributeError):\n",
    "        return str(response)[:100] + \"...\"\n",
    "\n",
    "def test_session_affinity():\n",
    "    \"\"\"Simple test based on the GitHub demo\"\"\"\n",
    "    print(\"üß™ Testing Session Affinity with OpenAI Responses API\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Create HTTP client with cookie support and logging\n",
    "    http_client = httpx.Client(\n",
    "        transport=BackendLoggingTransport(),\n",
    "    )\n",
    "    \n",
    "    # Create OpenAI client\n",
    "    client = AzureOpenAI(\n",
    "        api_key=subscription_key,\n",
    "        base_url=f\"{apim_resource_gateway_url}/inference/openai\",\n",
    "        api_version=\"2025-03-01-preview\",\n",
    "        http_client=http_client\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        print(\"\\n1Ô∏è‚É£ Creating first response...\")\n",
    "        first_response = client.responses.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            input=\"Explain photosynthesis in simple terms\"\n",
    "        )\n",
    "        \n",
    "        print(f\"‚úÖ First response ID: {first_response.id}\")\n",
    "        print(f\"üìÑ Content: {get_response_text(first_response)[:100]}...\")\n",
    "        \n",
    "        print(\"\\n2Ô∏è‚É£ Creating second response with previous_response_id...\")\n",
    "        second_response = client.responses.create(\n",
    "            model=\"gpt-4o-mini\", \n",
    "            input=\"Can you summarize that so it can be understood by a college freshman?\",\n",
    "            previous_response_id=first_response.id\n",
    "        )\n",
    "        \n",
    "        print(f\"‚úÖ Second response ID: {second_response.id}\")\n",
    "        print(f\"üìÑ Content: {get_response_text(second_response)[:100]}...\")\n",
    "        \n",
    "        print(\"\\n‚úÖ SUCCESS: Session affinity is working!\")\n",
    "        print(\"üí° Both requests completed successfully, indicating session stickiness.\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå FAILURE: {e}\")\n",
    "        if \"not found\" in str(e).lower():\n",
    "            print(\"üí° This is the expected error when session affinity is broken!\")\n",
    "            print(\"üí° The previous_response_id exists on a different backend.\")\n",
    "    \n",
    "    finally:\n",
    "        # Clean up\n",
    "        http_client.close()\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"üîç ANALYSIS:\")\n",
    "    print(\"- If you see different regions between requests ‚Üí session affinity broken\")\n",
    "    print(\"- If you get 'not found' error ‚Üí previous_response_id is on different backend\") \n",
    "    print(\"- If both requests succeed ‚Üí session affinity is working\")\n",
    "    print(\"- Check for APIM-Backend-Affinity cookies in the logs above\")\n",
    "\n",
    "# Run the test\n",
    "test_session_affinity()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d81d882",
   "metadata": {},
   "source": [
    "<a id='5'></a>\n",
    "### 5Ô∏è‚É£ Enable Session Affinity on Backend Pool\n",
    "\n",
    "Now let's enable session affinity on the backend pool. This configuration ensures that requests from the same client session are routed to the same backend instance, maintaining conversation state for the OpenAI Responses API.\n",
    "\n",
    "Session affinity uses cookies to track which backend instance should handle requests from a specific client session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d33ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable session affinity on the backend pool\n",
    "print(\"üîÑ Enabling session affinity on backend pool...\")\n",
    "\n",
    "backend_pool_name = \"inference-backend-pool\"\n",
    "\n",
    "# First get current backend pool configuration to preserve services\n",
    "get_result = utils.run(\n",
    "    f'az rest --method get --url \"https://management.azure.com{apim_service_id}/backends/{backend_pool_name}?api-version=2023-05-01-preview\"',\n",
    "    \"‚úÖ Retrieved backend pool configuration\",\n",
    "    \"‚ùå Failed to get backend pool configuration\"\n",
    ")\n",
    "\n",
    "if get_result.success and get_result.json_data:\n",
    "    current_config = get_result.json_data\n",
    "    current_services = current_config.get('properties', {}).get('pool', {}).get('services', [])\n",
    "    print(f\"üìã Found {len(current_services)} services in backend pool\")\n",
    "    \n",
    "    # Create the session affinity configuration with existing services\n",
    "    session_affinity_config = {\n",
    "        \"properties\": {\n",
    "            \"pool\": {\n",
    "                \"services\": current_services,  # Preserve existing services\n",
    "                \"sessionAffinity\": {\n",
    "                    \"enabled\": True,\n",
    "                    \"affinityType\": \"Cookie\",\n",
    "                    \"cookieName\": \"APIM-Backend-Affinity\",\n",
    "                    \"sessionId\": {\n",
    "                        \"source\": \"cookie\",  # Session ID comes from cookie\n",
    "                        \"name\": \"APIM-Backend-Affinity\"  # Cookie name for session ID\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Could not get current services, using minimal configuration...\")\n",
    "    # Create minimal session affinity configuration\n",
    "    session_affinity_config = {\n",
    "        \"properties\": {\n",
    "            \"pool\": {\n",
    "                \"sessionAffinity\": {\n",
    "                    \"enabled\": True,\n",
    "                    \"affinityType\": \"Cookie\",\n",
    "                    \"cookieName\": \"APIM-Backend-Affinity\",\n",
    "                    \"sessionId\": {\n",
    "                        \"source\": \"cookie\",\n",
    "                        \"name\": \"APIM-Backend-Affinity\"\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "# Apply session affinity to the backend pool\n",
    "result = utils.run(\n",
    "    f'az rest --method patch --url \"https://management.azure.com{apim_service_id}/backends/{backend_pool_name}?api-version=2023-05-01-preview\" --body \\'{json.dumps(session_affinity_config)}\\'',\n",
    "    \"‚úÖ Backend pool session affinity enabled\",\n",
    "    \"‚ùå Failed to enable backend pool session affinity\"\n",
    ")\n",
    "\n",
    "if result.success:\n",
    "    print(\"‚úÖ Session affinity enabled on backend pool!\")\n",
    "    print(\"üç™ Cookie-based session stickiness: APIM-Backend-Affinity\")\n",
    "    print(\"üéØ Ready to test session awareness!\")\n",
    "else:\n",
    "    print(\"‚ùå Failed to enable session affinity on backend pool\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37fe90b9",
   "metadata": {},
   "source": [
    "<a id='6'></a>\n",
    "### 6Ô∏è‚É£ Test Session Affinity\n",
    "\n",
    "Now let's test the session affinity to verify it's working correctly. With session affinity enabled, requests from the same client should stick to the same backend, allowing the OpenAI Responses API to maintain conversation state across multiple requests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce76415e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test session affinity behavior\n",
    "test_session_affinity()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a789f55a",
   "metadata": {},
   "source": [
    "# üéØ Lab Summary\n",
    "\n",
    "## What We Accomplished\n",
    "\n",
    "This lab demonstrated session awareness in Azure API Management backend pools using the OpenAI Responses API:\n",
    "\n",
    "### ‚úÖ **Core Functionality Tested:**\n",
    "- **Backend Pool Load Balancing**: Multiple AI Foundry instances across regions\n",
    "- **Session Affinity**: Cookie-based session stickiness in APIM\n",
    "- **OpenAI Responses API**: Stateful conversations with response chaining\n",
    "- **Managed Identity**: Secure authentication to AI services\n",
    "\n",
    "### üîß **Key Configuration:**\n",
    "- **Without Session Affinity**: Requests distribute randomly, breaking conversation state\n",
    "- **With Session Affinity**: Requests stick to same backend, maintaining conversation state\n",
    "\n",
    "### üí° **When to Use Session Affinity:**\n",
    "- OpenAI Responses API (multi-turn conversations)\n",
    "- OpenAI Assistants API (thread-based conversations)  \n",
    "- Any stateful AI workload requiring conversation continuity\n",
    "\n",
    "### üéâ **Success Criteria:**\n",
    "- Without affinity: \"not found\" errors when using `previous_response_id`\n",
    "- With affinity: Both requests succeed, same backend region, session cookies present\n",
    "\n",
    "This simplified approach follows proven patterns and is much more reliable than complex diagnostic approaches."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d27e955",
   "metadata": {},
   "source": [
    "<a id='cleanup'></a>\n",
    "### üóëÔ∏è Clean up resources\n",
    "\n",
    "When you're finished with the lab, run the [clean-up-resources notebook](clean-up-resources.ipynb) to remove all deployed resources from Azure and avoid extra charges."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
