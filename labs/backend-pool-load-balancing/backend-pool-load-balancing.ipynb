{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# APIM ‚ù§Ô∏è OpenAI\n",
    "\n",
    "## Backend pool Load Balancing lab\n",
    "![flow](../../images/backend-pool-load-balancing.gif)\n",
    "\n",
    "Playground to try the built-in load balancing [backend pool functionality of APIM](https://learn.microsoft.com/azure/api-management/backends?tabs=bicep) to a list of Azure OpenAI endpoints.\n",
    "\n",
    "Notes:\n",
    "- **This is a typical prioritized PTU with fallback consumption scenario**. The lab specifically showcases how a priority 1 (highest) backend is exhausted before gracefully falling back to two equally-weighted priority 2 backends. \n",
    "- The backend pool uses round-robin by default.\n",
    "- Priority and weight-based routing are supported and can be adjusted by modifying `priority` (the lower the number, the higher the priority) and `weight` parameters in the `openai_resources` variable below.\n",
    "- The `retry` API Management policy initiates a retry to an available backend if an HTTP 429 status code is encountered. This is transparent to the caller.\n",
    "\n",
    "### Result\n",
    "![result](result.png)\n",
    "\n",
    "### TOC\n",
    "- [0Ô∏è‚É£ Initialize notebook variables](#0)\n",
    "- [1Ô∏è‚É£ Verify the Azure CLI and the connected Azure subscription](#1)\n",
    "- [2Ô∏è‚É£ Create deployment using ü¶æ Bicep](#2)\n",
    "- [3Ô∏è‚É£ Get the deployment outputs](#3)\n",
    "- [üß™ Test the API using a direct HTTP call](#requests)\n",
    "- [üîç Analyze Load Balancing results](#plot)\n",
    "- [üß™ Test the API using the Azure OpenAI Python SDK](#sdk)\n",
    "- [üóëÔ∏è Clean up resources](#clean)\n",
    "\n",
    "### Prerequisites\n",
    "- [Python 3.12 or later version](https://www.python.org/) installed\n",
    "- [Pandas Library](https://pandas.pydata.org/) and matplotlib installed\n",
    "- [VS Code](https://code.visualstudio.com/) installed with the [Jupyter notebook extension](https://marketplace.visualstudio.com/items?itemName=ms-toolsai.jupyter) enabled\n",
    "- [Azure CLI](https://learn.microsoft.com/cli/azure/install-azure-cli) installed\n",
    "- [An Azure Subscription](https://azure.microsoft.com/free/) with Contributor permissions\n",
    "- [Access granted to Azure OpenAI](https://aka.ms/oai/access) or just enable the mock service\n",
    "- [Sign in to Azure with Azure CLI](https://learn.microsoft.com/cli/azure/authenticate-azure-cli-interactively)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='0'></a>\n",
    "### 0Ô∏è‚É£ Initialize notebook variables\n",
    "\n",
    "- Resources will be suffixed by a unique string based on your subscription id.\n",
    "- Adjust the location parameters according your preferences and on the [product availability by Azure region.](https://azure.microsoft.com/explore/global-infrastructure/products-by-region/?cdn=disable&products=cognitive-services,api-management) \n",
    "- Adjust the OpenAI model and version according the [availability by region.](https://learn.microsoft.com/azure/ai-services/openai/concepts/models) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ \u001b[1;32m Notebook initialized \u001b[0m‚åö 20:39:39.159781   \n"
     ]
    }
   ],
   "source": [
    "import os, sys, json\n",
    "sys.path.insert(1, '../../shared')  # add the shared directory to the Python path\n",
    "import utils\n",
    "\n",
    "deployment_name = os.path.basename(os.path.dirname(globals()['__vsc_ipynb_file__']))\n",
    "resource_group_name = f\"lab-{deployment_name}\" # change the name to match your naming style\n",
    "resource_group_location = \"westeurope\"\n",
    "\n",
    "apim_sku = 'Basicv2'\n",
    "\n",
    "# Prioritize UK South until exhaustion (simulate PTU with TPM), then equally distribute between Sweden and France (consumption fallback)\n",
    "openai_resources = [\n",
    "    {\"name\": \"openai1\", \"location\": \"uksouth\", \"priority\": 1},\n",
    "    {\"name\": \"openai2\", \"location\": \"swedencentral\", \"priority\": 2, \"weight\": 50},\n",
    "    {\"name\": \"openai3\", \"location\": \"francecentral\", \"priority\": 2, \"weight\": 50}\n",
    "]\n",
    "\n",
    "openai_deployment_name = \"gpt-35-turbo\"\n",
    "openai_model_name = \"gpt-35-turbo\"\n",
    "openai_model_version = \"0613\"\n",
    "openai_model_capacity = 8\n",
    "openai_api_version = \"2024-02-01\"\n",
    "\n",
    "utils.print_ok('Notebook initialized')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='1'></a>\n",
    "### 1Ô∏è‚É£ Verify the Azure CLI and the connected Azure subscription\n",
    "\n",
    "The following commands ensure that you have the latest version of the Azure CLI and that the Azure CLI is connected to your Azure subscription."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚öôÔ∏è \u001b[1;34m Running:  az account show \u001b[0m\n",
      "‚úÖ \u001b[1;32m Retrieved az account \u001b[0m‚åö 20:39:42.105004 [0m:2s]  \n"
     ]
    }
   ],
   "source": [
    "output = utils.run(\"az account show\", \"Retrieved az account\", \"Failed to get the current az account\")\n",
    "if output.success and output.json_data:\n",
    "    current_user = output.json_data['user']['name']\n",
    "    subscription_id = output.json_data['id']\n",
    "    tenant_id = output.json_data['tenantId']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='2'></a>\n",
    "### 2Ô∏è‚É£ Create deployment using ü¶æ Bicep\n",
    "\n",
    "This lab uses [Bicep](https://learn.microsoft.com/azure/azure-resource-manager/bicep/overview?tabs=bicep) to declarative define all the resources that will be deployed in the specified resource group. Change the parameters or the [main.bicep](main.bicep) directly to try different configurations. \n",
    "\n",
    "`openAIModelCapacity` is set intentionally low to `8` (8k tokens per minute) to showcase the retry logic in the load balancer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚öôÔ∏è \u001b[1;34m Running:  az group show --name lab-backend-pool-load-balancing \u001b[0m\n",
      "‚öôÔ∏è \u001b[1;34m Running:  az group create --name lab-backend-pool-load-balancing --location westeurope \u001b[0m\n",
      "‚úÖ \u001b[1;32m Resource group 'lab-backend-pool-load-balancing' created \u001b[0m‚åö 20:39:51.988365 [0m:4s]  \n",
      "‚öôÔ∏è \u001b[1;34m Running:  az deployment group create --name backend-pool-load-balancing --resource-group lab-backend-pool-load-balancing --template-file main.bicep --parameters params.json \u001b[0m\n",
      "‚úÖ \u001b[1;32m Deployment 'backend-pool-load-balancing' succeeded \u001b[0m‚åö 20:42:04.248186 [2m:12s]  \n"
     ]
    }
   ],
   "source": [
    "# create the resource group if doesn't exist\n",
    "utils.create_resource_group(True, resource_group_name, resource_group_location)\n",
    "\n",
    "# define the BICEP parameters\n",
    "bicep_parameters = {\n",
    "    \"$schema\": \"https://schema.management.azure.com/schemas/2019-04-01/deploymentParameters.json#\",\n",
    "    \"contentVersion\": \"1.0.0.0\",\n",
    "    \"parameters\": {\n",
    "        \"apimSku\": { \"value\": apim_sku },\n",
    "        \"openAIConfig\": { \"value\": openai_resources },\n",
    "        \"openAIDeploymentName\": { \"value\": openai_deployment_name },\n",
    "        \"openAIModelName\": { \"value\": openai_model_name },\n",
    "        \"openAIModelVersion\": { \"value\": openai_model_version },\n",
    "        \"openAIModelCapacity\": { \"value\": openai_model_capacity },\n",
    "        \"openAIAPIVersion\": { \"value\": openai_api_version }\n",
    "    }\n",
    "}\n",
    "\n",
    "# write the parameters to a file\n",
    "with open('params.json', 'w') as bicep_parameters_file:\n",
    "    bicep_parameters_file.write(json.dumps(bicep_parameters))\n",
    "\n",
    "# run the deployment\n",
    "output = utils.run(f\"az deployment group create --name {deployment_name} --resource-group {resource_group_name} --template-file main.bicep --parameters params.json\",\n",
    "                f\"Deployment '{deployment_name}' succeeded\", f\"Deployment '{deployment_name}' failed\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='3'></a>\n",
    "### 3Ô∏è‚É£ Get the deployment outputs\n",
    "\n",
    "Retrieve the required outputs from the Bicep deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚öôÔ∏è \u001b[1;34m Running:  az deployment group show --name backend-pool-load-balancing -g lab-backend-pool-load-balancing \u001b[0m\n",
      "‚úÖ \u001b[1;32m Retrieved deployment: backend-pool-load-balancing \u001b[0m‚åö 20:42:08.185084 [0m:3s]  \n",
      "üëâüèΩ \u001b[1;34m APIM Service Id: /subscriptions/9d4a14de-67d7-4029-a3b4-7a7e3e6581cf/resourceGroups/lab-backend-pool-load-balancing/providers/Microsoft.ApiManagement/service/apim-4qeimgeex7udc \u001b[0m\n",
      "üëâüèΩ \u001b[1;34m APIM Subscription Key (masked): ****2361 \u001b[0m\n",
      "üëâüèΩ \u001b[1;34m APIM API Gateway URL: https://apim-4qeimgeex7udc.azure-api.net \u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Obtain all of the outputs from the deployment\n",
    "output = utils.run(f\"az deployment group show --name {deployment_name} -g {resource_group_name}\", f\"Retrieved deployment: {deployment_name}\", f\"Failed to retrieve deployment: {deployment_name}\")\n",
    "if output.success and output.json_data:\n",
    "    apim_service_id = utils.get_deployment_output(output, 'apimServiceId', 'APIM Service Id')\n",
    "    apim_subscription_key = utils.get_deployment_output(output, 'apimSubscriptionKey', 'APIM Subscription Key (masked)', True)\n",
    "    apim_resource_gateway_url = utils.get_deployment_output(output, 'apimResourceGatewayURL', 'APIM API Gateway URL')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='requests'></a>\n",
    "### üß™ Test the API using a direct HTTP call\n",
    "Requests is an elegant and simple HTTP library for Python that will be used here to make raw API requests and inspect the responses. \n",
    "\n",
    "You will not see HTTP 429s returned as API Management's `retry` policy will select an available backend. If no backends are viable, an HTTP 503 will be returned.\n",
    "\n",
    "Tip: Use the [tracing tool](../../tools/tracing.ipynb) to track the behavior of the backend pool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ñ∂Ô∏è Run 1/20:\n",
      "‚åö 2.29 seconds\n",
      "Response status: \u001b[1;32m200 - OK\u001b[0m\n",
      "x-ms-region: \u001b[1;32mUK South\u001b[0m\n",
      "Token usage: {\n",
      "    \"completion_tokens\": 20,\n",
      "    \"prompt_tokens\": 31,\n",
      "    \"total_tokens\": 51\n",
      "}\n",
      "\n",
      "üí¨ Oh sure, because telling time is such a complicated task. Just look at any clock, genius.\n",
      "\n",
      "‚ñ∂Ô∏è Run 2/20:\n",
      "‚åö 0.47 seconds\n",
      "Response status: \u001b[1;32m200 - OK\u001b[0m\n",
      "x-ms-region: \u001b[1;32mUK South\u001b[0m\n",
      "Token usage: {\n",
      "    \"completion_tokens\": 43,\n",
      "    \"prompt_tokens\": 31,\n",
      "    \"total_tokens\": 74\n",
      "}\n",
      "\n",
      "üí¨ Sure, I'd be happy to tell you the time. It's a magical moment where the hands on the clock come together to form a meaningless number like 2:37 or 5:22. Enjoy!\n",
      "\n",
      "‚ñ∂Ô∏è Run 3/20:\n",
      "‚åö 0.49 seconds\n",
      "Response status: \u001b[1;32m200 - OK\u001b[0m\n",
      "x-ms-region: \u001b[1;32mUK South\u001b[0m\n",
      "Token usage: {\n",
      "    \"completion_tokens\": 52,\n",
      "    \"prompt_tokens\": 31,\n",
      "    \"total_tokens\": 83\n",
      "}\n",
      "\n",
      "üí¨ Oh, I'm flattered you think I'm capable of such a complex task. But alas, I am but a lowly virtual assistant. Perhaps you could consult the billions of devices around you that are specifically designed to display the time? Just a thought.\n",
      "\n",
      "‚ñ∂Ô∏è Run 4/20:\n",
      "‚åö 0.42 seconds\n",
      "Response status: \u001b[1;32m200 - OK\u001b[0m\n",
      "x-ms-region: \u001b[1;32mUK South\u001b[0m\n",
      "Token usage: {\n",
      "    \"completion_tokens\": 31,\n",
      "    \"prompt_tokens\": 31,\n",
      "    \"total_tokens\": 62\n",
      "}\n",
      "\n",
      "üí¨ Oh, I'd be delighted to help you with that. But let me just check if I feel like it... Ah, sorry, I don't.\n",
      "\n",
      "‚ñ∂Ô∏è Run 5/20:\n",
      "‚åö 0.39 seconds\n",
      "Response status: \u001b[1;32m200 - OK\u001b[0m\n",
      "x-ms-region: \u001b[1;32mUK South\u001b[0m\n",
      "Token usage: {\n",
      "    \"completion_tokens\": 31,\n",
      "    \"prompt_tokens\": 31,\n",
      "    \"total_tokens\": 62\n",
      "}\n",
      "\n",
      "üí¨ Oh, I'm sorry. I thought I was here to entertain you with delightful banter, not provide useful information like the time. Silly me.\n",
      "\n",
      "‚ñ∂Ô∏è Run 6/20:\n",
      "‚åö 0.51 seconds\n",
      "Response status: \u001b[1;32m200 - OK\u001b[0m\n",
      "x-ms-region: \u001b[1;32mUK South\u001b[0m\n",
      "Token usage: {\n",
      "    \"completion_tokens\": 31,\n",
      "    \"prompt_tokens\": 31,\n",
      "    \"total_tokens\": 62\n",
      "}\n",
      "\n",
      "üí¨ Oh, no, I couldn't possibly do that. Figuring out the time is a skill I have yet to master. Good luck with that though!\n",
      "\n",
      "‚ñ∂Ô∏è Run 7/20:\n",
      "‚åö 0.39 seconds\n",
      "Response status: \u001b[1;32m200 - OK\u001b[0m\n",
      "x-ms-region: \u001b[1;32mUK South\u001b[0m\n",
      "Token usage: {\n",
      "    \"completion_tokens\": 41,\n",
      "    \"prompt_tokens\": 31,\n",
      "    \"total_tokens\": 72\n",
      "}\n",
      "\n",
      "üí¨ Oh sure, let me just use my psychic abilities to determine the exact time. Oh wait, psychics aren't real. How about you just look at a clock or your phone like a normal person?\n",
      "\n",
      "‚ñ∂Ô∏è Run 8/20:\n",
      "‚åö 0.46 seconds\n",
      "Response status: \u001b[1;32m200 - OK\u001b[0m\n",
      "x-ms-region: \u001b[1;32mUK South\u001b[0m\n",
      "Token usage: {\n",
      "    \"completion_tokens\": 45,\n",
      "    \"prompt_tokens\": 31,\n",
      "    \"total_tokens\": 76\n",
      "}\n",
      "\n",
      "üí¨ Oh, sure! Let me just consult my vast knowledge and tell you the time down to the second... Actually, you know what? I'd rather not. Just look at a clock or use your smartphone like everyone else.\n",
      "\n",
      "‚ñ∂Ô∏è Run 9/20:\n",
      "‚åö 0.08 seconds\n",
      "Response status: \u001b[1;31m503 - Service Unavailable\u001b[0m\n",
      "\n",
      "\n",
      "‚ñ∂Ô∏è Run 10/20:\n",
      "‚åö 0.05 seconds\n",
      "Response status: \u001b[1;31m503 - Service Unavailable\u001b[0m\n",
      "\n",
      "\n",
      "‚ñ∂Ô∏è Run 11/20:\n",
      "‚åö 0.04 seconds\n",
      "Response status: \u001b[1;31m503 - Service Unavailable\u001b[0m\n",
      "\n",
      "\n",
      "‚ñ∂Ô∏è Run 12/20:\n",
      "‚åö 0.04 seconds\n",
      "Response status: \u001b[1;31m503 - Service Unavailable\u001b[0m\n",
      "\n",
      "\n",
      "‚ñ∂Ô∏è Run 13/20:\n",
      "‚åö 0.05 seconds\n",
      "Response status: \u001b[1;31m503 - Service Unavailable\u001b[0m\n",
      "\n",
      "\n",
      "‚ñ∂Ô∏è Run 14/20:\n",
      "‚åö 0.06 seconds\n",
      "Response status: \u001b[1;31m503 - Service Unavailable\u001b[0m\n",
      "\n",
      "\n",
      "‚ñ∂Ô∏è Run 15/20:\n",
      "‚åö 0.04 seconds\n",
      "Response status: \u001b[1;31m503 - Service Unavailable\u001b[0m\n",
      "\n",
      "\n",
      "‚ñ∂Ô∏è Run 16/20:\n",
      "‚åö 0.04 seconds\n",
      "Response status: \u001b[1;31m503 - Service Unavailable\u001b[0m\n",
      "\n",
      "\n",
      "‚ñ∂Ô∏è Run 17/20:\n",
      "‚åö 0.05 seconds\n",
      "Response status: \u001b[1;31m503 - Service Unavailable\u001b[0m\n",
      "\n",
      "\n",
      "‚ñ∂Ô∏è Run 18/20:\n",
      "‚åö 0.04 seconds\n",
      "Response status: \u001b[1;31m503 - Service Unavailable\u001b[0m\n",
      "\n",
      "\n",
      "‚ñ∂Ô∏è Run 19/20:\n",
      "‚åö 0.05 seconds\n",
      "Response status: \u001b[1;31m503 - Service Unavailable\u001b[0m\n",
      "\n",
      "\n",
      "‚ñ∂Ô∏è Run 20/20:\n",
      "‚åö 0.05 seconds\n",
      "Response status: \u001b[1;31m503 - Service Unavailable\u001b[0m\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests, time\n",
    "\n",
    "runs = 20\n",
    "sleep_time_ms = 100\n",
    "url = f\"{apim_resource_gateway_url}/openai/deployments/{openai_deployment_name}/chat/completions?api-version={openai_api_version}\"\n",
    "api_runs = []\n",
    "messages = {\"messages\": [\n",
    "    {\"role\": \"system\", \"content\": \"You are a sarcastic, unhelpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Can you tell me the time, please?\"}\n",
    "]}\n",
    "\n",
    "# Initialize a session for connection pooling\n",
    "session = requests.Session()\n",
    "# Set default headers\n",
    "session.headers.update({'api-key': apim_subscription_key})  # type: ignore\n",
    "\n",
    "try:\n",
    "    for i in range(runs):\n",
    "        print(f\"‚ñ∂Ô∏è Run {i+1}/{runs}:\")\n",
    "\n",
    "        start_time = time.time()\n",
    "        response = session.post(url, json = messages)\n",
    "        response_time = time.time() - start_time\n",
    "        print(f\"‚åö {response_time:.2f} seconds\")\n",
    "\n",
    "        # Check the response status code and apply formatting\n",
    "        if 200 <= response.status_code < 300:\n",
    "            status_code_str = f\"\\x1b[1;32m{response.status_code} - {response.reason}\\x1b[0m\" # Bold and green\n",
    "        elif response.status_code >= 400:\n",
    "            status_code_str = f\"\\x1b[1;31m{response.status_code} - {response.reason}\\x1b[0m\" # Bold and red\n",
    "        else:\n",
    "            status_code_str = str(response.status_code)  # No formatting\n",
    "\n",
    "        # Print the response status with the appropriate formatting\n",
    "        print(f\"Response status: {status_code_str}\")\n",
    "        # print(f\"Response headers: {json.dumps(dict(response.headers), indent = 4)}\")\n",
    "\n",
    "        if \"x-ms-region\" in response.headers:\n",
    "            print(f\"x-ms-region: \\x1b[1;32m{response.headers.get(\"x-ms-region\")}\\x1b[0m\") # this header is useful to determine the region of the backend that served the request\n",
    "            api_runs.append((response_time, response.headers.get(\"x-ms-region\")))\n",
    "\n",
    "        if (response.status_code == 200):\n",
    "            data = json.loads(response.text)\n",
    "            print(f\"Token usage: {json.dumps(dict(data.get(\"usage\")), indent = 4)}\\n\")\n",
    "            print(f\"üí¨ {data.get(\"choices\")[0].get(\"message\").get(\"content\")}\\n\")\n",
    "        else:\n",
    "            print(f\"{response.text}\\n\")\n",
    "\n",
    "        time.sleep(sleep_time_ms/1000)\n",
    "finally:\n",
    "    # Close the session to release the connection\n",
    "    session.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='plot'></a>\n",
    "### üîç Analyze Load Balancing results\n",
    "\n",
    "The priority 1 backend will be used until TPM exhaustion sets in, then distribution will occur near equally across the two priority 2 backends with 50/50 weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle as pltRectangle\n",
    "import matplotlib as mpl\n",
    "\n",
    "mpl.rcParams['figure.figsize'] = [15, 7]\n",
    "df = pd.DataFrame(api_runs, columns = ['Response Time', 'Region'])\n",
    "df['Run'] = range(1, len(df) + 1)\n",
    "\n",
    "# Define a color map for each region\n",
    "color_map = {'UK South': 'lightpink', 'France Central': 'lightblue', 'Sweden Central': 'lightyellow', 'Region3': 'red', 'Region4': 'orange'}  # Add more regions and colors as needed\n",
    "\n",
    "# Plot the dataframe with colored bars\n",
    "ax = df.plot(kind = 'bar', x = 'Run', y = 'Response Time', color = [color_map.get(region, 'gray') for region in df['Region']], legend = False)\n",
    "\n",
    "# Add legend\n",
    "legend_labels = [pltRectangle((0, 0), 1, 1, color = color_map.get(region, 'gray')) for region in df['Region'].unique()]\n",
    "ax.legend(legend_labels, df['Region'].unique())\n",
    "\n",
    "plt.title('Load Balancing results')\n",
    "plt.xlabel('Run #')\n",
    "plt.ylabel('Response Time')\n",
    "plt.xticks(rotation = 0)\n",
    "\n",
    "average = df['Response Time'].mean()\n",
    "plt.axhline(y = average, color = 'r', linestyle = '--', label = f'Average: {average:.2f}')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='sdk'></a>\n",
    "### üß™ Test the API using the Azure OpenAI Python SDK\n",
    "\n",
    "Repeat the same test using the Python SDK to ensure compatibility. Note that we do not know what region served the response; we only see that we obtained a response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ñ∂Ô∏è Run 1/20:\n"
     ]
    },
    {
     "ename": "InternalServerError",
     "evalue": "Error code: 503",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInternalServerError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 22\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m‚ñ∂Ô∏è Run \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mruns\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     21\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m---> 22\u001b[0m raw_response \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwith_raw_response\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mopenai_model_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m     23\u001b[0m response_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m‚åö \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse_time\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m seconds\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\alexviei\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\openai\\_legacy_response.py:350\u001b[0m, in \u001b[0;36mto_raw_response_wrapper.<locals>.wrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    346\u001b[0m extra_headers[RAW_RESPONSE_HEADER] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrue\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    348\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mextra_headers\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m extra_headers\n\u001b[1;32m--> 350\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cast(LegacyAPIResponse[R], \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mc:\\Users\\alexviei\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\openai\\_utils\\_utils.py:274\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    272\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    273\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[1;32m--> 274\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\alexviei\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\openai\\resources\\chat\\completions.py:668\u001b[0m, in \u001b[0;36mCompletions.create\u001b[1;34m(self, messages, model, frequency_penalty, function_call, functions, logit_bias, logprobs, max_tokens, n, parallel_tool_calls, presence_penalty, response_format, seed, service_tier, stop, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[0;32m    633\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    634\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[0;32m    635\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    665\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[0;32m    666\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[0;32m    667\u001b[0m     validate_response_format(response_format)\n\u001b[1;32m--> 668\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    669\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    670\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    671\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m    672\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    673\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    674\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    675\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    676\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    677\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    678\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    679\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    680\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    681\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparallel_tool_calls\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    682\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    683\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    684\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    685\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mservice_tier\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    686\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    687\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    688\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    689\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    690\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    691\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    692\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    693\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    694\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    695\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    696\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    697\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    698\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    699\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[0;32m    700\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    701\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    702\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    703\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    704\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\alexviei\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\openai\\_base_client.py:1260\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[1;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1246\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[0;32m   1247\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1248\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1255\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1256\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m   1257\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[0;32m   1258\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[0;32m   1259\u001b[0m     )\n\u001b[1;32m-> 1260\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mc:\\Users\\alexviei\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\openai\\_base_client.py:937\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    928\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[0;32m    929\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    930\u001b[0m     cast_to: Type[ResponseT],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    935\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    936\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m--> 937\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    938\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    939\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    940\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    941\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    942\u001b[0m \u001b[43m        \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    943\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\alexviei\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\openai\\_base_client.py:1026\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1024\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m retries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_retry(err\u001b[38;5;241m.\u001b[39mresponse):\n\u001b[0;32m   1025\u001b[0m     err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m-> 1026\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retry_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1027\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1028\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1029\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1030\u001b[0m \u001b[43m        \u001b[49m\u001b[43merr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1031\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1032\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1033\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1035\u001b[0m \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[0;32m   1036\u001b[0m \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[0;32m   1037\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mis_closed:\n",
      "File \u001b[1;32mc:\\Users\\alexviei\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\openai\\_base_client.py:1075\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[1;34m(self, options, cast_to, remaining_retries, response_headers, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1071\u001b[0m \u001b[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[0;32m   1072\u001b[0m \u001b[38;5;66;03m# different thread if necessary.\u001b[39;00m\n\u001b[0;32m   1073\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(timeout)\n\u001b[1;32m-> 1075\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1076\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1077\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1078\u001b[0m \u001b[43m    \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1079\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1080\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1081\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\alexviei\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\openai\\_base_client.py:1026\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1024\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m retries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_retry(err\u001b[38;5;241m.\u001b[39mresponse):\n\u001b[0;32m   1025\u001b[0m     err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m-> 1026\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retry_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1027\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1028\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1029\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1030\u001b[0m \u001b[43m        \u001b[49m\u001b[43merr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1031\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1032\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1033\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1035\u001b[0m \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[0;32m   1036\u001b[0m \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[0;32m   1037\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mis_closed:\n",
      "File \u001b[1;32mc:\\Users\\alexviei\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\openai\\_base_client.py:1075\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[1;34m(self, options, cast_to, remaining_retries, response_headers, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1071\u001b[0m \u001b[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[0;32m   1072\u001b[0m \u001b[38;5;66;03m# different thread if necessary.\u001b[39;00m\n\u001b[0;32m   1073\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(timeout)\n\u001b[1;32m-> 1075\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1076\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1077\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1078\u001b[0m \u001b[43m    \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1079\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1080\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1081\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\alexviei\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\openai\\_base_client.py:1041\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1038\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m   1040\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1041\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1043\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[0;32m   1044\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[0;32m   1045\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1049\u001b[0m     retries_taken\u001b[38;5;241m=\u001b[39moptions\u001b[38;5;241m.\u001b[39mget_max_retries(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_retries) \u001b[38;5;241m-\u001b[39m retries,\n\u001b[0;32m   1050\u001b[0m )\n",
      "\u001b[1;31mInternalServerError\u001b[0m: Error code: 503"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "runs = 20\n",
    "sleep_time_ms = 100\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    azure_endpoint = apim_resource_gateway_url,  # type: ignore\n",
    "    api_key = apim_subscription_key,\n",
    "    api_version = openai_api_version\n",
    ")\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a sarcastic, unhelpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Can you tell me the time, please?\"}\n",
    "]\n",
    "\n",
    "for i in range(runs):\n",
    "    print(f\"‚ñ∂Ô∏è Run {i+1}/{runs}:\")\n",
    "\n",
    "    start_time = time.time()\n",
    "    raw_response = client.chat.completions.with_raw_response.create(model = openai_model_name, messages = messages) # type: ignore\n",
    "    response_time = time.time() - start_time\n",
    "    print(f\"‚åö {response_time:.2f} seconds\")\n",
    "    print(f\"x-ms-region: \\x1b[1;32m{raw_response.headers.get(\"x-ms-region\")}\\x1b[0m\") # this header is useful to determine the region of the backend that served the request\n",
    "    response = raw_response.parse()\n",
    "    if response.usage:\n",
    "        print(f\"Token usage: Total tokens: {response.usage.total_tokens} (Prompt tokens: {response.usage.prompt_tokens} & Completion tokens: {response.usage.completion_tokens})\")\n",
    "    print(f\"üí¨ {response.choices[0].message.content}\\n\")\n",
    "\n",
    "    time.sleep(sleep_time_ms/1000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='clean'></a>\n",
    "### üóëÔ∏è Clean up resources\n",
    "\n",
    "When you're finished with the lab, you should remove all your deployed resources from Azure to avoid extra charges and keep your Azure subscription uncluttered.\n",
    "Use the [clean-up-resources notebook](clean-up-resources.ipynb) for that."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
