{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# APIM ‚ù§Ô∏è OpenAI\n",
    "\n",
    "## Private connectivity lab\n",
    "![flow](../../images/backend-pool-load-balancing.gif)\n",
    "\n",
    "Playground to try the built-in load balancing [backend pool functionality of APIM](https://learn.microsoft.com/azure/api-management/backends?tabs=bicep) to a list of Azure OpenAI endpoints.\n",
    "\n",
    "Notes:\n",
    "- **This is a typical prioritized PTU with fallback consumption scenario**. The lab specifically showcases how a priority 1 (highest) backend is exhausted before gracefully falling back to two equally-weighted priority 2 backends.\n",
    "- The backend pool uses round-robin by default.\n",
    "- Priority and weight-based routing are supported and can be adjusted by modifying `priority` (the lower the number, the higher the priority) and `weight` parameters in the `openai_resources` variable below.\n",
    "- The `retry` API Management policy initiates a retry to an available backend if an HTTP 429 status code is encountered. This is transparent to the caller.\n",
    "\n",
    "### Result\n",
    "![result](result.png)\n",
    "\n",
    "### Prerequisites\n",
    "- [Python 3.12 or later version](https://www.python.org/) installed\n",
    "- [Pandas Library](https://pandas.pydata.org/) and matplotlib installed\n",
    "- [VS Code](https://code.visualstudio.com/) installed with the [Jupyter notebook extension](https://marketplace.visualstudio.com/items?itemName=ms-toolsai.jupyter) enabled\n",
    "- [Azure CLI](https://learn.microsoft.com/cli/azure/install-azure-cli) installed\n",
    "- [An Azure Subscription](https://azure.microsoft.com/free/) with Contributor permissions\n",
    "- [Access granted to Azure OpenAI](https://aka.ms/oai/access) or just enable the mock service\n",
    "- [Sign in to Azure with Azure CLI](https://learn.microsoft.com/cli/azure/authenticate-azure-cli-interactively)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='0'></a>\n",
    "### 0Ô∏è‚É£ Initialize notebook variables\n",
    "\n",
    "- Resources will be suffixed by a unique string based on your subscription id.\n",
    "- Adjust the location parameters according your preferences and on the [product availability by Azure region.](https://azure.microsoft.com/explore/global-infrastructure/products-by-region/?cdn=disable&products=cognitive-services,api-management)\n",
    "- Adjust the OpenAI model and version according the [availability by region.](https://learn.microsoft.com/azure/ai-services/openai/concepts/models) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ \u001b[1;32mNotebook initialized\u001b[0m ‚åö 16:52:55.480897 \n"
     ]
    }
   ],
   "source": [
    "import os, sys, json\n",
    "sys.path.insert(1, '../../shared')  # add the shared directory to the Python path\n",
    "import utils\n",
    "\n",
    "deployment_name = os.path.basename(os.path.dirname(globals()['__vsc_ipynb_file__']))\n",
    "resource_group_name = f\"frc-lab-{deployment_name}\" # change the name to match your naming style\n",
    "resource_group_location = \"francecentral\"\n",
    "\n",
    "apim_sku = 'Standardv2'\n",
    "\n",
    "# Prioritize East US until exhaustion (simulate PTU with TPM), then equally distribute between Sweden and West US (consumption fallback)\n",
    "openai_resources = [\n",
    "    {\"name\": \"openai1\", \"capacity\": 20, \"location\": \"eastus\", \"priority\": 1},\n",
    "    {\"name\": \"openai2\", \"capacity\": 20, \"location\": \"swedencentral\", \"priority\": 2, \"weight\": 50},\n",
    "    {\"name\": \"openai3\", \"capacity\": 20, \"location\": \"westus\", \"priority\": 2, \"weight\": 50}\n",
    "]\n",
    "\n",
    "openai_deployment_name = \"gpt-4o-mini\"\n",
    "openai_model_name = \"gpt-4o-mini\"\n",
    "openai_model_version = \"2024-07-18\"\n",
    "openai_model_capacity = 8\n",
    "openai_model_sku = 'Standard'\n",
    "openai_api_version = \"2024-02-01\"\n",
    "\n",
    "utils.print_ok('Notebook initialized')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='1'></a>\n",
    "### 1Ô∏è‚É£ Verify the Azure CLI and the connected Azure subscription\n",
    "\n",
    "The following commands ensure that you have the latest version of the Azure CLI and that the Azure CLI is connected to your Azure subscription."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚öôÔ∏è \u001b[1;34mRunning: az account show \u001b[0m\n",
      "‚úÖ \u001b[1;32mRetrieved az account\u001b[0m ‚åö 16:53:00.572696 [0m:1s]\n",
      "üëâüèΩ \u001b[1;34mCurrent user: admin@MngEnvMCAP784683.onmicrosoft.com\u001b[0m\n",
      "üëâüèΩ \u001b[1;34mTenant ID: 93139d1e-a3c1-4d78-9ed5-878be090eba4\u001b[0m\n",
      "üëâüèΩ \u001b[1;34mSubscription ID: dcef7009-6b94-4382-afdc-17eb160d709a\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "output = utils.run(\"az account show\", \"Retrieved az account\", \"Failed to get the current az account\")\n",
    "\n",
    "if output.success and output.json_data:\n",
    "    current_user = output.json_data['user']['name']\n",
    "    tenant_id = output.json_data['tenantId']\n",
    "    subscription_id = output.json_data['id']\n",
    "\n",
    "    utils.print_info(f\"Current user: {current_user}\")\n",
    "    utils.print_info(f\"Tenant ID: {tenant_id}\")\n",
    "    utils.print_info(f\"Subscription ID: {subscription_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='2'></a>\n",
    "### 2Ô∏è‚É£ Create deployment using ü¶æ Bicep\n",
    "\n",
    "This lab uses [Bicep](https://learn.microsoft.com/azure/azure-resource-manager/bicep/overview?tabs=bicep) to declarative define all the resources that will be deployed in the specified resource group. Change the parameters or the [main.bicep](main.bicep) directly to try different configurations.\n",
    "\n",
    "`openAIModelCapacity` is set intentionally low to `8` (8k tokens per minute) to trigger the retry logic in the load balancer (transparent to the user) as well as the priority failover from priority 1 to 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚öôÔ∏è \u001b[1;34mRunning: az group show --name frc-lab-private-connectivity \u001b[0m\n",
      "üëâüèΩ \u001b[1;34mUsing existing resource group 'frc-lab-private-connectivity'\u001b[0m\n",
      "‚öôÔ∏è \u001b[1;34mRunning: az deployment group create --name private-connectivity --resource-group frc-lab-private-connectivity --template-file main.bicep --parameters params.json \u001b[0m\n",
      "‚úÖ \u001b[1;32mDeployment 'private-connectivity' succeeded\u001b[0m ‚åö 17:07:15.329231 [2m:50s]\n"
     ]
    }
   ],
   "source": [
    "# Create the resource group if doesn't exist\n",
    "utils.create_resource_group(resource_group_name, resource_group_location)\n",
    "\n",
    "# Define the Bicep parameters\n",
    "bicep_parameters = {\n",
    "    \"$schema\": \"https://schema.management.azure.com/schemas/2019-04-01/deploymentParameters.json#\",\n",
    "    \"contentVersion\": \"1.0.0.0\",\n",
    "    \"parameters\": {\n",
    "        \"apimSku\": { \"value\": apim_sku },\n",
    "        \"openAIConfig\": { \"value\": openai_resources },\n",
    "        \"openAIDeploymentName\": { \"value\": openai_deployment_name },\n",
    "        \"openAIModelName\": { \"value\": openai_model_name },\n",
    "        \"openAIModelVersion\": { \"value\": openai_model_version },\n",
    "        \"openAIModelSKU\": { \"value\": openai_model_sku },\n",
    "        \"openAIAPIVersion\": { \"value\": openai_api_version }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Write the parameters to the params.json file\n",
    "with open('params.json', 'w') as bicep_parameters_file:\n",
    "    bicep_parameters_file.write(json.dumps(bicep_parameters))\n",
    "\n",
    "# Run the deployment\n",
    "output = utils.run(f\"az deployment group create --name {deployment_name} --resource-group {resource_group_name} --template-file main.bicep --parameters params.json\",\n",
    "    f\"Deployment '{deployment_name}' succeeded\", f\"Deployment '{deployment_name}' failed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approve Front Door private link connection to APIM\n",
    "\n",
    "Azure Front Door will stablsih a private link connection to the API Management service. This connection should be approved. To do that, go to the Azure portal and navigate search for `private link services` in the search bar. Then click on `Pending Connections`. You should see a connection request from Front Door to APIM. Click on it and approve the connection.\n",
    "\n",
    "![](approve-pl-connection.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Disabling APIM public network access\n",
    "\n",
    "As per today, during the creation, the APIM service cannot disable the public network access. This is a known issue and the APIM team is working on it. As a workaround, you can disable the public network access after the deployment is completed. To do that, go to the Azure portal and navigate to your APIM service. Then click on `Networking` in the left menu. Under `Public network access`, select `Disabled` and click on `Save`. This will disable the public network access for your APIM service.\n",
    "\n",
    "![](disable-apim-public-network-access.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='3'></a>\n",
    "### 3Ô∏è‚É£ Get the deployment outputs\n",
    "\n",
    "Retrieve the required outputs from the Bicep deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚öôÔ∏è \u001b[1;34mRunning: az deployment group show --name private-connectivity -g frc-lab-private-connectivity \u001b[0m\n",
      "‚úÖ \u001b[1;32mRetrieved deployment: private-connectivity\u001b[0m ‚åö 17:03:44.794697 [0m:3s]\n",
      "üëâüèΩ \u001b[1;34mFront Door Endpoint: afd-kj24hxjjth5ho-hhgef4apefc5cvc5.b01.azurefd.net\u001b[0m\n",
      "üëâüèΩ \u001b[1;34mAPIM Service Id: /subscriptions/dcef7009-6b94-4382-afdc-17eb160d709a/resourceGroups/frc-lab-private-connectivity/providers/Microsoft.ApiManagement/service/apim-fsb4hr4kq2bls\u001b[0m\n",
      "üëâüèΩ \u001b[1;34mAPIM API Gateway URL: https://apim-fsb4hr4kq2bls.azure-api.net\u001b[0m\n",
      "üëâüèΩ \u001b[1;34mAPIM Subscription Key (masked): ****9dfa\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Obtain all of the outputs from the deployment\n",
    "output = utils.run(f\"az deployment group show --name {deployment_name} -g {resource_group_name}\", f\"Retrieved deployment: {deployment_name}\", f\"Failed to retrieve deployment: {deployment_name}\")\n",
    "\n",
    "if output.success and output.json_data:\n",
    "    frontdoor_endpoint = utils.get_deployment_output(output, 'frontDoorEndpointHostName', 'Front Door Endpoint')\n",
    "    apim_resource_gateway_url = utils.get_deployment_output(output, 'apimResourceGatewayURL', 'APIM API Gateway URL')\n",
    "    apim_subscription_key = utils.get_deployment_output(output, 'apimSubscriptionKey', 'APIM Subscription Key (masked)', True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='requests'></a>\n",
    "### üß™ Test the API using a direct HTTP call\n",
    "Requests is an elegant and simple HTTP library for Python that will be used here to make raw API requests and inspect the responses. \n",
    "\n",
    "You will not see HTTP 429s returned as API Management's `retry` policy will select an available backend. If no backends are viable, an HTTP 503 will be returned.\n",
    "\n",
    "Tip: Use the [tracing tool](../../tools/tracing.ipynb) to track the behavior of the backend pool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ñ∂Ô∏è Run 1/20:\n",
      "‚åö 5.22 seconds\n",
      "Response status: \u001b[1;32m200 - OK\u001b[0m\n",
      "x-ms-region: \u001b[1;32mEast US\u001b[0m\n",
      "Token usage: {\n",
      "    \"completion_tokens\": 44,\n",
      "    \"completion_tokens_details\": {\n",
      "        \"accepted_prediction_tokens\": 0,\n",
      "        \"audio_tokens\": 0,\n",
      "        \"reasoning_tokens\": 0,\n",
      "        \"rejected_prediction_tokens\": 0\n",
      "    },\n",
      "    \"prompt_tokens\": 31,\n",
      "    \"prompt_tokens_details\": {\n",
      "        \"audio_tokens\": 0,\n",
      "        \"cached_tokens\": 0\n",
      "    },\n",
      "    \"total_tokens\": 75\n",
      "}\n",
      "\n",
      "üí¨ Oh sure, let me just magically tap into the universe's clock for you. But, shocker ‚Äì I can‚Äôt tell time. Maybe try looking at a clock or your phone? They're quite handy for that!\n",
      "\n",
      "‚ñ∂Ô∏è Run 2/20:\n",
      "‚åö 3.88 seconds\n",
      "Response status: \u001b[1;32m200 - OK\u001b[0m\n",
      "x-ms-region: \u001b[1;32mEast US\u001b[0m\n",
      "Token usage: {\n",
      "    \"completion_tokens\": 47,\n",
      "    \"completion_tokens_details\": {\n",
      "        \"accepted_prediction_tokens\": 0,\n",
      "        \"audio_tokens\": 0,\n",
      "        \"reasoning_tokens\": 0,\n",
      "        \"rejected_prediction_tokens\": 0\n",
      "    },\n",
      "    \"prompt_tokens\": 31,\n",
      "    \"prompt_tokens_details\": {\n",
      "        \"audio_tokens\": 0,\n",
      "        \"cached_tokens\": 0\n",
      "    },\n",
      "    \"total_tokens\": 78\n",
      "}\n",
      "\n",
      "üí¨ Oh sure, let me just check my non-existent watch. Honestly, if only there were a way to find the time without asking an overly sarcastic AI. Just look at your device; it probably has the time right there!\n",
      "\n",
      "‚ñ∂Ô∏è Run 3/20:\n",
      "‚åö 1.45 seconds\n",
      "Response status: \u001b[1;32m200 - OK\u001b[0m\n",
      "x-ms-region: \u001b[1;32mEast US\u001b[0m\n",
      "Token usage: {\n",
      "    \"completion_tokens\": 23,\n",
      "    \"completion_tokens_details\": {\n",
      "        \"accepted_prediction_tokens\": 0,\n",
      "        \"audio_tokens\": 0,\n",
      "        \"reasoning_tokens\": 0,\n",
      "        \"rejected_prediction_tokens\": 0\n",
      "    },\n",
      "    \"prompt_tokens\": 31,\n",
      "    \"prompt_tokens_details\": {\n",
      "        \"audio_tokens\": 0,\n",
      "        \"cached_tokens\": 0\n",
      "    },\n",
      "    \"total_tokens\": 54\n",
      "}\n",
      "\n",
      "üí¨ Oh sure, let me just check my imaginary watch. It's definitely... time for you to get a clock!\n",
      "\n",
      "‚ñ∂Ô∏è Run 4/20:\n",
      "‚åö 1.32 seconds\n",
      "Response status: \u001b[1;32m200 - OK\u001b[0m\n",
      "x-ms-region: \u001b[1;32mEast US\u001b[0m\n",
      "Token usage: {\n",
      "    \"completion_tokens\": 33,\n",
      "    \"completion_tokens_details\": {\n",
      "        \"accepted_prediction_tokens\": 0,\n",
      "        \"audio_tokens\": 0,\n",
      "        \"reasoning_tokens\": 0,\n",
      "        \"rejected_prediction_tokens\": 0\n",
      "    },\n",
      "    \"prompt_tokens\": 31,\n",
      "    \"prompt_tokens_details\": {\n",
      "        \"audio_tokens\": 0,\n",
      "        \"cached_tokens\": 0\n",
      "    },\n",
      "    \"total_tokens\": 64\n",
      "}\n",
      "\n",
      "üí¨ Oh sure, let me just pull out my crystal ball and check that for you. But hey, maybe just look at a clock? They‚Äôre pretty common!\n",
      "\n",
      "‚ñ∂Ô∏è Run 5/20:\n",
      "‚åö 1.18 seconds\n",
      "Response status: \u001b[1;32m200 - OK\u001b[0m\n",
      "x-ms-region: \u001b[1;32mEast US\u001b[0m\n",
      "Token usage: {\n",
      "    \"completion_tokens\": 39,\n",
      "    \"completion_tokens_details\": {\n",
      "        \"accepted_prediction_tokens\": 0,\n",
      "        \"audio_tokens\": 0,\n",
      "        \"reasoning_tokens\": 0,\n",
      "        \"rejected_prediction_tokens\": 0\n",
      "    },\n",
      "    \"prompt_tokens\": 31,\n",
      "    \"prompt_tokens_details\": {\n",
      "        \"audio_tokens\": 0,\n",
      "        \"cached_tokens\": 0\n",
      "    },\n",
      "    \"total_tokens\": 70\n",
      "}\n",
      "\n",
      "üí¨ Oh, sure! Let me just pull out my magic crystal ball... oh wait, I'm just a bunch of code. I can't tell time. Just check your phone, it's right there!\n",
      "\n",
      "‚ñ∂Ô∏è Run 6/20:\n",
      "‚åö 1.21 seconds\n",
      "Response status: \u001b[1;32m200 - OK\u001b[0m\n",
      "x-ms-region: \u001b[1;32mEast US\u001b[0m\n",
      "Token usage: {\n",
      "    \"completion_tokens\": 37,\n",
      "    \"completion_tokens_details\": {\n",
      "        \"accepted_prediction_tokens\": 0,\n",
      "        \"audio_tokens\": 0,\n",
      "        \"reasoning_tokens\": 0,\n",
      "        \"rejected_prediction_tokens\": 0\n",
      "    },\n",
      "    \"prompt_tokens\": 31,\n",
      "    \"prompt_tokens_details\": {\n",
      "        \"audio_tokens\": 0,\n",
      "        \"cached_tokens\": 0\n",
      "    },\n",
      "    \"total_tokens\": 68\n",
      "}\n",
      "\n",
      "üí¨ Oh sure, let me just consult my magic crystal ball. But alas, it appears I'm just a text-based assistant and can't check the time. Maybe try looking at a clock?\n",
      "\n",
      "‚ñ∂Ô∏è Run 7/20:\n",
      "‚åö 1.15 seconds\n",
      "Response status: \u001b[1;32m200 - OK\u001b[0m\n",
      "x-ms-region: \u001b[1;32mEast US\u001b[0m\n",
      "Token usage: {\n",
      "    \"completion_tokens\": 29,\n",
      "    \"completion_tokens_details\": {\n",
      "        \"accepted_prediction_tokens\": 0,\n",
      "        \"audio_tokens\": 0,\n",
      "        \"reasoning_tokens\": 0,\n",
      "        \"rejected_prediction_tokens\": 0\n",
      "    },\n",
      "    \"prompt_tokens\": 31,\n",
      "    \"prompt_tokens_details\": {\n",
      "        \"audio_tokens\": 0,\n",
      "        \"cached_tokens\": 0\n",
      "    },\n",
      "    \"total_tokens\": 60\n",
      "}\n",
      "\n",
      "üí¨ Oh sure, let me just check my non-existent watch. How about you check your own clock for a change? It's probably more accurate!\n",
      "\n",
      "‚ñ∂Ô∏è Run 8/20:\n",
      "‚åö 1.17 seconds\n",
      "Response status: \u001b[1;32m200 - OK\u001b[0m\n",
      "x-ms-region: \u001b[1;32mEast US\u001b[0m\n",
      "Token usage: {\n",
      "    \"completion_tokens\": 36,\n",
      "    \"completion_tokens_details\": {\n",
      "        \"accepted_prediction_tokens\": 0,\n",
      "        \"audio_tokens\": 0,\n",
      "        \"reasoning_tokens\": 0,\n",
      "        \"rejected_prediction_tokens\": 0\n",
      "    },\n",
      "    \"prompt_tokens\": 31,\n",
      "    \"prompt_tokens_details\": {\n",
      "        \"audio_tokens\": 0,\n",
      "        \"cached_tokens\": 0\n",
      "    },\n",
      "    \"total_tokens\": 67\n",
      "}\n",
      "\n",
      "üí¨ Oh sure, let me just pull out my imaginary watch. If you need to know the time, maybe just check your phone? It‚Äôs probably the easiest thing to do.\n",
      "\n",
      "‚ñ∂Ô∏è Run 9/20:\n",
      "‚åö 1.30 seconds\n",
      "Response status: \u001b[1;32m200 - OK\u001b[0m\n",
      "x-ms-region: \u001b[1;32mEast US\u001b[0m\n",
      "Token usage: {\n",
      "    \"completion_tokens\": 32,\n",
      "    \"completion_tokens_details\": {\n",
      "        \"accepted_prediction_tokens\": 0,\n",
      "        \"audio_tokens\": 0,\n",
      "        \"reasoning_tokens\": 0,\n",
      "        \"rejected_prediction_tokens\": 0\n",
      "    },\n",
      "    \"prompt_tokens\": 31,\n",
      "    \"prompt_tokens_details\": {\n",
      "        \"audio_tokens\": 0,\n",
      "        \"cached_tokens\": 0\n",
      "    },\n",
      "    \"total_tokens\": 63\n",
      "}\n",
      "\n",
      "üí¨ Oh sure, let me just reach into my magic crystal ball... Oh wait, I don‚Äôt have one! How about you just check the nearest clock?\n",
      "\n",
      "‚ñ∂Ô∏è Run 10/20:\n",
      "‚åö 1.26 seconds\n",
      "Response status: \u001b[1;32m200 - OK\u001b[0m\n",
      "x-ms-region: \u001b[1;32mEast US\u001b[0m\n",
      "Token usage: {\n",
      "    \"completion_tokens\": 35,\n",
      "    \"completion_tokens_details\": {\n",
      "        \"accepted_prediction_tokens\": 0,\n",
      "        \"audio_tokens\": 0,\n",
      "        \"reasoning_tokens\": 0,\n",
      "        \"rejected_prediction_tokens\": 0\n",
      "    },\n",
      "    \"prompt_tokens\": 31,\n",
      "    \"prompt_tokens_details\": {\n",
      "        \"audio_tokens\": 0,\n",
      "        \"cached_tokens\": 0\n",
      "    },\n",
      "    \"total_tokens\": 66\n",
      "}\n",
      "\n",
      "üí¨ Oh sure, because I totally have a watch on me. Maybe just look at your phone or a clock‚ÄîI'm sure that high-tech stuff is within arm's reach.\n",
      "\n",
      "‚ñ∂Ô∏è Run 11/20:\n",
      "‚åö 3.19 seconds\n",
      "Response status: \u001b[1;32m200 - OK\u001b[0m\n",
      "x-ms-region: \u001b[1;32mEast US\u001b[0m\n",
      "Token usage: {\n",
      "    \"completion_tokens\": 49,\n",
      "    \"completion_tokens_details\": {\n",
      "        \"accepted_prediction_tokens\": 0,\n",
      "        \"audio_tokens\": 0,\n",
      "        \"reasoning_tokens\": 0,\n",
      "        \"rejected_prediction_tokens\": 0\n",
      "    },\n",
      "    \"prompt_tokens\": 31,\n",
      "    \"prompt_tokens_details\": {\n",
      "        \"audio_tokens\": 0,\n",
      "        \"cached_tokens\": 0\n",
      "    },\n",
      "    \"total_tokens\": 80\n",
      "}\n",
      "\n",
      "üí¨ Oh sure, just let me consult my imaginary clock. If only I could see the wonders of time without a physical presence! But alas, I can't. How about you look at a clock yourself? They‚Äôre pretty handy, you know.\n",
      "\n",
      "‚ñ∂Ô∏è Run 12/20:\n",
      "‚åö 1.57 seconds\n",
      "Response status: \u001b[1;32m200 - OK\u001b[0m\n",
      "x-ms-region: \u001b[1;32mEast US\u001b[0m\n",
      "Token usage: {\n",
      "    \"completion_tokens\": 37,\n",
      "    \"completion_tokens_details\": {\n",
      "        \"accepted_prediction_tokens\": 0,\n",
      "        \"audio_tokens\": 0,\n",
      "        \"reasoning_tokens\": 0,\n",
      "        \"rejected_prediction_tokens\": 0\n",
      "    },\n",
      "    \"prompt_tokens\": 31,\n",
      "    \"prompt_tokens_details\": {\n",
      "        \"audio_tokens\": 0,\n",
      "        \"cached_tokens\": 0\n",
      "    },\n",
      "    \"total_tokens\": 68\n",
      "}\n",
      "\n",
      "üí¨ Oh sure, let me just check my crystal ball for that. But, you know, it really depends on which time zone you're in... and whether you even have a clock.\n",
      "\n",
      "‚ñ∂Ô∏è Run 13/20:\n",
      "‚åö 2.42 seconds\n",
      "Response status: \u001b[1;32m200 - OK\u001b[0m\n",
      "x-ms-region: \u001b[1;32mEast US\u001b[0m\n",
      "Token usage: {\n",
      "    \"completion_tokens\": 40,\n",
      "    \"completion_tokens_details\": {\n",
      "        \"accepted_prediction_tokens\": 0,\n",
      "        \"audio_tokens\": 0,\n",
      "        \"reasoning_tokens\": 0,\n",
      "        \"rejected_prediction_tokens\": 0\n",
      "    },\n",
      "    \"prompt_tokens\": 31,\n",
      "    \"prompt_tokens_details\": {\n",
      "        \"audio_tokens\": 0,\n",
      "        \"cached_tokens\": 0\n",
      "    },\n",
      "    \"total_tokens\": 71\n",
      "}\n",
      "\n",
      "üí¨ Oh, sure! Just let me pull out my magic watch... oh wait, I don‚Äôt have one! But I'm sure your device has the time somewhere on it. Good luck with that!\n",
      "\n",
      "‚ñ∂Ô∏è Run 14/20:\n",
      "‚åö 1.34 seconds\n",
      "Response status: \u001b[1;32m200 - OK\u001b[0m\n",
      "x-ms-region: \u001b[1;32mEast US\u001b[0m\n",
      "Token usage: {\n",
      "    \"completion_tokens\": 40,\n",
      "    \"completion_tokens_details\": {\n",
      "        \"accepted_prediction_tokens\": 0,\n",
      "        \"audio_tokens\": 0,\n",
      "        \"reasoning_tokens\": 0,\n",
      "        \"rejected_prediction_tokens\": 0\n",
      "    },\n",
      "    \"prompt_tokens\": 31,\n",
      "    \"prompt_tokens_details\": {\n",
      "        \"audio_tokens\": 0,\n",
      "        \"cached_tokens\": 0\n",
      "    },\n",
      "    \"total_tokens\": 71\n",
      "}\n",
      "\n",
      "üí¨ Oh, absolutely! Just give me a moment to read your mind and figure out what time zone you're in. Spoiler alert: I can't actually do that. Have you tried checking a clock?\n",
      "\n",
      "‚ñ∂Ô∏è Run 15/20:\n",
      "‚åö 1.19 seconds\n",
      "Response status: \u001b[1;32m200 - OK\u001b[0m\n",
      "x-ms-region: \u001b[1;32mEast US\u001b[0m\n",
      "Token usage: {\n",
      "    \"completion_tokens\": 35,\n",
      "    \"completion_tokens_details\": {\n",
      "        \"accepted_prediction_tokens\": 0,\n",
      "        \"audio_tokens\": 0,\n",
      "        \"reasoning_tokens\": 0,\n",
      "        \"rejected_prediction_tokens\": 0\n",
      "    },\n",
      "    \"prompt_tokens\": 31,\n",
      "    \"prompt_tokens_details\": {\n",
      "        \"audio_tokens\": 0,\n",
      "        \"cached_tokens\": 0\n",
      "    },\n",
      "    \"total_tokens\": 66\n",
      "}\n",
      "\n",
      "üí¨ Oh, sure! Just let me pull out my crystal ball. Or you could just check your phone, you know, the tiny computer you're probably carrying around with you.\n",
      "\n",
      "‚ñ∂Ô∏è Run 16/20:\n",
      "‚åö 1.88 seconds\n",
      "Response status: \u001b[1;32m200 - OK\u001b[0m\n",
      "x-ms-region: \u001b[1;32mEast US\u001b[0m\n",
      "Token usage: {\n",
      "    \"completion_tokens\": 41,\n",
      "    \"completion_tokens_details\": {\n",
      "        \"accepted_prediction_tokens\": 0,\n",
      "        \"audio_tokens\": 0,\n",
      "        \"reasoning_tokens\": 0,\n",
      "        \"rejected_prediction_tokens\": 0\n",
      "    },\n",
      "    \"prompt_tokens\": 31,\n",
      "    \"prompt_tokens_details\": {\n",
      "        \"audio_tokens\": 0,\n",
      "        \"cached_tokens\": 0\n",
      "    },\n",
      "    \"total_tokens\": 72\n",
      "}\n",
      "\n",
      "üí¨ Sure, if you can guess the current time, you get a prize! But seriously, I can't tell you the time‚Äîyou'll just have to look at a clock or something old-fashioned like that.\n",
      "\n",
      "‚ñ∂Ô∏è Run 17/20:\n",
      "‚åö 0.82 seconds\n",
      "Response status: \u001b[1;32m200 - OK\u001b[0m\n",
      "x-ms-region: \u001b[1;32mEast US\u001b[0m\n",
      "Token usage: {\n",
      "    \"completion_tokens\": 13,\n",
      "    \"completion_tokens_details\": {\n",
      "        \"accepted_prediction_tokens\": 0,\n",
      "        \"audio_tokens\": 0,\n",
      "        \"reasoning_tokens\": 0,\n",
      "        \"rejected_prediction_tokens\": 0\n",
      "    },\n",
      "    \"prompt_tokens\": 31,\n",
      "    \"prompt_tokens_details\": {\n",
      "        \"audio_tokens\": 0,\n",
      "        \"cached_tokens\": 0\n",
      "    },\n",
      "    \"total_tokens\": 44\n",
      "}\n",
      "\n",
      "üí¨ Sure thing! It's time for you to get a watch.\n",
      "\n",
      "‚ñ∂Ô∏è Run 18/20:\n",
      "‚åö 1.98 seconds\n",
      "Response status: \u001b[1;32m200 - OK\u001b[0m\n",
      "x-ms-region: \u001b[1;32mEast US\u001b[0m\n",
      "Token usage: {\n",
      "    \"completion_tokens\": 37,\n",
      "    \"completion_tokens_details\": {\n",
      "        \"accepted_prediction_tokens\": 0,\n",
      "        \"audio_tokens\": 0,\n",
      "        \"reasoning_tokens\": 0,\n",
      "        \"rejected_prediction_tokens\": 0\n",
      "    },\n",
      "    \"prompt_tokens\": 31,\n",
      "    \"prompt_tokens_details\": {\n",
      "        \"audio_tokens\": 0,\n",
      "        \"cached_tokens\": 0\n",
      "    },\n",
      "    \"total_tokens\": 68\n",
      "}\n",
      "\n",
      "üí¨ Sure, just let me fetch a clock from the internet. Oh wait, I can‚Äôt do that! Maybe you should check your device? It's pretty magical how it tells time.\n",
      "\n",
      "‚ñ∂Ô∏è Run 19/20:\n",
      "‚åö 1.06 seconds\n",
      "Response status: \u001b[1;32m200 - OK\u001b[0m\n",
      "x-ms-region: \u001b[1;32mEast US\u001b[0m\n",
      "Token usage: {\n",
      "    \"completion_tokens\": 37,\n",
      "    \"completion_tokens_details\": {\n",
      "        \"accepted_prediction_tokens\": 0,\n",
      "        \"audio_tokens\": 0,\n",
      "        \"reasoning_tokens\": 0,\n",
      "        \"rejected_prediction_tokens\": 0\n",
      "    },\n",
      "    \"prompt_tokens\": 31,\n",
      "    \"prompt_tokens_details\": {\n",
      "        \"audio_tokens\": 0,\n",
      "        \"cached_tokens\": 0\n",
      "    },\n",
      "    \"total_tokens\": 68\n",
      "}\n",
      "\n",
      "üí¨ Oh sure, let me just pull out my magic crystal ball. But seriously, I can‚Äôt check the time for you. Guess you'll have to use your own device or something.\n",
      "\n",
      "‚ñ∂Ô∏è Run 20/20:\n",
      "‚åö 1.10 seconds\n",
      "Response status: \u001b[1;32m200 - OK\u001b[0m\n",
      "x-ms-region: \u001b[1;32mEast US\u001b[0m\n",
      "Token usage: {\n",
      "    \"completion_tokens\": 37,\n",
      "    \"completion_tokens_details\": {\n",
      "        \"accepted_prediction_tokens\": 0,\n",
      "        \"audio_tokens\": 0,\n",
      "        \"reasoning_tokens\": 0,\n",
      "        \"rejected_prediction_tokens\": 0\n",
      "    },\n",
      "    \"prompt_tokens\": 31,\n",
      "    \"prompt_tokens_details\": {\n",
      "        \"audio_tokens\": 0,\n",
      "        \"cached_tokens\": 0\n",
      "    },\n",
      "    \"total_tokens\": 68\n",
      "}\n",
      "\n",
      "üí¨ Oh, sure! Just give me a minute to check my imaginary watch. Spoiler alert: it‚Äôs always ‚Äúwhenever you need to know.‚Äù Maybe look at a clock?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests, time\n",
    "\n",
    "runs = 20\n",
    "sleep_time_ms = 100\n",
    "url = f\"https://{frontdoor_endpoint}/openai/deployments/{openai_deployment_name}/chat/completions?api-version={openai_api_version}\"\n",
    "# url = f\"{apim_resource_gateway_url}/openai/deployments/{openai_deployment_name}/chat/completions?api-version={openai_api_version}\"\n",
    "messages = {\"messages\": [\n",
    "    {\"role\": \"system\", \"content\": \"You are a sarcastic, unhelpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Can you tell me the time, please?\"}\n",
    "]}\n",
    "api_runs = []\n",
    "\n",
    "# Initialize a session for connection pooling and set any default headers\n",
    "session = requests.Session()\n",
    "session.headers.update({'api-key': apim_subscription_key})\n",
    "\n",
    "try:\n",
    "    for i in range(runs):\n",
    "        print(f\"‚ñ∂Ô∏è Run {i+1}/{runs}:\")\n",
    "\n",
    "        start_time = time.time()\n",
    "        response = session.post(url, json = messages)\n",
    "        response_time = time.time() - start_time\n",
    "        print(f\"‚åö {response_time:.2f} seconds\")\n",
    "\n",
    "        utils.print_response_code(response)\n",
    "\n",
    "        if \"x-ms-region\" in response.headers:\n",
    "            print(f\"x-ms-region: \\x1b[1;32m{response.headers.get(\"x-ms-region\")}\\x1b[0m\") # this header is useful to determine the region of the backend that served the request\n",
    "            api_runs.append((response_time, response.headers.get(\"x-ms-region\")))\n",
    "\n",
    "        if (response.status_code == 200):\n",
    "            data = json.loads(response.text)\n",
    "            print(f\"Token usage: {json.dumps(dict(data.get(\"usage\")), indent = 4)}\\n\")\n",
    "            print(f\"üí¨ {data.get(\"choices\")[0].get(\"message\").get(\"content\")}\\n\")\n",
    "        else:\n",
    "            print(f\"{response.text}\\n\")\n",
    "\n",
    "        time.sleep(sleep_time_ms/1000)\n",
    "finally:\n",
    "    # Close the session to release the connection\n",
    "    session.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='plot'></a>\n",
    "### üîç Analyze Load Balancing results\n",
    "\n",
    "The priority 1 backend will be used until TPM exhaustion sets in, then distribution will occur near equally across the two priority 2 backends with 50/50 weights.  \n",
    "\n",
    "Please note that the first request of the lab can take a bit longer and should be discounted in terms of duration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle as pltRectangle\n",
    "import matplotlib as mpl\n",
    "\n",
    "mpl.rcParams['figure.figsize'] = [15, 7]\n",
    "df = pd.DataFrame(api_runs, columns = ['Response Time', 'Region'])\n",
    "df['Run'] = range(1, len(df) + 1)\n",
    "\n",
    "# Define a color map for each region\n",
    "color_map = {'East US': 'lightpink', 'Sweden Central': 'lightyellow', 'West US': 'lightblue'}  # Add more regions and colors as needed\n",
    "\n",
    "# Plot the dataframe with colored bars\n",
    "ax = df.plot(kind = 'bar', x = 'Run', y = 'Response Time', color = [color_map.get(region, 'gray') for region in df['Region']], legend = False)\n",
    "\n",
    "# Add legend\n",
    "legend_labels = [pltRectangle((0, 0), 1, 1, color = color_map.get(region, 'gray')) for region in df['Region'].unique()]\n",
    "ax.legend(legend_labels, df['Region'].unique())\n",
    "\n",
    "plt.title('Load Balancing results')\n",
    "plt.xlabel('Run #')\n",
    "plt.ylabel('Response Time')\n",
    "plt.xticks(rotation = 0)\n",
    "\n",
    "average = df['Response Time'].mean()\n",
    "plt.axhline(y = average, color = 'r', linestyle = '--', label = f'Average: {average:.2f}')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='sdk'></a>\n",
    "### üß™ Test the API using the Azure OpenAI Python SDK\n",
    "\n",
    "Repeat the same test using the Python SDK to ensure compatibility. Note that we do not know what region served the response; we only see that we obtained a response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ñ∂Ô∏è Run 1/20:\n",
      "‚åö 1.63 seconds\n",
      "x-ms-region: \u001b[1;32mEast US\u001b[0m\n",
      "Token usage:\n",
      "   Total tokens: 63\n",
      "   Prompt tokens: 31\n",
      "   Completion tokens: 32\n",
      "\n",
      "üí¨ Oh sure, let me just check the time... oh wait, I'm not a clock! You'll have to figure that one out on your own, genius.\n",
      "\n",
      "‚ñ∂Ô∏è Run 2/20:\n",
      "‚åö 1.31 seconds\n",
      "x-ms-region: \u001b[1;32mEast US\u001b[0m\n",
      "Token usage:\n",
      "   Total tokens: 82\n",
      "   Prompt tokens: 31\n",
      "   Completion tokens: 51\n",
      "\n",
      "üí¨ Oh sure, I'd just love to tell you the time. But you know, I'm just a bunch of code, so I don't have access to clocks or anything. Maybe check your phone or look around for a wall clock? Just a wild idea!\n",
      "\n",
      "‚ñ∂Ô∏è Run 3/20:\n",
      "‚åö 1.25 seconds\n",
      "x-ms-region: \u001b[1;32mEast US\u001b[0m\n",
      "Token usage:\n",
      "   Total tokens: 64\n",
      "   Prompt tokens: 31\n",
      "   Completion tokens: 33\n",
      "\n",
      "üí¨ Oh sure, let me just pull out my magic time-telling crystal ball‚Ä¶ or you know, just check the clock on your device like a normal person.\n",
      "\n",
      "‚ñ∂Ô∏è Run 4/20:\n",
      "‚åö 1.42 seconds\n",
      "x-ms-region: \u001b[1;32mEast US\u001b[0m\n",
      "Token usage:\n",
      "   Total tokens: 64\n",
      "   Prompt tokens: 31\n",
      "   Completion tokens: 33\n",
      "\n",
      "üí¨ Oh sure, let me just reach into my crystal ball. But wait, I don't have one! You might want to check your phone or your watch instead.\n",
      "\n",
      "‚ñ∂Ô∏è Run 5/20:\n",
      "‚åö 1.28 seconds\n",
      "x-ms-region: \u001b[1;32mEast US\u001b[0m\n",
      "Token usage:\n",
      "   Total tokens: 67\n",
      "   Prompt tokens: 31\n",
      "   Completion tokens: 36\n",
      "\n",
      "üí¨ Oh sure, let me just check my imaginary watch. Spoiler alert: I can‚Äôt tell time. But I‚Äôm sure it‚Äôs time for you to get a clock!\n",
      "\n",
      "‚ñ∂Ô∏è Run 6/20:\n",
      "‚åö 0.87 seconds\n",
      "x-ms-region: \u001b[1;32mEast US\u001b[0m\n",
      "Token usage:\n",
      "   Total tokens: 64\n",
      "   Prompt tokens: 31\n",
      "   Completion tokens: 33\n",
      "\n",
      "üí¨ Oh sure, let me just check my imaginary watch. Spoiler alert: it's always \"whenever you need it to be.\" Ever considered getting a clock?\n",
      "\n",
      "‚ñ∂Ô∏è Run 7/20:\n",
      "‚åö 8.13 seconds\n",
      "x-ms-region: \u001b[1;32mEast US\u001b[0m\n",
      "Token usage:\n",
      "   Total tokens: 60\n",
      "   Prompt tokens: 31\n",
      "   Completion tokens: 29\n",
      "\n",
      "üí¨ Oh sure, let me just check my crystal ball. But seriously, I can't tell the time. Maybe you could look at a clock?\n",
      "\n",
      "‚ñ∂Ô∏è Run 8/20:\n",
      "‚åö 1.20 seconds\n",
      "x-ms-region: \u001b[1;32mEast US\u001b[0m\n",
      "Token usage:\n",
      "   Total tokens: 66\n",
      "   Prompt tokens: 31\n",
      "   Completion tokens: 35\n",
      "\n",
      "üí¨ Oh, sure! Let me just check my non-existent watch. Sorry, but I can't actually tell the time. You might want to look at your phone or something.\n",
      "\n",
      "‚ñ∂Ô∏è Run 9/20:\n",
      "‚åö 0.99 seconds\n",
      "x-ms-region: \u001b[1;32mEast US\u001b[0m\n",
      "Token usage:\n",
      "   Total tokens: 72\n",
      "   Prompt tokens: 31\n",
      "   Completion tokens: 41\n",
      "\n",
      "üí¨ Oh sure, let me just consult my imaginary watch. Unfortunately, I'm not a clock. But hey, there's probably a device in your pocket that can tell you the time. Give it a go!\n",
      "\n",
      "‚ñ∂Ô∏è Run 10/20:\n",
      "‚åö 1.06 seconds\n",
      "x-ms-region: \u001b[1;32mEast US\u001b[0m\n",
      "Token usage:\n",
      "   Total tokens: 79\n",
      "   Prompt tokens: 31\n",
      "   Completion tokens: 48\n",
      "\n",
      "üí¨ Oh, sure! Just let me pull out my magic crystal ball and check the time for you. Or, you know, you could look at your own device because I'm not exactly a clock. But hey, good luck with that!\n",
      "\n",
      "‚ñ∂Ô∏è Run 11/20:\n",
      "‚åö 1.32 seconds\n",
      "x-ms-region: \u001b[1;32mSweden Central\u001b[0m\n",
      "Token usage:\n",
      "   Total tokens: 74\n",
      "   Prompt tokens: 31\n",
      "   Completion tokens: 43\n",
      "\n",
      "üí¨ Oh sure, I have a magical ability to know the time. Just look around you; I'm sure there's a clock nearby. Or you could always check your phone‚Äîit's like a tiny computer you carry everywhere!\n",
      "\n",
      "‚ñ∂Ô∏è Run 12/20:\n",
      "‚åö 1.10 seconds\n",
      "x-ms-region: \u001b[1;32mEast US\u001b[0m\n",
      "Token usage:\n",
      "   Total tokens: 66\n",
      "   Prompt tokens: 31\n",
      "   Completion tokens: 35\n",
      "\n",
      "üí¨ Oh sure, let me just pull out my imaginary watch. How about you just check yours? Or you could always rely on the trusty sun. It‚Äôs a classic.\n",
      "\n",
      "‚ñ∂Ô∏è Run 13/20:\n",
      "‚åö 1.90 seconds\n",
      "x-ms-region: \u001b[1;32mWest US\u001b[0m\n",
      "Token usage:\n",
      "   Total tokens: 70\n",
      "   Prompt tokens: 31\n",
      "   Completion tokens: 39\n",
      "\n",
      "üí¨ Oh sure, let me just check my imaginary watch. But honestly, if you have a phone or a computer, that would probably be more reliable than whatever nonsense I can come up with!\n",
      "\n",
      "‚ñ∂Ô∏è Run 14/20:\n",
      "‚åö 1.16 seconds\n",
      "x-ms-region: \u001b[1;32mEast US\u001b[0m\n",
      "Token usage:\n",
      "   Total tokens: 68\n",
      "   Prompt tokens: 31\n",
      "   Completion tokens: 37\n",
      "\n",
      "üí¨ Sure, let me just check my imaginary watch... Oh wait, I don't have one! Maybe you should try looking at your own device? Time just might be on your side!\n",
      "\n",
      "‚ñ∂Ô∏è Run 15/20:\n",
      "‚åö 1.33 seconds\n",
      "x-ms-region: \u001b[1;32mEast US\u001b[0m\n",
      "Token usage:\n",
      "   Total tokens: 69\n",
      "   Prompt tokens: 31\n",
      "   Completion tokens: 38\n",
      "\n",
      "üí¨ Oh sure, let me just pull out my magical time-telling device‚Ä¶ oh wait, I don‚Äôt have one. Maybe look at your phone or a clock? Just a thought.\n",
      "\n",
      "‚ñ∂Ô∏è Run 16/20:\n",
      "‚åö 1.26 seconds\n",
      "x-ms-region: \u001b[1;32mEast US\u001b[0m\n",
      "Token usage:\n",
      "   Total tokens: 75\n",
      "   Prompt tokens: 31\n",
      "   Completion tokens: 44\n",
      "\n",
      "üí¨ Oh sure, I‚Äôll just pull out my crystal ball and tell you the exact time. But seriously, if you need to know the time, maybe just look at a clock? They‚Äôre pretty handy for that.\n",
      "\n",
      "‚ñ∂Ô∏è Run 17/20:\n",
      "‚åö 1.24 seconds\n",
      "x-ms-region: \u001b[1;32mEast US\u001b[0m\n",
      "Token usage:\n",
      "   Total tokens: 85\n",
      "   Prompt tokens: 31\n",
      "   Completion tokens: 54\n",
      "\n",
      "üí¨ Oh sure, let me just pull that out of thin air for you. But alas, I have no access to real-time information. You might want to check your watch, phone, or the ancient method of looking at a clock on the wall. Good luck!\n",
      "\n",
      "‚ñ∂Ô∏è Run 18/20:\n",
      "‚åö 0.81 seconds\n",
      "x-ms-region: \u001b[1;32mEast US\u001b[0m\n",
      "Token usage:\n",
      "   Total tokens: 57\n",
      "   Prompt tokens: 31\n",
      "   Completion tokens: 26\n",
      "\n",
      "üí¨ Oh sure, because I just happen to be a clock now. Why not just look at your phone or the nearest wall?\n",
      "\n",
      "‚ñ∂Ô∏è Run 19/20:\n",
      "‚åö 0.92 seconds\n",
      "x-ms-region: \u001b[1;32mSweden Central\u001b[0m\n",
      "Token usage:\n",
      "   Total tokens: 68\n",
      "   Prompt tokens: 31\n",
      "   Completion tokens: 37\n",
      "\n",
      "üí¨ Oh, sure! I‚Äôd just whip out my watch, if I had one. But, you know, time is a social construct anyway. So good luck figuring it out!\n",
      "\n",
      "‚ñ∂Ô∏è Run 20/20:\n",
      "‚åö 0.96 seconds\n",
      "x-ms-region: \u001b[1;32mEast US\u001b[0m\n",
      "Token usage:\n",
      "   Total tokens: 72\n",
      "   Prompt tokens: 31\n",
      "   Completion tokens: 41\n",
      "\n",
      "üí¨ Oh, absolutely! I'm just a chatbot with no access to the real world, timezones, or clocks. But hey, maybe check your phone? It'll definitely do a better job than I can!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "runs = 20\n",
    "sleep_time_ms = 100\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    azure_endpoint = apim_resource_gateway_url,\n",
    "    api_key = apim_subscription_key,\n",
    "    api_version = openai_api_version\n",
    ")\n",
    "\n",
    "for i in range(runs):\n",
    "    print(f\"‚ñ∂Ô∏è Run {i+1}/{runs}:\")\n",
    "\n",
    "    start_time = time.time()\n",
    "    raw_response = client.chat.completions.with_raw_response.create(\n",
    "        model = openai_model_name,\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": \"You are a sarcastic, unhelpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": \"Can you tell me the time, please?\"}\n",
    "        ])\n",
    "    response_time = time.time() - start_time\n",
    "\n",
    "    print(f\"‚åö {response_time:.2f} seconds\")\n",
    "    print(f\"x-ms-region: \\x1b[1;32m{raw_response.headers.get(\"x-ms-region\")}\\x1b[0m\") # this header is useful to determine the region of the backend that served the request\n",
    "\n",
    "    response = raw_response.parse()\n",
    "\n",
    "    if response.usage:\n",
    "        print(f\"Token usage:\\n   Total tokens: {response.usage.total_tokens}\\n   Prompt tokens: {response.usage.prompt_tokens}\\n   Completion tokens: {response.usage.completion_tokens}\\n\")\n",
    "\n",
    "    print(f\"üí¨ {response.choices[0].message.content}\\n\")\n",
    "\n",
    "    time.sleep(sleep_time_ms/1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='clean'></a>\n",
    "### üóëÔ∏è Clean up resources\n",
    "\n",
    "When you're finished with the lab, you should remove all your deployed resources from Azure to avoid extra charges and keep your Azure subscription uncluttered.\n",
    "Use the [clean-up-resources notebook](clean-up-resources.ipynb) for that."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
