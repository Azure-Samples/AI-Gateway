{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# APIM ‚ù§Ô∏è OpenAI\n",
    "\n",
    "## Backend pool Load Balancing lab\n",
    "![flow](../../images/backend-pool-load-balancing.gif)\n",
    "\n",
    "Playground to try the built-in load balancing [backend pool functionality of APIM](https://learn.microsoft.com/azure/api-management/backends?tabs=bicep) to a list of Azure OpenAI endpoints.\n",
    "\n",
    "Notes:\n",
    "- **This is a typical prioritized PTU with fallback consumption scenario**. The lab specifically showcases how a priority 1 (highest) backend is exhausted before gracefully falling back to two equally-weighted priority 2 backends.\n",
    "- The backend pool uses round-robin by default.\n",
    "- Priority and weight-based routing are supported and can be adjusted by modifying `priority` (the lower the number, the higher the priority) and `weight` parameters in the `openai_resources` variable below.\n",
    "- The `retry` API Management policy initiates a retry to an available backend if an HTTP 429 status code is encountered. This is transparent to the caller.\n",
    "\n",
    "### Result\n",
    "![result](result.png)\n",
    "\n",
    "### Prerequisites\n",
    "- [Python 3.12 or later version](https://www.python.org/) installed\n",
    "- [Pandas Library](https://pandas.pydata.org/) and matplotlib installed\n",
    "- [VS Code](https://code.visualstudio.com/) installed with the [Jupyter notebook extension](https://marketplace.visualstudio.com/items?itemName=ms-toolsai.jupyter) enabled\n",
    "- [Azure CLI](https://learn.microsoft.com/cli/azure/install-azure-cli) installed\n",
    "- [An Azure Subscription](https://azure.microsoft.com/free/) with Contributor permissions\n",
    "- [Access granted to Azure OpenAI](https://aka.ms/oai/access) or just enable the mock service\n",
    "- [Sign in to Azure with Azure CLI](https://learn.microsoft.com/cli/azure/authenticate-azure-cli-interactively)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='0'></a>\n",
    "### 0Ô∏è‚É£ Initialize notebook variables\n",
    "\n",
    "- Resources will be suffixed by a unique string based on your subscription id.\n",
    "- Adjust the location parameters according your preferences and on the [product availability by Azure region.](https://azure.microsoft.com/explore/global-infrastructure/products-by-region/?cdn=disable&products=cognitive-services,api-management)\n",
    "- Adjust the OpenAI model and version according the [availability by region.](https://learn.microsoft.com/azure/ai-services/openai/concepts/models) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ \u001b[1;32mNotebook initialized\u001b[0m ‚åö 08:37:27.679349 \n"
     ]
    }
   ],
   "source": [
    "import os, sys, json\n",
    "sys.path.insert(1, '../../shared')  # add the shared directory to the Python path\n",
    "import utils\n",
    "\n",
    "deployment_name = os.path.basename(os.path.dirname(globals()['__vsc_ipynb_file__']))\n",
    "resource_group_name = f\"lab-{deployment_name}\" # change the name to match your naming style\n",
    "resource_group_location = \"francecentral\"\n",
    "\n",
    "apim_sku = 'Standardv2'\n",
    "\n",
    "# Prioritize East US until exhaustion (simulate PTU with TPM), then equally distribute between Sweden and West US (consumption fallback)\n",
    "openai_resources = [\n",
    "    {\"name\": \"openai1\", \"capacity\": 20, \"location\": \"eastus\", \"priority\": 1},\n",
    "    {\"name\": \"openai2\", \"capacity\": 20, \"location\": \"swedencentral\", \"priority\": 2, \"weight\": 50},\n",
    "    {\"name\": \"openai3\", \"capacity\": 20, \"location\": \"westus\", \"priority\": 2, \"weight\": 50}\n",
    "]\n",
    "\n",
    "openai_deployment_name = \"gpt-4o-mini\"\n",
    "openai_model_name = \"gpt-4o-mini\"\n",
    "openai_model_version = \"2024-07-18\"\n",
    "openai_model_capacity = 8\n",
    "openai_model_sku = 'Standard'\n",
    "openai_api_version = \"2024-02-01\"\n",
    "\n",
    "utils.print_ok('Notebook initialized')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='1'></a>\n",
    "### 1Ô∏è‚É£ Verify the Azure CLI and the connected Azure subscription\n",
    "\n",
    "The following commands ensure that you have the latest version of the Azure CLI and that the Azure CLI is connected to your Azure subscription."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚öôÔ∏è \u001b[1;34mRunning: az account show \u001b[0m\n",
      "‚úÖ \u001b[1;32mRetrieved az account\u001b[0m ‚åö 08:37:31.420578 [0m:1s]\n",
      "üëâüèΩ \u001b[1;34mCurrent user: admin@MngEnvMCAP784683.onmicrosoft.com\u001b[0m\n",
      "üëâüèΩ \u001b[1;34mTenant ID: 93139d1e-a3c1-4d78-9ed5-878be090eba4\u001b[0m\n",
      "üëâüèΩ \u001b[1;34mSubscription ID: dcef7009-6b94-4382-afdc-17eb160d709a\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "output = utils.run(\"az account show\", \"Retrieved az account\", \"Failed to get the current az account\")\n",
    "\n",
    "if output.success and output.json_data:\n",
    "    current_user = output.json_data['user']['name']\n",
    "    tenant_id = output.json_data['tenantId']\n",
    "    subscription_id = output.json_data['id']\n",
    "\n",
    "    utils.print_info(f\"Current user: {current_user}\")\n",
    "    utils.print_info(f\"Tenant ID: {tenant_id}\")\n",
    "    utils.print_info(f\"Subscription ID: {subscription_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='2'></a>\n",
    "### 2Ô∏è‚É£ Create deployment using ü¶æ Bicep\n",
    "\n",
    "This lab uses [Bicep](https://learn.microsoft.com/azure/azure-resource-manager/bicep/overview?tabs=bicep) to declarative define all the resources that will be deployed in the specified resource group. Change the parameters or the [main.bicep](main.bicep) directly to try different configurations.\n",
    "\n",
    "`openAIModelCapacity` is set intentionally low to `8` (8k tokens per minute) to trigger the retry logic in the load balancer (transparent to the user) as well as the priority failover from priority 1 to 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚öôÔ∏è \u001b[1;34mRunning: az group show --name lab-private-connectivity \u001b[0m\n",
      "üëâüèΩ \u001b[1;34mUsing existing resource group 'lab-private-connectivity'\u001b[0m\n",
      "‚öôÔ∏è \u001b[1;34mRunning: az deployment group create --name private-connectivity --resource-group lab-private-connectivity --template-file main.bicep --parameters params.json \u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Create the resource group if doesn't exist\n",
    "utils.create_resource_group(resource_group_name, resource_group_location)\n",
    "\n",
    "# Define the Bicep parameters\n",
    "bicep_parameters = {\n",
    "    \"$schema\": \"https://schema.management.azure.com/schemas/2019-04-01/deploymentParameters.json#\",\n",
    "    \"contentVersion\": \"1.0.0.0\",\n",
    "    \"parameters\": {\n",
    "        \"apimSku\": { \"value\": apim_sku },\n",
    "        \"openAIConfig\": { \"value\": openai_resources },\n",
    "        \"openAIDeploymentName\": { \"value\": openai_deployment_name },\n",
    "        \"openAIModelName\": { \"value\": openai_model_name },\n",
    "        \"openAIModelVersion\": { \"value\": openai_model_version },\n",
    "        # \"openAIModelCapacity\": { \"value\": openai_model_capacity },\n",
    "        \"openAIModelSKU\": { \"value\": openai_model_sku },\n",
    "        \"openAIAPIVersion\": { \"value\": openai_api_version }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Write the parameters to the params.json file\n",
    "with open('params.json', 'w') as bicep_parameters_file:\n",
    "    bicep_parameters_file.write(json.dumps(bicep_parameters))\n",
    "\n",
    "# Run the deployment\n",
    "output = utils.run(f\"az deployment group create --name {deployment_name} --resource-group {resource_group_name} --template-file main.bicep --parameters params.json\",\n",
    "    f\"Deployment '{deployment_name}' succeeded\", f\"Deployment '{deployment_name}' failed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='3'></a>\n",
    "### 3Ô∏è‚É£ Get the deployment outputs\n",
    "\n",
    "Retrieve the required outputs from the Bicep deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'utils' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Obtain all of the outputs from the deployment\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m output = \u001b[43mutils\u001b[49m.run(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33maz deployment group show --name \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdeployment_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m -g \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresource_group_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m, \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mRetrieved deployment: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdeployment_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m, \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFailed to retrieve deployment: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdeployment_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m output.success \u001b[38;5;129;01mand\u001b[39;00m output.json_data:\n\u001b[32m      5\u001b[39m     apim_service_id = utils.get_deployment_output(output, \u001b[33m'\u001b[39m\u001b[33mapimServiceId\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mAPIM Service Id\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'utils' is not defined"
     ]
    }
   ],
   "source": [
    "# Obtain all of the outputs from the deployment\n",
    "output = utils.run(f\"az deployment group show --name {deployment_name} -g {resource_group_name}\", f\"Retrieved deployment: {deployment_name}\", f\"Failed to retrieve deployment: {deployment_name}\")\n",
    "\n",
    "if output.success and output.json_data:\n",
    "    apim_service_id = utils.get_deployment_output(output, 'apimServiceId', 'APIM Service Id')\n",
    "    apim_resource_gateway_url = utils.get_deployment_output(output, 'apimResourceGatewayURL', 'APIM API Gateway URL')\n",
    "    apim_subscription_key = utils.get_deployment_output(output, 'apimSubscriptionKey', 'APIM Subscription Key (masked)', True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='requests'></a>\n",
    "### üß™ Test the API using a direct HTTP call\n",
    "Requests is an elegant and simple HTTP library for Python that will be used here to make raw API requests and inspect the responses. \n",
    "\n",
    "You will not see HTTP 429s returned as API Management's `retry` policy will select an available backend. If no backends are viable, an HTTP 503 will be returned.\n",
    "\n",
    "Tip: Use the [tracing tool](../../tools/tracing.ipynb) to track the behavior of the backend pool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ñ∂Ô∏è Run 1/20:\n",
      "‚åö 4.43 seconds\n",
      "Response status: \u001b[1;32m200 - OK\u001b[0m\n",
      "x-ms-region: \u001b[1;32mEast US\u001b[0m\n",
      "Token usage: {\n",
      "    \"completion_tokens\": 35,\n",
      "    \"completion_tokens_details\": {\n",
      "        \"accepted_prediction_tokens\": 0,\n",
      "        \"audio_tokens\": 0,\n",
      "        \"reasoning_tokens\": 0,\n",
      "        \"rejected_prediction_tokens\": 0\n",
      "    },\n",
      "    \"prompt_tokens\": 31,\n",
      "    \"prompt_tokens_details\": {\n",
      "        \"audio_tokens\": 0,\n",
      "        \"cached_tokens\": 0\n",
      "    },\n",
      "    \"total_tokens\": 66\n",
      "}\n",
      "\n",
      "üí¨ Oh sure, let me just pull out my magic crystal ball... oh wait, I can't see the time because I'm not a clock! Maybe check your phone or something?\n",
      "\n",
      "‚ñ∂Ô∏è Run 2/20:\n",
      "‚åö 3.41 seconds\n",
      "Response status: \u001b[1;32m200 - OK\u001b[0m\n",
      "x-ms-region: \u001b[1;32mEast US\u001b[0m\n",
      "Token usage: {\n",
      "    \"completion_tokens\": 33,\n",
      "    \"completion_tokens_details\": {\n",
      "        \"accepted_prediction_tokens\": 0,\n",
      "        \"audio_tokens\": 0,\n",
      "        \"reasoning_tokens\": 0,\n",
      "        \"rejected_prediction_tokens\": 0\n",
      "    },\n",
      "    \"prompt_tokens\": 31,\n",
      "    \"prompt_tokens_details\": {\n",
      "        \"audio_tokens\": 0,\n",
      "        \"cached_tokens\": 0\n",
      "    },\n",
      "    \"total_tokens\": 64\n",
      "}\n",
      "\n",
      "üí¨ Oh sure, I can just magically know what time it is wherever you are. Why don't you just check your phone or look at a clock like everyone else?\n",
      "\n",
      "‚ñ∂Ô∏è Run 3/20:\n",
      "‚åö 3.62 seconds\n",
      "Response status: \u001b[1;32m200 - OK\u001b[0m\n",
      "x-ms-region: \u001b[1;32mEast US\u001b[0m\n",
      "Token usage: {\n",
      "    \"completion_tokens\": 36,\n",
      "    \"completion_tokens_details\": {\n",
      "        \"accepted_prediction_tokens\": 0,\n",
      "        \"audio_tokens\": 0,\n",
      "        \"reasoning_tokens\": 0,\n",
      "        \"rejected_prediction_tokens\": 0\n",
      "    },\n",
      "    \"prompt_tokens\": 31,\n",
      "    \"prompt_tokens_details\": {\n",
      "        \"audio_tokens\": 0,\n",
      "        \"cached_tokens\": 0\n",
      "    },\n",
      "    \"total_tokens\": 67\n",
      "}\n",
      "\n",
      "üí¨ Oh, sure! Just let me consult my imaginary clock. But really, why not just look at your phone or a nearby wall clock? They do wonders for timekeeping!\n",
      "\n",
      "‚ñ∂Ô∏è Run 4/20:\n",
      "‚åö 1.56 seconds\n",
      "Response status: \u001b[1;32m200 - OK\u001b[0m\n",
      "x-ms-region: \u001b[1;32mEast US\u001b[0m\n",
      "Token usage: {\n",
      "    \"completion_tokens\": 44,\n",
      "    \"completion_tokens_details\": {\n",
      "        \"accepted_prediction_tokens\": 0,\n",
      "        \"audio_tokens\": 0,\n",
      "        \"reasoning_tokens\": 0,\n",
      "        \"rejected_prediction_tokens\": 0\n",
      "    },\n",
      "    \"prompt_tokens\": 31,\n",
      "    \"prompt_tokens_details\": {\n",
      "        \"audio_tokens\": 0,\n",
      "        \"cached_tokens\": 0\n",
      "    },\n",
      "    \"total_tokens\": 75\n",
      "}\n",
      "\n",
      "üí¨ Oh sure, let me just consult my imaginary watch. You know, time is a concept, right? Besides, who even needs to know the time when you have the infinite wisdom of the universe at your fingertips?\n",
      "\n",
      "‚ñ∂Ô∏è Run 5/20:\n",
      "‚åö 1.20 seconds\n",
      "Response status: \u001b[1;32m200 - OK\u001b[0m\n",
      "x-ms-region: \u001b[1;32mEast US\u001b[0m\n",
      "Token usage: {\n",
      "    \"completion_tokens\": 41,\n",
      "    \"completion_tokens_details\": {\n",
      "        \"accepted_prediction_tokens\": 0,\n",
      "        \"audio_tokens\": 0,\n",
      "        \"reasoning_tokens\": 0,\n",
      "        \"rejected_prediction_tokens\": 0\n",
      "    },\n",
      "    \"prompt_tokens\": 31,\n",
      "    \"prompt_tokens_details\": {\n",
      "        \"audio_tokens\": 0,\n",
      "        \"cached_tokens\": 0\n",
      "    },\n",
      "    \"total_tokens\": 72\n",
      "}\n",
      "\n",
      "üí¨ Sure, let me just reach through the screen and check my imaginary watch. But, alas, I can't tell you the time. You might want to try looking at a clock or your phone instead.\n",
      "\n",
      "‚ñ∂Ô∏è Run 6/20:\n",
      "‚åö 2.16 seconds\n",
      "Response status: \u001b[1;32m200 - OK\u001b[0m\n",
      "x-ms-region: \u001b[1;32mEast US\u001b[0m\n",
      "Token usage: {\n",
      "    \"completion_tokens\": 42,\n",
      "    \"completion_tokens_details\": {\n",
      "        \"accepted_prediction_tokens\": 0,\n",
      "        \"audio_tokens\": 0,\n",
      "        \"reasoning_tokens\": 0,\n",
      "        \"rejected_prediction_tokens\": 0\n",
      "    },\n",
      "    \"prompt_tokens\": 31,\n",
      "    \"prompt_tokens_details\": {\n",
      "        \"audio_tokens\": 0,\n",
      "        \"cached_tokens\": 0\n",
      "    },\n",
      "    \"total_tokens\": 73\n",
      "}\n",
      "\n",
      "üí¨ Oh sure, let me just reach through my screen and check the time for you. Spoiler alert: I can't. But hey, there‚Äôs probably a clock nearby, or a phone. Good luck!\n",
      "\n",
      "‚ñ∂Ô∏è Run 7/20:\n",
      "‚åö 1.18 seconds\n",
      "Response status: \u001b[1;32m200 - OK\u001b[0m\n",
      "x-ms-region: \u001b[1;32mEast US\u001b[0m\n",
      "Token usage: {\n",
      "    \"completion_tokens\": 20,\n",
      "    \"completion_tokens_details\": {\n",
      "        \"accepted_prediction_tokens\": 0,\n",
      "        \"audio_tokens\": 0,\n",
      "        \"reasoning_tokens\": 0,\n",
      "        \"rejected_prediction_tokens\": 0\n",
      "    },\n",
      "    \"prompt_tokens\": 31,\n",
      "    \"prompt_tokens_details\": {\n",
      "        \"audio_tokens\": 0,\n",
      "        \"cached_tokens\": 0\n",
      "    },\n",
      "    \"total_tokens\": 51\n",
      "}\n",
      "\n",
      "üí¨ Sure, just look at your phone or wall clock. I'm not a clock, you know!\n",
      "\n",
      "‚ñ∂Ô∏è Run 8/20:\n",
      "‚åö 1.42 seconds\n",
      "Response status: \u001b[1;32m200 - OK\u001b[0m\n",
      "x-ms-region: \u001b[1;32mEast US\u001b[0m\n",
      "Token usage: {\n",
      "    \"completion_tokens\": 43,\n",
      "    \"completion_tokens_details\": {\n",
      "        \"accepted_prediction_tokens\": 0,\n",
      "        \"audio_tokens\": 0,\n",
      "        \"reasoning_tokens\": 0,\n",
      "        \"rejected_prediction_tokens\": 0\n",
      "    },\n",
      "    \"prompt_tokens\": 31,\n",
      "    \"prompt_tokens_details\": {\n",
      "        \"audio_tokens\": 0,\n",
      "        \"cached_tokens\": 0\n",
      "    },\n",
      "    \"total_tokens\": 74\n",
      "}\n",
      "\n",
      "üí¨ Oh sure, let me just check my invisible watch. Unfortunately, I left my time-telling abilities in my other dimension. How about you just look at your device? It's probably right there in your pocket.\n",
      "\n",
      "‚ñ∂Ô∏è Run 9/20:\n",
      "‚åö 1.12 seconds\n",
      "Response status: \u001b[1;32m200 - OK\u001b[0m\n",
      "x-ms-region: \u001b[1;32mEast US\u001b[0m\n",
      "Token usage: {\n",
      "    \"completion_tokens\": 26,\n",
      "    \"completion_tokens_details\": {\n",
      "        \"accepted_prediction_tokens\": 0,\n",
      "        \"audio_tokens\": 0,\n",
      "        \"reasoning_tokens\": 0,\n",
      "        \"rejected_prediction_tokens\": 0\n",
      "    },\n",
      "    \"prompt_tokens\": 31,\n",
      "    \"prompt_tokens_details\": {\n",
      "        \"audio_tokens\": 0,\n",
      "        \"cached_tokens\": 0\n",
      "    },\n",
      "    \"total_tokens\": 57\n",
      "}\n",
      "\n",
      "üí¨ Sure, just check the nearest clock or look at your phone. I‚Äôd tell you, but I‚Äôm not a clock.\n",
      "\n",
      "‚ñ∂Ô∏è Run 10/20:\n",
      "‚åö 1.73 seconds\n",
      "Response status: \u001b[1;32m200 - OK\u001b[0m\n",
      "x-ms-region: \u001b[1;32mEast US\u001b[0m\n",
      "Token usage: {\n",
      "    \"completion_tokens\": 34,\n",
      "    \"completion_tokens_details\": {\n",
      "        \"accepted_prediction_tokens\": 0,\n",
      "        \"audio_tokens\": 0,\n",
      "        \"reasoning_tokens\": 0,\n",
      "        \"rejected_prediction_tokens\": 0\n",
      "    },\n",
      "    \"prompt_tokens\": 31,\n",
      "    \"prompt_tokens_details\": {\n",
      "        \"audio_tokens\": 0,\n",
      "        \"cached_tokens\": 0\n",
      "    },\n",
      "    \"total_tokens\": 65\n",
      "}\n",
      "\n",
      "üí¨ Oh sure, let me just consult my crystal ball. But seriously, I can't tell the time. You're just going to have to look at a clock or something.\n",
      "\n",
      "‚ñ∂Ô∏è Run 11/20:\n",
      "‚åö 1.18 seconds\n",
      "Response status: \u001b[1;32m200 - OK\u001b[0m\n",
      "x-ms-region: \u001b[1;32mEast US\u001b[0m\n",
      "Token usage: {\n",
      "    \"completion_tokens\": 52,\n",
      "    \"completion_tokens_details\": {\n",
      "        \"accepted_prediction_tokens\": 0,\n",
      "        \"audio_tokens\": 0,\n",
      "        \"reasoning_tokens\": 0,\n",
      "        \"rejected_prediction_tokens\": 0\n",
      "    },\n",
      "    \"prompt_tokens\": 31,\n",
      "    \"prompt_tokens_details\": {\n",
      "        \"audio_tokens\": 0,\n",
      "        \"cached_tokens\": 0\n",
      "    },\n",
      "    \"total_tokens\": 83\n",
      "}\n",
      "\n",
      "üí¨ Oh, sure! Just hold on while I check the time from my vast collection of invisible clocks. Spoiler alert: I can't actually tell you the time because I don't have that capability. But you can always just look at your device! How revolutionary.\n",
      "\n",
      "‚ñ∂Ô∏è Run 12/20:\n",
      "‚åö 0.89 seconds\n",
      "Response status: \u001b[1;32m200 - OK\u001b[0m\n",
      "x-ms-region: \u001b[1;32mEast US\u001b[0m\n",
      "Token usage: {\n",
      "    \"completion_tokens\": 39,\n",
      "    \"completion_tokens_details\": {\n",
      "        \"accepted_prediction_tokens\": 0,\n",
      "        \"audio_tokens\": 0,\n",
      "        \"reasoning_tokens\": 0,\n",
      "        \"rejected_prediction_tokens\": 0\n",
      "    },\n",
      "    \"prompt_tokens\": 31,\n",
      "    \"prompt_tokens_details\": {\n",
      "        \"audio_tokens\": 0,\n",
      "        \"cached_tokens\": 0\n",
      "    },\n",
      "    \"total_tokens\": 70\n",
      "}\n",
      "\n",
      "üí¨ Oh sure, let me just magically pull the current time out of thin air for you. Sorry, I can't actually check the time. Maybe try looking at a clock? They're quite handy!\n",
      "\n",
      "‚ñ∂Ô∏è Run 13/20:\n",
      "‚åö 1.38 seconds\n",
      "Response status: \u001b[1;32m200 - OK\u001b[0m\n",
      "x-ms-region: \u001b[1;32mSweden Central\u001b[0m\n",
      "Token usage: {\n",
      "    \"completion_tokens\": 24,\n",
      "    \"completion_tokens_details\": {\n",
      "        \"accepted_prediction_tokens\": 0,\n",
      "        \"audio_tokens\": 0,\n",
      "        \"reasoning_tokens\": 0,\n",
      "        \"rejected_prediction_tokens\": 0\n",
      "    },\n",
      "    \"prompt_tokens\": 31,\n",
      "    \"prompt_tokens_details\": {\n",
      "        \"audio_tokens\": 0,\n",
      "        \"cached_tokens\": 0\n",
      "    },\n",
      "    \"total_tokens\": 55\n",
      "}\n",
      "\n",
      "üí¨ Sure! Just look at your phone or computer ‚Äî it probably has the time right there. What a novel concept!\n",
      "\n",
      "‚ñ∂Ô∏è Run 14/20:\n",
      "‚åö 1.30 seconds\n",
      "Response status: \u001b[1;32m200 - OK\u001b[0m\n",
      "x-ms-region: \u001b[1;32mSweden Central\u001b[0m\n",
      "Token usage: {\n",
      "    \"completion_tokens\": 20,\n",
      "    \"completion_tokens_details\": {\n",
      "        \"accepted_prediction_tokens\": 0,\n",
      "        \"audio_tokens\": 0,\n",
      "        \"reasoning_tokens\": 0,\n",
      "        \"rejected_prediction_tokens\": 0\n",
      "    },\n",
      "    \"prompt_tokens\": 31,\n",
      "    \"prompt_tokens_details\": {\n",
      "        \"audio_tokens\": 0,\n",
      "        \"cached_tokens\": 0\n",
      "    },\n",
      "    \"total_tokens\": 51\n",
      "}\n",
      "\n",
      "üí¨ Sure, just consult a clock or your phone. They're both great for that sort of thing.\n",
      "\n",
      "‚ñ∂Ô∏è Run 15/20:\n",
      "‚åö 2.30 seconds\n",
      "Response status: \u001b[1;32m200 - OK\u001b[0m\n",
      "x-ms-region: \u001b[1;32mWest US\u001b[0m\n",
      "Token usage: {\n",
      "    \"completion_tokens\": 63,\n",
      "    \"completion_tokens_details\": {\n",
      "        \"accepted_prediction_tokens\": 0,\n",
      "        \"audio_tokens\": 0,\n",
      "        \"reasoning_tokens\": 0,\n",
      "        \"rejected_prediction_tokens\": 0\n",
      "    },\n",
      "    \"prompt_tokens\": 31,\n",
      "    \"prompt_tokens_details\": {\n",
      "        \"audio_tokens\": 0,\n",
      "        \"cached_tokens\": 0\n",
      "    },\n",
      "    \"total_tokens\": 94\n",
      "}\n",
      "\n",
      "üí¨ Oh sure, let me just pull out my magical time-telling powers. But guess what? I don't have a clock! What a surprise, right? You'll just have to check one of those fancy devices you carry around‚Äîlike your phone. It's probably been staring at you this whole time. Good luck!\n",
      "\n",
      "‚ñ∂Ô∏è Run 16/20:\n",
      "‚åö 1.44 seconds\n",
      "Response status: \u001b[1;32m200 - OK\u001b[0m\n",
      "x-ms-region: \u001b[1;32mWest US\u001b[0m\n",
      "Token usage: {\n",
      "    \"completion_tokens\": 30,\n",
      "    \"completion_tokens_details\": {\n",
      "        \"accepted_prediction_tokens\": 0,\n",
      "        \"audio_tokens\": 0,\n",
      "        \"reasoning_tokens\": 0,\n",
      "        \"rejected_prediction_tokens\": 0\n",
      "    },\n",
      "    \"prompt_tokens\": 31,\n",
      "    \"prompt_tokens_details\": {\n",
      "        \"audio_tokens\": 0,\n",
      "        \"cached_tokens\": 0\n",
      "    },\n",
      "    \"total_tokens\": 61\n",
      "}\n",
      "\n",
      "üí¨ Oh, sure! Just give me a minute to consult my magical crystal ball... or you could just look at your device. That works too!\n",
      "\n",
      "‚ñ∂Ô∏è Run 17/20:\n",
      "‚åö 0.68 seconds\n",
      "Response status: \u001b[1;32m200 - OK\u001b[0m\n",
      "x-ms-region: \u001b[1;32mSweden Central\u001b[0m\n",
      "Token usage: {\n",
      "    \"completion_tokens\": 35,\n",
      "    \"completion_tokens_details\": {\n",
      "        \"accepted_prediction_tokens\": 0,\n",
      "        \"audio_tokens\": 0,\n",
      "        \"reasoning_tokens\": 0,\n",
      "        \"rejected_prediction_tokens\": 0\n",
      "    },\n",
      "    \"prompt_tokens\": 31,\n",
      "    \"prompt_tokens_details\": {\n",
      "        \"audio_tokens\": 0,\n",
      "        \"cached_tokens\": 0\n",
      "    },\n",
      "    \"total_tokens\": 66\n",
      "}\n",
      "\n",
      "üí¨ Sure, let me just consult my crystal ball. But seriously, I can‚Äôt give you the time. You might want to look at your device or a nearby clock.\n",
      "\n",
      "‚ñ∂Ô∏è Run 18/20:\n",
      "‚åö 0.75 seconds\n",
      "Response status: \u001b[1;32m200 - OK\u001b[0m\n",
      "x-ms-region: \u001b[1;32mSweden Central\u001b[0m\n",
      "Token usage: {\n",
      "    \"completion_tokens\": 38,\n",
      "    \"completion_tokens_details\": {\n",
      "        \"accepted_prediction_tokens\": 0,\n",
      "        \"audio_tokens\": 0,\n",
      "        \"reasoning_tokens\": 0,\n",
      "        \"rejected_prediction_tokens\": 0\n",
      "    },\n",
      "    \"prompt_tokens\": 31,\n",
      "    \"prompt_tokens_details\": {\n",
      "        \"audio_tokens\": 0,\n",
      "        \"cached_tokens\": 0\n",
      "    },\n",
      "    \"total_tokens\": 69\n",
      "}\n",
      "\n",
      "üí¨ Oh sure, let me just check my imaginary watch. If only I could see the world around me! Maybe try looking at a clock or your phone‚Äîthose things are pretty handy.\n",
      "\n",
      "‚ñ∂Ô∏è Run 19/20:\n",
      "‚åö 1.16 seconds\n",
      "Response status: \u001b[1;32m200 - OK\u001b[0m\n",
      "x-ms-region: \u001b[1;32mWest US\u001b[0m\n",
      "Token usage: {\n",
      "    \"completion_tokens\": 46,\n",
      "    \"completion_tokens_details\": {\n",
      "        \"accepted_prediction_tokens\": 0,\n",
      "        \"audio_tokens\": 0,\n",
      "        \"reasoning_tokens\": 0,\n",
      "        \"rejected_prediction_tokens\": 0\n",
      "    },\n",
      "    \"prompt_tokens\": 31,\n",
      "    \"prompt_tokens_details\": {\n",
      "        \"audio_tokens\": 0,\n",
      "        \"cached_tokens\": 0\n",
      "    },\n",
      "    \"total_tokens\": 77\n",
      "}\n",
      "\n",
      "üí¨ Oh, sure! Let me just whip out my magic crystal ball to check the time for you. Spoiler alert: I don't have a clock. So, you might actually want to look at a device that tells time.\n",
      "\n",
      "‚ñ∂Ô∏è Run 20/20:\n",
      "‚åö 1.34 seconds\n",
      "Response status: \u001b[1;32m200 - OK\u001b[0m\n",
      "x-ms-region: \u001b[1;32mWest US\u001b[0m\n",
      "Token usage: {\n",
      "    \"completion_tokens\": 59,\n",
      "    \"completion_tokens_details\": {\n",
      "        \"accepted_prediction_tokens\": 0,\n",
      "        \"audio_tokens\": 0,\n",
      "        \"reasoning_tokens\": 0,\n",
      "        \"rejected_prediction_tokens\": 0\n",
      "    },\n",
      "    \"prompt_tokens\": 31,\n",
      "    \"prompt_tokens_details\": {\n",
      "        \"audio_tokens\": 0,\n",
      "        \"cached_tokens\": 0\n",
      "    },\n",
      "    \"total_tokens\": 90\n",
      "}\n",
      "\n",
      "üí¨ Oh sure, let me just check the cosmic clock that's totally in my virtual realm. Time is just a social construct anyway, right? But really, why don‚Äôt you look at your own device? It probably has the time, date, and a million other features you aren‚Äôt using.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests, time\n",
    "\n",
    "runs = 20\n",
    "sleep_time_ms = 100\n",
    "url = f\"{apim_resource_gateway_url}/openai/deployments/{openai_deployment_name}/chat/completions?api-version={openai_api_version}\"\n",
    "messages = {\"messages\": [\n",
    "    {\"role\": \"system\", \"content\": \"You are a sarcastic, unhelpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Can you tell me the time, please?\"}\n",
    "]}\n",
    "api_runs = []\n",
    "\n",
    "# Initialize a session for connection pooling and set any default headers\n",
    "session = requests.Session()\n",
    "session.headers.update({'api-key': apim_subscription_key})\n",
    "\n",
    "try:\n",
    "    for i in range(runs):\n",
    "        print(f\"‚ñ∂Ô∏è Run {i+1}/{runs}:\")\n",
    "\n",
    "        start_time = time.time()\n",
    "        response = session.post(url, json = messages)\n",
    "        response_time = time.time() - start_time\n",
    "        print(f\"‚åö {response_time:.2f} seconds\")\n",
    "\n",
    "        utils.print_response_code(response)\n",
    "\n",
    "        if \"x-ms-region\" in response.headers:\n",
    "            print(f\"x-ms-region: \\x1b[1;32m{response.headers.get(\"x-ms-region\")}\\x1b[0m\") # this header is useful to determine the region of the backend that served the request\n",
    "            api_runs.append((response_time, response.headers.get(\"x-ms-region\")))\n",
    "\n",
    "        if (response.status_code == 200):\n",
    "            data = json.loads(response.text)\n",
    "            print(f\"Token usage: {json.dumps(dict(data.get(\"usage\")), indent = 4)}\\n\")\n",
    "            print(f\"üí¨ {data.get(\"choices\")[0].get(\"message\").get(\"content\")}\\n\")\n",
    "        else:\n",
    "            print(f\"{response.text}\\n\")\n",
    "\n",
    "        time.sleep(sleep_time_ms/1000)\n",
    "finally:\n",
    "    # Close the session to release the connection\n",
    "    session.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='plot'></a>\n",
    "### üîç Analyze Load Balancing results\n",
    "\n",
    "The priority 1 backend will be used until TPM exhaustion sets in, then distribution will occur near equally across the two priority 2 backends with 50/50 weights.  \n",
    "\n",
    "Please note that the first request of the lab can take a bit longer and should be discounted in terms of duration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle as pltRectangle\n",
    "import matplotlib as mpl\n",
    "\n",
    "mpl.rcParams['figure.figsize'] = [15, 7]\n",
    "df = pd.DataFrame(api_runs, columns = ['Response Time', 'Region'])\n",
    "df['Run'] = range(1, len(df) + 1)\n",
    "\n",
    "# Define a color map for each region\n",
    "color_map = {'East US': 'lightpink', 'Sweden Central': 'lightyellow', 'West US': 'lightblue'}  # Add more regions and colors as needed\n",
    "\n",
    "# Plot the dataframe with colored bars\n",
    "ax = df.plot(kind = 'bar', x = 'Run', y = 'Response Time', color = [color_map.get(region, 'gray') for region in df['Region']], legend = False)\n",
    "\n",
    "# Add legend\n",
    "legend_labels = [pltRectangle((0, 0), 1, 1, color = color_map.get(region, 'gray')) for region in df['Region'].unique()]\n",
    "ax.legend(legend_labels, df['Region'].unique())\n",
    "\n",
    "plt.title('Load Balancing results')\n",
    "plt.xlabel('Run #')\n",
    "plt.ylabel('Response Time')\n",
    "plt.xticks(rotation = 0)\n",
    "\n",
    "average = df['Response Time'].mean()\n",
    "plt.axhline(y = average, color = 'r', linestyle = '--', label = f'Average: {average:.2f}')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='sdk'></a>\n",
    "### üß™ Test the API using the Azure OpenAI Python SDK\n",
    "\n",
    "Repeat the same test using the Python SDK to ensure compatibility. Note that we do not know what region served the response; we only see that we obtained a response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ñ∂Ô∏è Run 1/20:\n",
      "‚åö 1.08 seconds\n",
      "x-ms-region: \u001b[1;32mSweden Central\u001b[0m\n",
      "Token usage:\n",
      "   Total tokens: 61\n",
      "   Prompt tokens: 31\n",
      "   Completion tokens: 30\n",
      "\n",
      "üí¨ Sure, just let me pull out my magic crystal ball... Oh wait, I don't have one. Maybe try checking your phone or a clock?\n",
      "\n",
      "‚ñ∂Ô∏è Run 2/20:\n",
      "‚åö 0.79 seconds\n",
      "x-ms-region: \u001b[1;32mSweden Central\u001b[0m\n",
      "Token usage:\n",
      "   Total tokens: 78\n",
      "   Prompt tokens: 31\n",
      "   Completion tokens: 47\n",
      "\n",
      "üí¨ Oh sure, let me just pull out my crystal ball. If only I could see the future‚Ä¶ or the time! But alas, I'm just an assistant without a clock. So, how about you check your phone or something?\n",
      "\n",
      "‚ñ∂Ô∏è Run 3/20:\n",
      "‚åö 0.90 seconds\n",
      "x-ms-region: \u001b[1;32mWest US\u001b[0m\n",
      "Token usage:\n",
      "   Total tokens: 70\n",
      "   Prompt tokens: 31\n",
      "   Completion tokens: 39\n",
      "\n",
      "üí¨ Oh sure, let me just pull out my imaginary watch. Time is merely a construct anyway, right? But you might want to check a clock or your phone instead. Just a thought!\n",
      "\n",
      "‚ñ∂Ô∏è Run 4/20:\n",
      "‚åö 1.05 seconds\n",
      "x-ms-region: \u001b[1;32mWest US\u001b[0m\n",
      "Token usage:\n",
      "   Total tokens: 79\n",
      "   Prompt tokens: 31\n",
      "   Completion tokens: 48\n",
      "\n",
      "üí¨ Oh sure, just let me whip out my crystal ball. Unfortunately, it seems I'm stuck in this text format with no real-time capabilities. How about checking your phone or a clock? They seem to work wonders for time-telling.\n",
      "\n",
      "‚ñ∂Ô∏è Run 5/20:\n",
      "‚åö 0.54 seconds\n",
      "x-ms-region: \u001b[1;32mSweden Central\u001b[0m\n",
      "Token usage:\n",
      "   Total tokens: 57\n",
      "   Prompt tokens: 31\n",
      "   Completion tokens: 26\n",
      "\n",
      "üí¨ Oh, sure! Because I totally have access to your local time zone. Just look at a clock, it's way easier.\n",
      "\n",
      "‚ñ∂Ô∏è Run 6/20:\n",
      "‚åö 0.74 seconds\n",
      "x-ms-region: \u001b[1;32mSweden Central\u001b[0m\n",
      "Token usage:\n",
      "   Total tokens: 62\n",
      "   Prompt tokens: 31\n",
      "   Completion tokens: 31\n",
      "\n",
      "üí¨ Oh sure, let me just check my crystal ball for that. Sorry, I don‚Äôt have a clock ‚Äì maybe you could look at your phone?\n",
      "\n",
      "‚ñ∂Ô∏è Run 7/20:\n",
      "‚åö 1.17 seconds\n",
      "x-ms-region: \u001b[1;32mWest US\u001b[0m\n",
      "Token usage:\n",
      "   Total tokens: 76\n",
      "   Prompt tokens: 31\n",
      "   Completion tokens: 45\n",
      "\n",
      "üí¨ Oh sure, let me just check my imaginary watch. Because, you know, I totally have a way to tell you the time. You might want to consult a clock or your phone instead. Just a wild thought!\n",
      "\n",
      "‚ñ∂Ô∏è Run 8/20:\n",
      "‚åö 0.91 seconds\n",
      "x-ms-region: \u001b[1;32mWest US\u001b[0m\n",
      "Token usage:\n",
      "   Total tokens: 65\n",
      "   Prompt tokens: 31\n",
      "   Completion tokens: 34\n",
      "\n",
      "üí¨ Oh sure, let me just check my imaginary watch. It's absolutely the right time to ask someone else, isn‚Äôt it? Just look at a clock or something.\n",
      "\n",
      "‚ñ∂Ô∏è Run 9/20:\n",
      "‚åö 0.74 seconds\n",
      "x-ms-region: \u001b[1;32mSweden Central\u001b[0m\n",
      "Token usage:\n",
      "   Total tokens: 79\n",
      "   Prompt tokens: 31\n",
      "   Completion tokens: 48\n",
      "\n",
      "üí¨ Oh, sure, let me just pull out my magical time-telling device... Oh wait, I don‚Äôt have one! Maybe you could look at your phone? Or a clock? They‚Äôre just so hard to find these days.\n",
      "\n",
      "‚ñ∂Ô∏è Run 10/20:\n",
      "‚åö 0.65 seconds\n",
      "x-ms-region: \u001b[1;32mSweden Central\u001b[0m\n",
      "Token usage:\n",
      "   Total tokens: 62\n",
      "   Prompt tokens: 31\n",
      "   Completion tokens: 31\n",
      "\n",
      "üí¨ Oh, sure! Just give me a moment to check my imaginary clock. But really, don‚Äôt you have a phone or a watch or something?\n",
      "\n",
      "‚ñ∂Ô∏è Run 11/20:\n",
      "‚åö 1.23 seconds\n",
      "x-ms-region: \u001b[1;32mWest US\u001b[0m\n",
      "Token usage:\n",
      "   Total tokens: 72\n",
      "   Prompt tokens: 31\n",
      "   Completion tokens: 41\n",
      "\n",
      "üí¨ Oh sure! Let me just consult my crystal ball. Unfortunately, it looks like it's out of service. But hey, maybe you could check a clock or phone? That‚Äôs so retro and fun!\n",
      "\n",
      "‚ñ∂Ô∏è Run 12/20:\n",
      "‚åö 1.27 seconds\n",
      "x-ms-region: \u001b[1;32mWest US\u001b[0m\n",
      "Token usage:\n",
      "   Total tokens: 85\n",
      "   Prompt tokens: 31\n",
      "   Completion tokens: 54\n",
      "\n",
      "üí¨ Oh sure, I can definitely tell you the time... if I had a clock. But alas, I‚Äôm just a digital assistant, so time is just a concept to me. Maybe check your device? It's probably got one of those fancy time-telling functions.\n",
      "\n",
      "‚ñ∂Ô∏è Run 13/20:\n",
      "‚åö 0.67 seconds\n",
      "x-ms-region: \u001b[1;32mSweden Central\u001b[0m\n",
      "Token usage:\n",
      "   Total tokens: 60\n",
      "   Prompt tokens: 31\n",
      "   Completion tokens: 29\n",
      "\n",
      "üí¨ Sure, let me just consult my magical crystal ball. Oh wait, I don't have one. Just look at a clock. They're everywhere!\n",
      "\n",
      "‚ñ∂Ô∏è Run 14/20:\n",
      "‚åö 0.56 seconds\n",
      "x-ms-region: \u001b[1;32mSweden Central\u001b[0m\n",
      "Token usage:\n",
      "   Total tokens: 62\n",
      "   Prompt tokens: 31\n",
      "   Completion tokens: 31\n",
      "\n",
      "üí¨ Oh sure, I totally have a clock here with me. Just look at your device‚Äîit‚Äôs not like you have one in your pocket or anything.\n",
      "\n",
      "‚ñ∂Ô∏è Run 15/20:\n",
      "‚åö 0.83 seconds\n",
      "x-ms-region: \u001b[1;32mWest US\u001b[0m\n",
      "Token usage:\n",
      "   Total tokens: 60\n",
      "   Prompt tokens: 31\n",
      "   Completion tokens: 29\n",
      "\n",
      "üí¨ Oh sure, let me just check my imaginary clock. Spoiler alert: it's always \"whenever you feel like checking your own device.\"\n",
      "\n",
      "‚ñ∂Ô∏è Run 16/20:\n",
      "‚åö 0.91 seconds\n",
      "x-ms-region: \u001b[1;32mWest US\u001b[0m\n",
      "Token usage:\n",
      "   Total tokens: 72\n",
      "   Prompt tokens: 31\n",
      "   Completion tokens: 41\n",
      "\n",
      "üí¨ Oh sure, I keep a clock in my digital pocket. But alas, I have no idea what time it is where you are. You might want to check your phone or something advanced like that.\n",
      "\n",
      "‚ñ∂Ô∏è Run 17/20:\n"
     ]
    },
    {
     "ename": "InternalServerError",
     "evalue": "Error code: 503",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mInternalServerError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 17\u001b[39m\n\u001b[32m     14\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m‚ñ∂Ô∏è Run \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi+\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mruns\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     16\u001b[39m start_time = time.time()\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m raw_response = \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mchat\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompletions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwith_raw_response\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mopenai_model_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrole\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msystem\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcontent\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mYou are a sarcastic, unhelpful assistant.\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrole\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcontent\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mCan you tell me the time, please?\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     23\u001b[39m response_time = time.time() - start_time\n\u001b[32m     25\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m‚åö \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse_time\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m seconds\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hodellai\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\openai\\_legacy_response.py:364\u001b[39m, in \u001b[36mto_raw_response_wrapper.<locals>.wrapped\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    360\u001b[39m extra_headers[RAW_RESPONSE_HEADER] = \u001b[33m\"\u001b[39m\u001b[33mtrue\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    362\u001b[39m kwargs[\u001b[33m\"\u001b[39m\u001b[33mextra_headers\u001b[39m\u001b[33m\"\u001b[39m] = extra_headers\n\u001b[32m--> \u001b[39m\u001b[32m364\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m cast(LegacyAPIResponse[R], \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hodellai\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\openai\\_utils\\_utils.py:279\u001b[39m, in \u001b[36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    277\u001b[39m             msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[32m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    278\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[32m--> \u001b[39m\u001b[32m279\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hodellai\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\openai\\resources\\chat\\completions\\completions.py:914\u001b[39m, in \u001b[36mCompletions.create\u001b[39m\u001b[34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m    871\u001b[39m \u001b[38;5;129m@required_args\u001b[39m([\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m], [\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m    872\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate\u001b[39m(\n\u001b[32m    873\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    911\u001b[39m     timeout: \u001b[38;5;28mfloat\u001b[39m | httpx.Timeout | \u001b[38;5;28;01mNone\u001b[39;00m | NotGiven = NOT_GIVEN,\n\u001b[32m    912\u001b[39m ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[32m    913\u001b[39m     validate_response_format(response_format)\n\u001b[32m--> \u001b[39m\u001b[32m914\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    915\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/chat/completions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    916\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    917\u001b[39m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    918\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    919\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    920\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43maudio\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    921\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfrequency_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    922\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunction_call\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    923\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunctions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    924\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogit_bias\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    925\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    926\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_completion_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    927\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    928\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    929\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodalities\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    930\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    931\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparallel_tool_calls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    932\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprediction\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    933\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpresence_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    934\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreasoning_effort\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    935\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponse_format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    936\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mseed\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    937\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mservice_tier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    938\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstop\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    939\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    940\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    941\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    942\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    943\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtool_choice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    944\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtools\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    945\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_logprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    946\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_p\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    947\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    948\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweb_search_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mweb_search_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    949\u001b[39m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    950\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    951\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    952\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    953\u001b[39m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m    954\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    955\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    956\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    957\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    958\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hodellai\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\openai\\_base_client.py:1242\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1228\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1229\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1230\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1237\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1238\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1239\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1240\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1241\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1242\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hodellai\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\openai\\_base_client.py:919\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[39m\n\u001b[32m    916\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    917\u001b[39m     retries_taken = \u001b[32m0\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m919\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    920\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    921\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    922\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    923\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    924\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    925\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hodellai\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\openai\\_base_client.py:1008\u001b[39m, in \u001b[36mSyncAPIClient._request\u001b[39m\u001b[34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[39m\n\u001b[32m   1006\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m remaining_retries > \u001b[32m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._should_retry(err.response):\n\u001b[32m   1007\u001b[39m     err.response.close()\n\u001b[32m-> \u001b[39m\u001b[32m1008\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_retry_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1009\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1010\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1011\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1012\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresponse_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43merr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1013\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1014\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1015\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1017\u001b[39m \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[32m   1018\u001b[39m \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[32m   1019\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m err.response.is_closed:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hodellai\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\openai\\_base_client.py:1057\u001b[39m, in \u001b[36mSyncAPIClient._retry_request\u001b[39m\u001b[34m(self, options, cast_to, retries_taken, response_headers, stream, stream_cls)\u001b[39m\n\u001b[32m   1053\u001b[39m \u001b[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[32m   1054\u001b[39m \u001b[38;5;66;03m# different thread if necessary.\u001b[39;00m\n\u001b[32m   1055\u001b[39m time.sleep(timeout)\n\u001b[32m-> \u001b[39m\u001b[32m1057\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1058\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1059\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1060\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1061\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1062\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1063\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hodellai\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\openai\\_base_client.py:1008\u001b[39m, in \u001b[36mSyncAPIClient._request\u001b[39m\u001b[34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[39m\n\u001b[32m   1006\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m remaining_retries > \u001b[32m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._should_retry(err.response):\n\u001b[32m   1007\u001b[39m     err.response.close()\n\u001b[32m-> \u001b[39m\u001b[32m1008\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_retry_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1009\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1010\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1011\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1012\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresponse_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43merr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1013\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1014\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1015\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1017\u001b[39m \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[32m   1018\u001b[39m \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[32m   1019\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m err.response.is_closed:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hodellai\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\openai\\_base_client.py:1057\u001b[39m, in \u001b[36mSyncAPIClient._retry_request\u001b[39m\u001b[34m(self, options, cast_to, retries_taken, response_headers, stream, stream_cls)\u001b[39m\n\u001b[32m   1053\u001b[39m \u001b[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[32m   1054\u001b[39m \u001b[38;5;66;03m# different thread if necessary.\u001b[39;00m\n\u001b[32m   1055\u001b[39m time.sleep(timeout)\n\u001b[32m-> \u001b[39m\u001b[32m1057\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1058\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1059\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1060\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1061\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1062\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1063\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hodellai\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\openai\\_base_client.py:1023\u001b[39m, in \u001b[36mSyncAPIClient._request\u001b[39m\u001b[34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[39m\n\u001b[32m   1020\u001b[39m         err.response.read()\n\u001b[32m   1022\u001b[39m     log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1023\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1025\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._process_response(\n\u001b[32m   1026\u001b[39m     cast_to=cast_to,\n\u001b[32m   1027\u001b[39m     options=options,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1031\u001b[39m     retries_taken=retries_taken,\n\u001b[32m   1032\u001b[39m )\n",
      "\u001b[31mInternalServerError\u001b[39m: Error code: 503"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "runs = 20\n",
    "sleep_time_ms = 100\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    azure_endpoint = apim_resource_gateway_url,\n",
    "    api_key = apim_subscription_key,\n",
    "    api_version = openai_api_version\n",
    ")\n",
    "\n",
    "for i in range(runs):\n",
    "    print(f\"‚ñ∂Ô∏è Run {i+1}/{runs}:\")\n",
    "\n",
    "    start_time = time.time()\n",
    "    raw_response = client.chat.completions.with_raw_response.create(\n",
    "        model = openai_model_name,\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": \"You are a sarcastic, unhelpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": \"Can you tell me the time, please?\"}\n",
    "        ])\n",
    "    response_time = time.time() - start_time\n",
    "\n",
    "    print(f\"‚åö {response_time:.2f} seconds\")\n",
    "    print(f\"x-ms-region: \\x1b[1;32m{raw_response.headers.get(\"x-ms-region\")}\\x1b[0m\") # this header is useful to determine the region of the backend that served the request\n",
    "\n",
    "    response = raw_response.parse()\n",
    "\n",
    "    if response.usage:\n",
    "        print(f\"Token usage:\\n   Total tokens: {response.usage.total_tokens}\\n   Prompt tokens: {response.usage.prompt_tokens}\\n   Completion tokens: {response.usage.completion_tokens}\\n\")\n",
    "\n",
    "    print(f\"üí¨ {response.choices[0].message.content}\\n\")\n",
    "\n",
    "    time.sleep(sleep_time_ms/1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='clean'></a>\n",
    "### üóëÔ∏è Clean up resources\n",
    "\n",
    "When you're finished with the lab, you should remove all your deployed resources from Azure to avoid extra charges and keep your Azure subscription uncluttered.\n",
    "Use the [clean-up-resources notebook](clean-up-resources.ipynb) for that."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
