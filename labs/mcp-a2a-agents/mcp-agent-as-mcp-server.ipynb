{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42162c2c",
   "metadata": {},
   "source": [
    "# APIM ❤️ AI Agents\n",
    "\n",
    "## Agent 2 Agent Communication over MCP for MCP-enabled agents lab (initial release)\n",
    "![flow](../../images/mcp-agent-2-agent.gif)\n",
    "\n",
    "Playground to experiment with [Agent 2 Agent Communication over MCP](https://devblogs.microsoft.com/blog/can-you-build-agent2agent-communication-on-mcp-yes) agents with which in turn use [MCP](https://modelcontextprotocol.io/) for tools with Azure API Management to enable plug & play of tools to LLMs. \n",
    "\n",
    "This lab relies on tools provided and deployed as part of shared infrastructure:\n",
    "- Basic oncall service: provides a tool to get a list of random people currently on-call with their status and time zone.\n",
    "- Basic weather service: provide tools to get cities for a given country and retrieve random weather information for a specified city.\n",
    "\n",
    "MCP-enabled agents are then deployed within ACA (Azure Container Apps) as MCP servers.\n",
    "\n",
    "This lab demonstrates the art of the possible of creating hetrogenous multi-agentic system with agents created using multiple orchestrators, and then allowing a single unifying protocol to communicate accross the through APIM for Authn/Authz\n",
    "\n",
    "### Prerequisites\n",
    "\n",
    "- [Python 3.13 or later](https://www.python.org/) installed\n",
    "- [VS Code](https://code.visualstudio.com/) installed with the [Jupyter notebook extension](https://marketplace.visualstudio.com/items?itemName=ms-toolsai.jupyter) enabled\n",
    "- [Python environment](https://code.visualstudio.com/docs/python/environments#_creating-environments) with the [requirements.txt](../../requirements.txt) or run `pip install -r requirements.txt` in your terminal\n",
    "- [An Azure Subscription](https://azure.microsoft.com/free/) with [Contributor](https://learn.microsoft.com/en-us/azure/role-based-access-control/built-in-roles/privileged#contributor) + [RBAC Administrator](https://learn.microsoft.com/en-us/azure/role-based-access-control/built-in-roles/privileged#role-based-access-control-administrator) or [Owner](https://learn.microsoft.com/en-us/azure/role-based-access-control/built-in-roles/privileged#owner) roles\n",
    "- [Azure CLI](https://learn.microsoft.com/cli/azure/install-azure-cli) installed and [Signed into your Azure subscription](https://learn.microsoft.com/cli/azure/authenticate-azure-cli-interactively)\n",
    "\n",
    "**Important** This lab follows a different architecture from other lab.\n",
    "\n",
    "Please deploy the shared infrastructure from this [Notebook](deploy-a2a-infra-assests.ipynb) before proceeding\n",
    "\n",
    "▶️ Click `Run All` to execute all steps sequentially, or execute them `Step by Step`...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66bb76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, json\n",
    "sys.path.insert(1, '../../shared')  # add the shared directory to the Python path\n",
    "import utils\n",
    "\n",
    "deployment_name = os.path.basename(os.path.dirname(globals()['__vsc_ipynb_file__']))\n",
    "resource_group_name = f\"lab-{deployment_name}\" # change the name to match your naming style\n",
    "resource_group_location = \"westeurope\"\n",
    "\n",
    "apim_sku = 'Basicv2'\n",
    "\n",
    "openai_resources = [ {\"name\": \"openai1\", \"location\": \"uksouth\"}]\n",
    "openai_model_name = \"gpt-4o-mini\"\n",
    "openai_model_version = \"2024-07-18\"\n",
    "openai_model_sku = \"GlobalStandard\"\n",
    "openai_deployment_name = \"gpt-4o-mini\"\n",
    "openai_api_version = \"2024-10-21\"\n",
    "\n",
    "build = 0\n",
    "weather_mcp_server_image = \"weather-mcp-server\"\n",
    "weather_mcp_server_src = \"src/weather/mcp-server\"\n",
    "\n",
    "oncall_mcp_server_image = \"oncall-mcp-server\"\n",
    "oncall_mcp_server_src = \"src/oncall/mcp-server\"\n",
    "\n",
    "utils.print_ok('Notebook initialized')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134b5c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain all of the outputs from the deployment\n",
    "output = utils.run(f\"az deployment group show --name {deployment_name} -g {resource_group_name}\", f\"Retrieved deployment: {deployment_name}\", f\"Failed to retrieve deployment: {deployment_name}\")\n",
    "\n",
    "if output.success and output.json_data:\n",
    "    apim_service_id = utils.get_deployment_output(output, 'apimServiceId', 'APIM Service Id')\n",
    "    apim_resource_gateway_url = utils.get_deployment_output(output, 'apimResourceGatewayURL', 'APIM Gateway URL')\n",
    "    apim_resource_name = utils.get_deployment_output(output, 'apimResourceName', 'APIM Resource Name')\n",
    "    apim_subscription_key = utils.get_deployment_output(output, 'apimSubscriptionKey', 'APIM Subscription Key (masked)', True)\n",
    "    app_insights_name = utils.get_deployment_output(output, 'applicationInsightsName', 'Application Insights Name')\n",
    "    container_registry_name = utils.get_deployment_output(output, 'containerRegistryName', 'Container Registry Name')\n",
    "    weather_containerapp_resource_name = utils.get_deployment_output(output, 'weatherMCPServerContainerAppResourceName', 'Weather Container App Resource Name')\n",
    "    oncall_containerapp_resource_name = utils.get_deployment_output(output, 'oncallMCPServerContainerAppResourceName', 'Oncall Container App Resource Name')\n",
    "\n",
    "    a2a_weather_containerapp_resource_name = utils.get_deployment_output(output, 'a2AWeatherAgentServerContainerAppResourceName', 'A2A (Weather) Agent Container App Resource Name')\n",
    "    a2a_oncall_containerapp_resource_name = utils.get_deployment_output(output, 'a2AOncallAgentServerContainerAppResourceName', 'A2A (Oncall) Agent Container App Resource Name')\n",
    "\n",
    "    a2a_weather_a2a_agent_ep = utils.get_deployment_output(output, 'a2AWeatherAgentServerContainerAppFQDN', 'A2A (Weather) Agent Endpoint')\n",
    "    a2a_oncall_a2a_agent_ep = utils.get_deployment_output(output, 'a2AOncallAgentServerContainerAppFQDN', 'A2A (Oncall) Agent Endpoint')\n",
    "\n",
    "inference_api_path = \"\"\n",
    "inference_api_version = \"2025-03-01-preview\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "325c5b86",
   "metadata": {},
   "source": [
    "### Building Customisable MCP-Server with MCP-enabled Agent images for deployment in ACA\n",
    "\n",
    "#### Semantic-Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b166ab63",
   "metadata": {},
   "outputs": [],
   "source": [
    "build = build + 1\n",
    "\n",
    "mcp_sk_server_image = \"sk-agent-mcp-server\"\n",
    "mcp_sk_server_src = \"src/mcp_sk_servers/src\"\n",
    "\n",
    "utils.run(f\"az acr build --image {mcp_sk_server_image}:v0.{build} --resource-group {resource_group_name} --registry {container_registry_name} --file {mcp_sk_server_src}/Dockerfile {mcp_sk_server_src}/. --no-logs\", \n",
    "          \"Generic MCP SK Server image was successfully built\", \"Failed to build the Generic MCP SK Server image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a128f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "title=\"Weather\"\n",
    "mcp_url = \"/weather\"\n",
    "\n",
    "utils.run(f'az containerapp secret set -n  {a2a_weather_containerapp_resource_name} -g {resource_group_name} --secrets apimsubscriptionkey={apim_subscription_key}', \"Weather A2A Server secret updated\", \"Weather A2A Server secret update failed\")\n",
    "utils.run(f'az containerapp update -n {a2a_weather_containerapp_resource_name} -g  {resource_group_name} --image \"{container_registry_name}.azurecr.io/{mcp_sk_server_image}:v0.{build}\" --set-env-vars TITLE={title} MCP_URL={mcp_url} APIM_GATEWAY_URL={apim_resource_gateway_url} OPENAI_API_VERSION={openai_api_version} OPENAI_DEPLOYMENT_NAME={openai_deployment_name} APIM_SUBSCRIPTION_KEY=secretref:apimsubscriptionkey', \n",
    "          \"Weather MCP SK Server with MCP deployment succeeded\", \"Weather MCP SK Server with MCP deployment failed\")\n",
    "\n",
    "title=\"Oncall\"\n",
    "mcp_url = \"/oncall\"\n",
    "\n",
    "utils.run(f'az containerapp secret set -n  {a2a_oncall_containerapp_resource_name} -g {resource_group_name} --secrets apimsubscriptionkey={apim_subscription_key}', \"Oncall A2A Server secret updated\", \"Oncall A2A Server secret update failed\")\n",
    "utils.run(f'az containerapp update -n {a2a_oncall_containerapp_resource_name} -g  {resource_group_name} --image \"{container_registry_name}.azurecr.io/{mcp_sk_server_image}:v0.{build}\" --set-env-vars TITLE={title} MCP_URL={mcp_url} APIM_GATEWAY_URL={apim_resource_gateway_url} OPENAI_API_VERSION={openai_api_version} OPENAI_DEPLOYMENT_NAME={openai_deployment_name} APIM_SUBSCRIPTION_KEY=secretref:apimsubscriptionkey', \n",
    "          \"Oncall MCP SK Server with MCP deployment succeeded\", \"Oncall MCP SK Server with MCP deployment failed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b0382f",
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.print_info(f\"MCP URL for Weather Agent direct to ACA: https://{a2a_weather_a2a_agent_ep}/mcp\")\n",
    "utils.print_info(f\"MCP URL for OnCall Agent direct to ACA: https://{a2a_oncall_a2a_agent_ep}/mcp\")\n",
    "\n",
    "utils.print_info(f'MCP URL for Weather Agent via APIM: {apim_resource_gateway_url}/weather-agent-mcp/mcp')\n",
    "utils.print_info(f'MCP URL for OnCall Agent via APIM: {apim_resource_gateway_url}/oncall-agent-mcp/mcp')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec670e54",
   "metadata": {},
   "source": [
    "### AG Agent of MCP-Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a5a151",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from autogen_ext.models.openai import AzureOpenAIChatCompletionClient\n",
    "from autogen_ext.tools.mcp import StreamableHttpServerParams, StreamableHttpMcpToolAdapter, mcp_server_tools\n",
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_agentchat.ui import Console\n",
    "\n",
    "async def run_agent(prompt: str) -> None:\n",
    "    # Create server params for the remote MCP service\n",
    "    weather_agent_mcp_params = StreamableHttpServerParams(\n",
    "        url=f\"{apim_resource_gateway_url}/weather-agent-mcp/mcp\",\n",
    "        headers={\"Content-Type\": \"application/json\"},\n",
    "        timeout=30,  # Connection timeout in seconds\n",
    "    )\n",
    "    weather_tools = await mcp_server_tools(weather_agent_mcp_params)\n",
    "\n",
    "    oncall_agent_mcp_params = StreamableHttpServerParams(\n",
    "        url=f\"{apim_resource_gateway_url}/oncall-agent-mcp/mcp\",\n",
    "        headers={\"Content-Type\": \"application/json\"},\n",
    "        timeout=30,  # Connection timeout in seconds\n",
    "    )\n",
    "\n",
    "    # Get all available tools\n",
    "    oncall_tools = await mcp_server_tools(oncall_agent_mcp_params)\n",
    "\n",
    "    # Create an agent that can use the translation tool\n",
    "    model_client = AzureOpenAIChatCompletionClient(azure_deployment=openai_model_name, model=openai_model_name,\n",
    "                azure_endpoint=f\"{apim_resource_gateway_url}/{inference_api_path}\",\n",
    "                api_key=apim_subscription_key,\n",
    "                api_version=inference_api_version\n",
    "    )\n",
    "    agent = AssistantAgent(\n",
    "        name=\"weather\",\n",
    "        model_client=model_client,\n",
    "        reflect_on_tool_use=True,\n",
    "        tools=weather_tools + oncall_tools,  # type: ignore\n",
    "        system_message=\"You are a helpful assistant.\",\n",
    "    )\n",
    "    await Console(\n",
    "        agent.run_stream(task=prompt)\n",
    "    )\n",
    "\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "asyncio.run(run_agent(\"What's the weather in Lisbon, Cairo and London? and who's oncall in CET only?\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51168b4f",
   "metadata": {},
   "source": [
    "### SK Agent of MCP-Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3c2aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from semantic_kernel.agents import ChatCompletionAgent, ChatHistoryAgentThread\n",
    "from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion\n",
    "from semantic_kernel.connectors.mcp import MCPStreamableHttpPlugin\n",
    "\n",
    "user_input = \"What's the current weather in Lisbon and London? and who's oncall today in CET only?\"\n",
    "\n",
    "weather_agent = MCPStreamableHttpPlugin(\n",
    "    name=\"Weather\",\n",
    "    url=f\"{apim_resource_gateway_url}/weather-agent-mcp/mcp\",\n",
    "    description=\"Weather Agent\",\n",
    "    )\n",
    "\n",
    "oncall_agent = MCPStreamableHttpPlugin(\n",
    "    name=\"OnCall\",\n",
    "    url=f\"{apim_resource_gateway_url}/oncall-agent-mcp/mcp\",\n",
    "    description=\"OnCall Agent\",\n",
    ")\n",
    "\n",
    "await weather_agent.connect()  # Ensure the plugin is connected before using it\n",
    "await oncall_agent.connect()  # Ensure the plugin is connected before using it\n",
    "\n",
    "agent = ChatCompletionAgent(\n",
    "    service=AzureChatCompletion(\n",
    "        endpoint=f\"{apim_resource_gateway_url}/{inference_api_path}\",\n",
    "        api_key=apim_subscription_key,\n",
    "        api_version=inference_api_version,                \n",
    "        deployment_name=openai_model_name  # Use the first model from the models_config\n",
    "    ),\n",
    "    name=\"IssueAgent\",\n",
    "    instructions=\"Answer questions using the tools available to you.\",\n",
    "    plugins=[weather_agent, oncall_agent],\n",
    ")\n",
    "\n",
    "thread: ChatHistoryAgentThread | None = None\n",
    "\n",
    "print(f\"# User: {user_input}\")\n",
    "# 2. Invoke the agent for a response\n",
    "response = await agent.get_response(messages=user_input, thread=thread)\n",
    "print(f\"# {response.name}: {response} \")\n",
    "thread = response.thread # type: ignore\n",
    "\n",
    "# 3. Cleanup: Clear the thread\n",
    "await thread.delete() if thread else None\n",
    "# await weather_plugin.close()  # Ensure the plugin is disconnected after use\n",
    "# await oncall_plugin.close()  # Ensure the plugin is disconnected after use\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
