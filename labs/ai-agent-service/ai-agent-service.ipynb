{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# APIM ‚ù§Ô∏è AI Agents\n",
    "\n",
    "## Azure AI Agent Service lab\n",
    "\n",
    "![flow](../../images/ai-agent-service.gif)\n",
    "\n",
    "Use this playground to explore the [Azure AI Agent Service](https://learn.microsoft.com/en-us/azure/ai-services/agents/overview), leveraging Azure API Management to control multiple services, including Logic Apps Workflows, and OpenAPI-based APIs. This enables limitless opportunities for AI agents while maintaining control through Azure API Management!\n",
    "\n",
    "### Prerequisites\n",
    "\n",
    "- [Python 3.12 or later version](https://www.python.org/) installed\n",
    "- [VS Code](https://code.visualstudio.com/) installed with the [Jupyter notebook extension](https://marketplace.visualstudio.com/items?itemName=ms-toolsai.jupyter) enabled\n",
    "- [Python environment](https://code.visualstudio.com/docs/python/environments#_creating-environments) with the [requirements.txt](../../requirements.txt) or run `pip install -r requirements.txt` in your terminal\n",
    "- [An Azure Subscription](https://azure.microsoft.com/free/) with [Contributor](https://learn.microsoft.com/en-us/azure/role-based-access-control/built-in-roles/privileged#contributor) + [RBAC Administrator](https://learn.microsoft.com/en-us/azure/role-based-access-control/built-in-roles/privileged#role-based-access-control-administrator) or [Owner](https://learn.microsoft.com/en-us/azure/role-based-access-control/built-in-roles/privileged#owner) roles\n",
    "- [Azure CLI](https://learn.microsoft.com/cli/azure/install-azure-cli) installed and [Signed into your Azure subscription](https://learn.microsoft.com/cli/azure/authenticate-azure-cli-interactively)\n",
    "\n",
    "‚ñ∂Ô∏è Click `Run All` to execute all steps sequentially, or execute them `Step by Step`..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='0'></a>\n",
    "### 0Ô∏è‚É£ Initialize notebook variables\n",
    "\n",
    "- Resources will be suffixed by a unique string based on your subscription id.\n",
    "- Adjust the location parameters according your preferences and on the [product availability by Azure region.](https://azure.microsoft.com/explore/global-infrastructure/products-by-region/?cdn=disable&products=cognitive-services,api-management) \n",
    "- Adjust the models and versions according the [availability by region.](https://learn.microsoft.com/azure/ai-services/openai/concepts/models) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import os, sys, json\n",
    "sys.path.insert(1, '../../shared')  # add the shared directory to the Python path\n",
    "import utils\n",
    "\n",
    "deployment_name = os.path.basename(os.path.dirname(globals()['__vsc_ipynb_file__']))\n",
    "resource_group_name = f\"lab-{deployment_name}\" # change the name to match your naming style\n",
    "resource_group_location = \"eastus2\"\n",
    "\n",
    "aiservices_config = [{\"name\": \"foundry1\", \"location\": \"eastus2\"}]\n",
    "\n",
    "models_config = [{\"name\": \"gpt-4.1-mini\", \"publisher\": \"OpenAI\", \"version\": \"2025-04-14\", \"sku\": \"GlobalStandard\", \"capacity\": 20}]\n",
    "\n",
    "apim_sku = 'Basicv2'\n",
    "apim_subscriptions_config = [{\"name\": \"subscription1\", \"displayName\": \"Subscription 1\"}]\n",
    "\n",
    "inference_api_path = \"inference\"  # path to the inference API in the APIM service\n",
    "inference_api_type = \"AzureAI\"  # options: AzureOpenAI, AzureAI, OpenAI, PassThrough\n",
    "inference_api_version = \"2024-05-01-preview\"\n",
    "foundry_project_name = deployment_name\n",
    "\n",
    "utils.print_ok('Notebook initialized')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='1'></a>\n",
    "### 1Ô∏è‚É£ Verify the Azure CLI and the connected Azure subscription\n",
    "\n",
    "The following commands ensure that you have the latest version of the Azure CLI and that the Azure CLI is connected to your Azure subscription."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = utils.run(\"az account show\", \"Retrieved az account\", \"Failed to get the current az account\")\n",
    "\n",
    "if output.success and output.json_data:\n",
    "    current_user = output.json_data['user']['name']\n",
    "    tenant_id = output.json_data['tenantId']\n",
    "    subscription_id = output.json_data['id']\n",
    "\n",
    "    utils.print_info(f\"Current user: {current_user}\")\n",
    "    utils.print_info(f\"Tenant ID: {tenant_id}\")\n",
    "    utils.print_info(f\"Subscription ID: {subscription_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='2'></a>\n",
    "### 2Ô∏è‚É£ Create deployment using ü¶æ Bicep\n",
    "\n",
    "This lab uses [Bicep](https://learn.microsoft.com/azure/azure-resource-manager/bicep/overview?tabs=bicep) to declarative define all the resources that will be deployed in the specified resource group. Change the parameters or the [main.bicep](main.bicep) directly to try different configurations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the resource group if doesn't exist\n",
    "utils.create_resource_group(resource_group_name, resource_group_location)\n",
    "\n",
    "# Define the Bicep parameters\n",
    "bicep_parameters = {\n",
    "    \"$schema\": \"https://schema.management.azure.com/schemas/2019-04-01/deploymentParameters.json#\",\n",
    "    \"contentVersion\": \"1.0.0.0\",\n",
    "    \"parameters\": {\n",
    "        \"apimSku\": { \"value\": apim_sku },\n",
    "        \"aiServicesConfig\": { \"value\": aiservices_config },\n",
    "        \"modelsConfig\": { \"value\": models_config },\n",
    "        \"apimSubscriptionsConfig\": { \"value\": apim_subscriptions_config },\n",
    "        \"inferenceAPIPath\": { \"value\": inference_api_path },\n",
    "        \"inferenceAPIType\": { \"value\": inference_api_type },\n",
    "        \"foundryProjectName\": { \"value\": foundry_project_name }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Write the parameters to the params.json file\n",
    "with open('params.json', 'w') as bicep_parameters_file:\n",
    "    bicep_parameters_file.write(json.dumps(bicep_parameters))\n",
    "\n",
    "# Run the deployment\n",
    "output = utils.run(f\"az deployment group create --name {deployment_name} --resource-group {resource_group_name} --template-file main.bicep --parameters params.json\",\n",
    "    f\"Deployment '{deployment_name}' succeeded\", f\"Deployment '{deployment_name}' failed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='3'></a>\n",
    "### 3Ô∏è‚É£ Get the deployment outputs\n",
    "\n",
    "Retrieve the required outputs from the Bicep deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain all of the outputs from the deployment\n",
    "output = utils.run(f\"az deployment group show --name {deployment_name} -g {resource_group_name}\", f\"Retrieved deployment: {deployment_name}\", f\"Failed to retrieve deployment: {deployment_name}\")\n",
    "\n",
    "if output.success and output.json_data:\n",
    "    log_analytics_id = utils.get_deployment_output(output, 'logAnalyticsWorkspaceId', 'Log Analytics Id')\n",
    "    apim_service_id = utils.get_deployment_output(output, 'apimServiceId', 'APIM Service Id')\n",
    "    apim_resource_gateway_url = utils.get_deployment_output(output, 'apimResourceGatewayURL', 'APIM API Gateway URL')\n",
    "    apim_subscriptions = json.loads(utils.get_deployment_output(output, 'apimSubscriptions').replace(\"\\'\", \"\\\"\"))\n",
    "    for subscription in apim_subscriptions:\n",
    "        subscription_name = subscription['name']\n",
    "        subscription_key = subscription['key']\n",
    "        utils.print_info(f\"Subscription Name: {subscription_name}\")\n",
    "        utils.print_info(f\"Subscription Key: ****{subscription_key[-4:]}\")\n",
    "    api_key = apim_subscriptions[0].get(\"key\") # default api key to the first subscription key\n",
    "    app_insights_name = utils.get_deployment_output(output, 'applicationInsightsName', 'Application Insights Name')\n",
    "    foundry_project_endpoint = utils.get_deployment_output(output, 'foundryProjectEndpoint', 'Foundry Project Endpoint')\n",
    "    bing_search_connection_id = utils.get_deployment_output(output, 'bingSearchConnectionId', 'Bing Search Connection Id')\n",
    "    weather_api_connection_id = utils.get_deployment_output(output, 'weatherAPIConnectionId', 'Weather API Connection Id')\n",
    "    place_order_api_connection_id = utils.get_deployment_output(output, 'placeOrderAPIConnectionId', 'Place Order API Connection Id')\n",
    "    product_catalog_api_connection_id = utils.get_deployment_output(output, 'productCatalogAPIConnectionId', 'Product Catalog API Connection Id')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='4'></a>\n",
    "### 4Ô∏è‚É£ List the connections\n",
    "\n",
    "Retrieve the connections managed in AI Foundry available for the Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.projects import AIProjectClient\n",
    "from azure.ai.projects.models import ConnectionType\n",
    "from azure.identity import DefaultAzureCredential\n",
    "\n",
    "project_client = AIProjectClient(credential=DefaultAzureCredential(),\n",
    "    endpoint=foundry_project_endpoint)\n",
    "with project_client:\n",
    "    connections = project_client.connections.list()\n",
    "    for connection in connections:\n",
    "        utils.print_info(f\"Name: {connection.name}, Id: {connection.id}, Type: {connection.type}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='quickstart'></a>\n",
    "### üß™ Create and run a Math Tutor Agent with OpenAI Assistants API\n",
    "\n",
    "Check the official documentation for updates on this quickstart:\n",
    "https://learn.microsoft.com/en-us/azure/ai-services/agents/quickstart\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from azure.ai.projects import AIProjectClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.ai.agents.models import CodeInterpreterTool\n",
    "from azure.monitor.opentelemetry import configure_azure_monitor\n",
    "\n",
    "\n",
    "from azure.core.settings import settings\n",
    "settings.tracing_implementation = \"opentelemetry\"\n",
    "\n",
    "from opentelemetry import trace\n",
    "from opentelemetry.sdk.trace import TracerProvider\n",
    "from opentelemetry.sdk.trace.export import SimpleSpanProcessor, ConsoleSpanExporter\n",
    "from azure.ai.projects import enable_telemetry\n",
    "from opentelemetry import trace\n",
    "\n",
    "# Setup tracing to console\n",
    "#span_exporter = ConsoleSpanExporter()\n",
    "#tracer_provider = TracerProvider()\n",
    "#tracer_provider.add_span_processor(SimpleSpanProcessor(span_exporter))\n",
    "#trace.set_tracer_provider(tracer_provider)\n",
    "#enable_telemetry(destination=sys.stdout)\n",
    "#tracer = trace.get_tracer(__name__)\n",
    "\n",
    "\n",
    "# Create an Azure AI Client from an endpoint, copied from your Azure AI Foundry project.\n",
    "# You need to login to Azure subscription via Azure CLI and set the environment variables\n",
    "\n",
    "# Create an AIProjectClient instance\n",
    "project_client = AIProjectClient(\n",
    "    endpoint=foundry_project_endpoint,\n",
    "    credential=DefaultAzureCredential(),  # Use Azure Default Credential for authentication\n",
    ")\n",
    "\n",
    "\n",
    "code_interpreter = CodeInterpreterTool()\n",
    "with project_client:\n",
    "    agent = project_client.agents.create_agent(\n",
    "        model=str(models_config[0].get('name')),\n",
    "        name=\"my-agent\",  # Name of the agent\n",
    "        instructions=\"You are a personal math tutor. Answer questions briefly, in a sentence or less.\",  # Instructions for the agent\n",
    "        tools=code_interpreter.definitions,  # Attach the tool\n",
    "        \n",
    "    )\n",
    "    print(f\"Created agent, ID: {agent.id}\")\n",
    "\n",
    "    # Create a thread for communication\n",
    "    thread = project_client.agents.threads.create()\n",
    "    print(f\"Created thread, ID: {thread.id}\")\n",
    "    \n",
    "    # Add a message to the thread\n",
    "    message = project_client.agents.messages.create(\n",
    "        thread_id=thread.id,\n",
    "        role=\"user\",  # Role of the message sender\n",
    "        content=\"I need to solve the equation `3x + 11 = 14`. Can you help me?\",  # Message content\n",
    "    )\n",
    "    print(f\"Created message, ID: {message['id']}\")\n",
    "    \n",
    "    # Create and process an agent run\n",
    "    run = project_client.agents.runs.create_and_process(thread_id=thread.id, agent_id=agent.id)\n",
    "    print(f\"Run finished with status: {run.status}\")\n",
    "    \n",
    "    # Check if the run failed\n",
    "    if run.status == \"failed\":\n",
    "        print(f\"Run failed: {run.last_error}\")\n",
    "    \n",
    "    # Fetch and log all messages\n",
    "    messages = project_client.agents.messages.list(thread_id=thread.id)\n",
    "    for message in messages:\n",
    "        print(f\"Role: {message.role}, Content: {message.content}\")\n",
    "    \n",
    "    # Delete the agent when done\n",
    "    project_client.agents.delete_agent(agent.id)\n",
    "    print(\"Deleted agent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='weatherapi'></a>\n",
    "### üß™ Run agent with Weather API from Azure API Management\n",
    "\n",
    "üëâ Check the [Azure AI Foundry Tracing](https://learn.microsoft.com/en-us/azure/ai-studio/concepts/trace) information to understand the execution process.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following code was adapted from this sample:\n",
    "# https://github.com/Azure/azure-sdk-for-python/blob/main/sdk/ai/azure-ai-projects/samples/agents/sample_agents_openapi.py\n",
    "\n",
    "import jsonref\n",
    "from azure.ai.projects import AIProjectClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.ai.agents.models import OpenApiTool, OpenApiConnectionAuthDetails, OpenApiConnectionSecurityScheme\n",
    "from azure.monitor.opentelemetry import configure_azure_monitor\n",
    "\n",
    "prompt_content = \"Return a summary of the temperature in Seattle and 3 other sister cities in Europe?\"\n",
    "\n",
    "# Initialize the project client using the endpoint and default credentials\n",
    "with AIProjectClient(\n",
    "    endpoint=foundry_project_endpoint,\n",
    "    credential=DefaultAzureCredential(exclude_interactive_browser_credential=False)\n",
    ") as project_client:\n",
    "    # </initialization>\n",
    "\n",
    "    with open(\"./city-weather-openapi.json\", \"r\") as f:\n",
    "        openapi_weather = jsonref.loads(f.read().replace(\"https://replace-me.local/weatherservice\", f\"{apim_resource_gateway_url}/weatherservice\"))\n",
    "\n",
    "    openapi_tool = OpenApiTool(name=\"get_weather\", spec=openapi_weather, description=\"Retrieve weather information for a location\", \n",
    "        auth=OpenApiConnectionAuthDetails(security_scheme=OpenApiConnectionSecurityScheme(connection_id=weather_api_connection_id)))\n",
    "\n",
    "    # <agent_creation>\n",
    "    # --- Agent Creation ---\n",
    "    # Create an agent configured with the combined OpenAPI tool definitions\n",
    "    agent = project_client.agents.create_agent(\n",
    "        model=str(models_config[0].get('name')), # Specify the model deployment\n",
    "        name=\"my-agent\", # Give the agent a name\n",
    "        instructions=\"You are a helpful agent\", # Define agent's role\n",
    "        tools=openapi_tool.definitions, # Provide the list of tool definitions\n",
    "    )\n",
    "    print(f\"Created agent, ID: {agent.id}\")\n",
    "    # </agent_creation>\n",
    "\n",
    "    # <thread_management>\n",
    "    # --- Thread Management ---\n",
    "    # Create a new conversation thread for the interaction\n",
    "    thread = project_client.agents.threads.create()\n",
    "    print(f\"Created thread, ID: {thread.id}\")\n",
    "\n",
    "    # Create the initial user message in the thread\n",
    "    message = project_client.agents.messages.create(\n",
    "        thread_id=thread.id,\n",
    "        role=\"user\",\n",
    "        content=prompt_content,\n",
    "    )\n",
    "    print(f\"Created message, ID: {message.id}\")\n",
    "    # </thread_management>\n",
    "\n",
    "    # <message_processing>\n",
    "    # --- Message Processing (Run Creation and Auto-processing) ---\n",
    "    # Create and automatically process the run, handling tool calls internally\n",
    "    # Note: This differs from the function_tool example where tool calls are handled manually\n",
    "    run = project_client.agents.runs.create_and_process(thread_id=thread.id, agent_id=agent.id)\n",
    "    print(f\"Run finished with status: {run.status}\")\n",
    "    # </message_processing>\n",
    "\n",
    "    # <tool_execution_loop> # Note: This section now processes completed steps, as create_and_process_run handles execution\n",
    "    # --- Post-Run Step Analysis ---\n",
    "    if run.status == \"failed\":\n",
    "        print(f\"Run failed: {run.last_error}\")\n",
    "\n",
    "    # Retrieve the steps taken during the run for analysis\n",
    "    run_steps = project_client.agents.run_steps.list(thread_id=thread.id, run_id=run.id)\n",
    "\n",
    "    # Loop through each step to display information\n",
    "    for step in run_steps:\n",
    "        print(f\"Step {step['id']} status: {step['status']}\")\n",
    "\n",
    "        # Check if there are tool calls recorded in the step details\n",
    "        step_details = step.get(\"step_details\", {})\n",
    "        tool_calls = step_details.get(\"tool_calls\", [])\n",
    "\n",
    "        if tool_calls:\n",
    "            print(\"  Tool calls:\")\n",
    "            for call in tool_calls:\n",
    "                print(f\"    Tool Call ID: {call.get('id')}\")\n",
    "                print(f\"    Type: {call.get('type')}\")\n",
    "\n",
    "                function_details = call.get(\"function\", {})\n",
    "                if function_details:\n",
    "                    print(f\"    Function name: {function_details.get('name')}\")\n",
    "                    print(f\"    Function output: {function_details.get('output')}\")\n",
    "        print() # Add an extra newline between steps for readability\n",
    "    # </tool_execution_loop>\n",
    "\n",
    "    # <cleanup>\n",
    "    # --- Cleanup ---\n",
    "    # Delete the agent resource to clean up\n",
    "    project_client.agents.delete_agent(agent.id)\n",
    "    print(\"Deleted agent\")\n",
    "\n",
    "    # Fetch and log all messages exchanged during the conversation thread\n",
    "    messages = project_client.agents.messages.list(thread_id=thread.id)\n",
    "    for message in messages:\n",
    "        print(f\"Message ID: {message.id}, Role: {message.role}, Content: {message.content}\")\n",
    "    # </cleanup>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='logicapp'></a>\n",
    "### üß™ Run agent operations with OpenAPI Backend and Logic Apps workflow\n",
    "\n",
    "‚öôÔ∏è **Tools**:\n",
    "- Get Product Catalog - OpenAPI Backend mocked with an APIM policy.\n",
    "- Place Order - A Logic Apps workflow that processes orders with a maximum of five items.\n",
    "\n",
    "‚ú® **Expected Behavior**:\n",
    "- The agent receives a user request to order 11 smartphones.\n",
    "- The agent calls the product catalog API to retrieve the product SKU and available stock quantity.\n",
    "- If the order quantity exceeds available stock, the agent will respond that the order cannot be processed due to insufficient stock.\n",
    "- If stock is available, the agent will initiate the order workflow, which will fail because the quantity exceeds the maximum limit of five items.\n",
    "- As the agent was instructed to recover from errors, it will place multiple orders, each with a quantity below the maximum limit, ensuring the total equals the desired order quantity.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following code was adapted from this sample:\n",
    "# https://github.com/Azure/azure-sdk-for-python/blob/main/sdk/ai/azure-ai-projects/samples/agents/sample_agents_openapi.py\n",
    "\n",
    "import jsonref\n",
    "from azure.ai.projects import AIProjectClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.ai.agents.models import OpenApiTool, OpenApiConnectionAuthDetails, OpenApiConnectionSecurityScheme\n",
    "from azure.monitor.opentelemetry import configure_azure_monitor\n",
    "\n",
    "prompt_content = \"List the available smartphones in the catalog and place an order for one of each for me and my 10 friends.\"\n",
    "\n",
    "# Initialize the project client using the endpoint and default credentials\n",
    "with AIProjectClient(\n",
    "    endpoint=foundry_project_endpoint,\n",
    "    credential=DefaultAzureCredential(exclude_interactive_browser_credential=False)\n",
    ") as project_client:\n",
    "    \n",
    "    with open(\"./product-catalog-openapi.json\", \"r\") as f:\n",
    "        openapi_product_catalog = jsonref.loads(f.read().replace(\"https://replace-me.local/catalogservice\", f\"{apim_resource_gateway_url}/catalogservice\"))\n",
    "    openapi_tools = OpenApiTool(name=\"get_product_catalog\", spec=openapi_product_catalog, description=\"Retrieve the list of products available in the catalog\", \n",
    "        auth=OpenApiConnectionAuthDetails(security_scheme=OpenApiConnectionSecurityScheme(connection_id=product_catalog_api_connection_id)))\n",
    "\n",
    "    with open(\"./place-order-openapi.json\", \"r\") as f:\n",
    "        openapi_place_order = jsonref.loads(f.read().replace(\"https://replace-me.local/orderservice\", f\"{apim_resource_gateway_url}/orderservice\"))\n",
    "    openapi_tools.add_definition(name=\"place_order\", spec=openapi_place_order, description=\"Place a product order\", \n",
    "        auth=OpenApiConnectionAuthDetails(security_scheme=OpenApiConnectionSecurityScheme(connection_id=place_order_api_connection_id)))\n",
    "\n",
    "    # <agent_creation>\n",
    "    # --- Agent Creation ---\n",
    "    # Create an agent configured with the combined OpenAPI tool definitions\n",
    "    agent = project_client.agents.create_agent(\n",
    "        model=str(models_config[0].get('name')), # Specify the model deployment\n",
    "        name=\"my-agent\", # Give the agent a name\n",
    "        instructions=\"You are a helpful sales assistant that helps users order products. Recover from errors if any and place multiple orders if needed.\",\n",
    "        tools=openapi_tool.definitions, # Provide the list of tool definitions\n",
    "    )\n",
    "    print(f\"Created agent, ID: {agent.id}\")\n",
    "    # </agent_creation>\n",
    "\n",
    "    # <thread_management>\n",
    "    # --- Thread Management ---\n",
    "    # Create a new conversation thread for the interaction\n",
    "    thread = project_client.agents.threads.create()\n",
    "    print(f\"Created thread, ID: {thread.id}\")\n",
    "\n",
    "    # Create the initial user message in the thread\n",
    "    message = project_client.agents.messages.create(\n",
    "        thread_id=thread.id,\n",
    "        role=\"user\",\n",
    "        content=prompt_content,\n",
    "    )\n",
    "    print(f\"Created message, ID: {message.id}\")\n",
    "    # </thread_management>\n",
    "\n",
    "    # <message_processing>\n",
    "    # --- Message Processing (Run Creation and Auto-processing) ---\n",
    "    # Create and automatically process the run, handling tool calls internally\n",
    "    # Note: This differs from the function_tool example where tool calls are handled manually\n",
    "    run = project_client.agents.runs.create_and_process(thread_id=thread.id, agent_id=agent.id)\n",
    "    print(f\"Run finished with status: {run.status}\")\n",
    "    # </message_processing>\n",
    "\n",
    "    # <tool_execution_loop> # Note: This section now processes completed steps, as create_and_process_run handles execution\n",
    "    # --- Post-Run Step Analysis ---\n",
    "    if run.status == \"failed\":\n",
    "        print(f\"Run failed: {run.last_error}\")\n",
    "\n",
    "    # Retrieve the steps taken during the run for analysis\n",
    "    run_steps = project_client.agents.run_steps.list(thread_id=thread.id, run_id=run.id)\n",
    "\n",
    "    # Loop through each step to display information\n",
    "    for step in run_steps:\n",
    "        print(f\"Step {step['id']} status: {step['status']}\")\n",
    "\n",
    "        # Check if there are tool calls recorded in the step details\n",
    "        step_details = step.get(\"step_details\", {})\n",
    "        tool_calls = step_details.get(\"tool_calls\", [])\n",
    "\n",
    "        if tool_calls:\n",
    "            print(\"  Tool calls:\")\n",
    "            for call in tool_calls:\n",
    "                print(f\"    Tool Call ID: {call.get('id')}\")\n",
    "                print(f\"    Type: {call.get('type')}\")\n",
    "\n",
    "                function_details = call.get(\"function\", {})\n",
    "                if function_details:\n",
    "                    print(f\"    Function name: {function_details.get('name')}\")\n",
    "                    print(f\"    Function output: {function_details.get('output')}\")\n",
    "        print() # Add an extra newline between steps for readability\n",
    "    # </tool_execution_loop>\n",
    "\n",
    "    # <cleanup>\n",
    "    # --- Cleanup ---\n",
    "    # Delete the agent resource to clean up\n",
    "    project_client.agents.delete_agent(agent.id)\n",
    "    print(\"Deleted agent\")\n",
    "\n",
    "    # Fetch and log all messages exchanged during the conversation thread\n",
    "    messages = project_client.agents.messages.list(thread_id=thread.id)\n",
    "    for message in messages:\n",
    "        print(f\"Message ID: {message.id}, Role: {message.role}, Content: {message.content}\")\n",
    "    # </cleanup>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='kql'></a>\n",
    "### üîç Analyze Application Insights custom metrics with a KQL query\n",
    "\n",
    "With this query you can get the custom metrics that were emitted by Azure APIM. Note that it may take a few minutes for data to become available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "query = \"\\\"\" + \"customMetrics \\\n",
    "| where name == 'Total Tokens' \\\n",
    "| where timestamp >= ago(1h) \\\n",
    "| extend parsedCustomDimensions = parse_json(customDimensions) \\\n",
    "| extend apimSubscription = tostring(parsedCustomDimensions.['Subscription ID']) \\\n",
    "| extend agentID = tostring(parsedCustomDimensions.['Agent ID']) \\\n",
    "| summarize TotalValue = sum(value) by apimSubscription, bin(timestamp, 1m), agentID \\\n",
    "| order by timestamp asc\" + \"\\\"\"\n",
    "\n",
    "output = utils.run(f\"az monitor app-insights query --app {app_insights_name} -g {resource_group_name} --analytics-query {query}\",\n",
    "    f\"App Insights query succeeded\", f\"App Insights query  failed\")\n",
    "\n",
    "table = output.json_data['tables'][0]\n",
    "df = pd.DataFrame(table.get(\"rows\"), columns = [col.get(\"name\") for col in table.get('columns')])\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp']).dt.strftime('%H:%M')\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='plot'></a>\n",
    "### üîç Plot the custom metrics results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.figsize'] = [15, 7]\n",
    "if df.empty:\n",
    "    print(\"No data to plot\")\n",
    "else:\n",
    "    df_pivot = df.pivot(index='timestamp', columns='apimSubscription', values='TotalValue')\n",
    "    ax = df_pivot.plot(kind='bar', stacked=True)\n",
    "    plt.title('Total token usage over time by APIM Subscription')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Tokens')\n",
    "    plt.legend(title='APIM Subscription')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='clean'></a>\n",
    "### üóëÔ∏è Clean up resources\n",
    "\n",
    "When you're finished with the lab, you should remove all your deployed resources from Azure to avoid extra charges and keep your Azure subscription uncluttered.\n",
    "Use the [clean-up-resources notebook](clean-up-resources.ipynb) for that."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
