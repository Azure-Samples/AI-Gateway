{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# APIM ‚ù§Ô∏è AI Agents\n",
    "\n",
    "## Azure AI Agent Service lab\n",
    "\n",
    "![flow](../../images/ai-agent-service.gif)\n",
    "\n",
    "Use this playground to explore the [Azure AI Agent Service](https://learn.microsoft.com/en-us/azure/ai-services/agents/overview), leveraging Azure API Management to control multiple services, including Azure OpenAI models, Bing Web Search, Logic Apps Workflows, and OpenAPI-based APIs. This enables limitless opportunities for AI agents while maintaining control through Azure API Management!\n",
    "\n",
    "### Prerequisites\n",
    "\n",
    "- [Python 3.12 or later version](https://www.python.org/) installed\n",
    "- [VS Code](https://code.visualstudio.com/) installed with the [Jupyter notebook extension](https://marketplace.visualstudio.com/items?itemName=ms-toolsai.jupyter) enabled\n",
    "- [Python environment](https://code.visualstudio.com/docs/python/environments#_creating-environments) with the [requirements.txt](../../requirements.txt) or run `pip install -r requirements.txt` in your terminal\n",
    "- [An Azure Subscription](https://azure.microsoft.com/free/) with [Contributor](https://learn.microsoft.com/en-us/azure/role-based-access-control/built-in-roles/privileged#contributor) + [RBAC Administrator](https://learn.microsoft.com/en-us/azure/role-based-access-control/built-in-roles/privileged#role-based-access-control-administrator) or [Owner](https://learn.microsoft.com/en-us/azure/role-based-access-control/built-in-roles/privileged#owner) roles\n",
    "- [Azure CLI](https://learn.microsoft.com/cli/azure/install-azure-cli) installed and [Signed into your Azure subscription](https://learn.microsoft.com/cli/azure/authenticate-azure-cli-interactively)\n",
    "\n",
    "‚ñ∂Ô∏è Click `Run All` to execute all steps sequentially, or execute them `Step by Step`..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='0'></a>\n",
    "### 0Ô∏è‚É£ Initialize notebook variables\n",
    "\n",
    "- Resources will be suffixed by a unique string based on your subscription id.\n",
    "- Adjust the location parameters according your preferences and on the [product availability by Azure region.](https://azure.microsoft.com/explore/global-infrastructure/products-by-region/?cdn=disable&products=cognitive-services,api-management) \n",
    "- Adjust the OpenAI model and version according the [availability by region.](https://learn.microsoft.com/azure/ai-services/openai/concepts/models) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import os, sys, json\n",
    "sys.path.insert(1, '../../shared')  # add the shared directory to the Python path\n",
    "import utils\n",
    "\n",
    "deployment_name = os.path.basename(os.path.dirname(globals()['__vsc_ipynb_file__']))\n",
    "resource_group_name = f\"lab-{deployment_name}\" # change the name to match your naming convention\n",
    "resource_group_location = \"eastus2\" # all the resources will be deployed in this location\n",
    "\n",
    "apim_sku = 'Basicv2'\n",
    "\n",
    "# Azure OpenAI configuration\n",
    "openai_resources = [ {\"name\": \"openai1\", \"location\": \"eastus2\"} ]\n",
    "openai_model_name = \"gpt-4o\"\n",
    "openai_model_version = \"2024-08-06\"\n",
    "openai_model_sku = \"GlobalStandard\"\n",
    "openai_model_capacity = 200\n",
    "openai_deployment_name = \"gpt-4o\"\n",
    "openai_api_version = \"2025-01-01-preview\"\n",
    "\n",
    "utils.print_ok('Notebook initialized')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='1'></a>\n",
    "### 1Ô∏è‚É£ Verify the Azure CLI and the connected Azure subscription\n",
    "\n",
    "The following commands ensure that you have the latest version of the Azure CLI and that the Azure CLI is connected to your Azure subscription."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = utils.run(\"az account show\", \"Retrieved az account\", \"Failed to get the current az account\")\n",
    "\n",
    "if output.success and output.json_data:\n",
    "    current_user = output.json_data['user']['name']\n",
    "    tenant_id = output.json_data['tenantId']\n",
    "    subscription_id = output.json_data['id']\n",
    "\n",
    "    utils.print_info(f\"Current user: {current_user}\")\n",
    "    utils.print_info(f\"Tenant ID: {tenant_id}\")\n",
    "    utils.print_info(f\"Subscription ID: {subscription_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='2'></a>\n",
    "### 2Ô∏è‚É£ Create deployment using ü¶æ Bicep\n",
    "\n",
    "This lab uses [Bicep](https://learn.microsoft.com/azure/azure-resource-manager/bicep/overview?tabs=bicep) to declarative define all the resources that will be deployed in the specified resource group. Change the parameters or the [main.bicep](main.bicep) directly to try different configurations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the resource group if doesn't exist\n",
    "utils.create_resource_group(resource_group_name, resource_group_location)\n",
    "\n",
    "# Define the Bicep parameters\n",
    "bicep_parameters = {\n",
    "    \"$schema\": \"https://schema.management.azure.com/schemas/2019-04-01/deploymentParameters.json#\",\n",
    "    \"contentVersion\": \"1.0.0.0\",\n",
    "    \"parameters\": {\n",
    "        \"apimSku\": { \"value\": apim_sku },\n",
    "        \"openAIConfig\": { \"value\": openai_resources },\n",
    "        \"openAIDeploymentName\": { \"value\": openai_deployment_name },\n",
    "        \"openAIModelName\": { \"value\": openai_model_name },\n",
    "        \"openAIModelVersion\": { \"value\": openai_model_version },\n",
    "        \"openAIModelSKU\": { \"value\": openai_model_sku },\n",
    "        \"openAIModelCapacity\": { \"value\": openai_model_capacity },\n",
    "        \"openAIAPIVersion\": { \"value\": openai_api_version }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Write the parameters to the params.json file\n",
    "with open('params.json', 'w') as bicep_parameters_file:\n",
    "    bicep_parameters_file.write(json.dumps(bicep_parameters))\n",
    "\n",
    "# Run the deployment\n",
    "output = utils.run(f\"az deployment group create --name {deployment_name} --resource-group {resource_group_name} --template-file main.bicep --parameters params.json\",\n",
    "    f\"Deployment '{deployment_name}' succeeded\", f\"Deployment '{deployment_name}' failed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='3'></a>\n",
    "### 3Ô∏è‚É£ Get the deployment outputs\n",
    "\n",
    "Retrieve the required outputs from the Bicep deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain all of the outputs from the deployment\n",
    "output = utils.run(f\"az deployment group show --name {deployment_name} -g {resource_group_name}\", f\"Retrieved deployment: {deployment_name}\", f\"Failed to retrieve deployment: {deployment_name}\")\n",
    "\n",
    "if output.success and output.json_data:\n",
    "    app_insights_name = utils.get_deployment_output(output, 'applicationInsightsName', 'Application Insights Name')    \n",
    "    apim_resource_gateway_url = utils.get_deployment_output(output, 'apimResourceGatewayURL', 'APIM API Gateway URL')\n",
    "    project_connection_string = utils.get_deployment_output(output, 'projectConnectionString', 'AI Foundry Project Connection String', True)\n",
    "    bing_search_connection = utils.get_deployment_output(output, 'bingSearchConnectionName', 'Bing Search Connection')\n",
    "    weather_api_connection_id = utils.get_deployment_output(output, 'weatherAPIConnectionId', 'Weather API Connection Id')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='4'></a>\n",
    "### 4Ô∏è‚É£ List the connections\n",
    "\n",
    "Retrieve the connections managed in AI Foundry available for the Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.projects import AIProjectClient\n",
    "from azure.ai.projects.models import ConnectionType\n",
    "from azure.identity import DefaultAzureCredential\n",
    "\n",
    "project_client = AIProjectClient.from_connection_string(\n",
    "    credential=DefaultAzureCredential(),\n",
    "    conn_str=project_connection_string,\n",
    ")\n",
    "\n",
    "with project_client:\n",
    "    connections = project_client.connections.list()\n",
    "    utils.print_ok(f\"Listing all connections (found {len(connections)}):\")\n",
    "    for connection in connections:\n",
    "        utils.print_info(f\"Name: {connection.name}, Type: {connection.connection_type}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='quickstart'></a>\n",
    "### üß™ Create and run a Math Tutor Agent with OpenAI Assistants API\n",
    "\n",
    "Check the official documentation for updates on this quickstart:\n",
    "https://learn.microsoft.com/en-us/azure/ai-services/agents/quickstart\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, logging\n",
    "from azure.ai.projects import AIProjectClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "with AIProjectClient.from_connection_string(\n",
    "    credential=DefaultAzureCredential(),\n",
    "    conn_str=project_connection_string,\n",
    "    logging_enable = True\n",
    ") as project_client:\n",
    "    client: AzureOpenAI = project_client.inference.get_azure_openai_client(\n",
    "        api_version = openai_api_version  \n",
    "    )\n",
    "\n",
    "    with client:\n",
    "        agent = client.beta.assistants.create(\n",
    "            model=openai_deployment_name, name=\"my-agent\", instructions=\"'You are a personal math tutor. Answer questions briefly, in a sentence or less.\"\n",
    "        )\n",
    "        utils.print_ok(f\"Created agent, agent ID: {agent.id}\")\n",
    "\n",
    "        thread = client.beta.threads.create()\n",
    "        utils.print_ok(f\"Created thread, thread ID: {thread.id}\")\n",
    "\n",
    "        message = client.beta.threads.messages.create(thread_id=thread.id, role=\"user\", content=\"I need to solve the equation `3x + 11 = 14`. Can you help me?\",\n",
    "            extra_headers={\"x-agent-id\": \"agent1\"}   )\n",
    "        utils.print_ok(f\"Created message, message ID: {message.id}\")\n",
    "\n",
    "        run = client.beta.threads.runs.create(thread_id=thread.id, assistant_id=agent.id,\n",
    "            extra_headers={\"x-agent-id\": \"agent1\"}   )\n",
    "\n",
    "        # Poll the run while run status is queued or in progress\n",
    "        while run.status in [\"queued\", \"in_progress\", \"requires_action\"]:\n",
    "            time.sleep(1)  # Wait for a second\n",
    "            run = client.beta.threads.runs.retrieve(thread_id=thread.id, run_id=run.id)\n",
    "            utils.print_ok(f\"Run status: {run.status}\")\n",
    "\n",
    "        client.beta.assistants.delete(agent.id)\n",
    "        utils.print_ok(\"Deleted agent\")\n",
    "\n",
    "        messages = client.beta.threads.messages.list(thread_id=thread.id)\n",
    "        print(f\"üó®Ô∏è {messages.data[0].content[0].text.value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='functions'></a>\n",
    "### üß™ Run agent operations with local function tools\n",
    "\n",
    "üëâ Check the [Azure AI Foundry Tracing](https://learn.microsoft.com/en-us/azure/ai-studio/concepts/trace) information to understand the execution process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following code was copied from this sample:\n",
    "# https://github.com/Azure/azure-sdk-for-python/blob/main/sdk/ai/azure-ai-projects/samples/agents/sample_agents_functions_with_azure_monitor_tracing.py\n",
    "\n",
    "from typing import Any, Callable, Set\n",
    "\n",
    "import time, json\n",
    "from azure.ai.projects import AIProjectClient\n",
    "from azure.ai.projects.telemetry import trace_function\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.ai.projects.models import FunctionTool, RequiredFunctionToolCall, SubmitToolOutputsAction, ToolOutput\n",
    "from opentelemetry import trace\n",
    "from azure.monitor.opentelemetry import configure_azure_monitor\n",
    "\n",
    "project_client = AIProjectClient.from_connection_string(\n",
    "    credential=DefaultAzureCredential(), conn_str=project_connection_string\n",
    ")\n",
    "\n",
    "# Enable Azure Monitor tracing\n",
    "application_insights_connection_string = project_client.telemetry.get_connection_string()\n",
    "if not application_insights_connection_string:\n",
    "    utils.print_error(\"Application Insights was not enabled for this project.\")\n",
    "    utils.print_error(\"Enable it via the 'Tracing' tab in your AI Foundry project page.\")\n",
    "    raise RuntimeError(\"Application Insights was not enabled for this project.\")\n",
    "    \n",
    "configure_azure_monitor(connection_string=application_insights_connection_string)\n",
    "\n",
    "scenario = deployment_name\n",
    "tracer = trace.get_tracer(deployment_name)\n",
    "\n",
    "# The trace_func decorator will trace the function call and enable adding additional attributes\n",
    "# to the span in the function implementation. Note that this will trace the function parameters and their values.\n",
    "@trace_function()\n",
    "def fetch_weather(location: str) -> str:\n",
    "    \"\"\"\n",
    "    Fetches the weather information for the specified location.\n",
    "\n",
    "    :param location (str): The location to fetch weather for.\n",
    "    :return: Weather information as a JSON string.\n",
    "    :rtype: str\n",
    "    \"\"\"\n",
    "    # In a real-world scenario, you'd integrate with a weather API.\n",
    "    # Here, we'll mock the response.\n",
    "    mock_weather_data = {\"New York\": \"Sunny, 25¬∞C\", \"London\": \"Cloudy, 18¬∞C\", \"Tokyo\": \"Rainy, 22¬∞C\"}\n",
    "\n",
    "    # Adding attributes to the current span\n",
    "    span = trace.get_current_span()\n",
    "    span.set_attribute(\"requested_location\", location)\n",
    "\n",
    "    weather = mock_weather_data.get(location, \"Weather data not available for this location.\")\n",
    "    weather_json = json.dumps({\"weather\": weather})\n",
    "    return weather_json\n",
    "\n",
    "\n",
    "# Statically defined user functions for fast reference\n",
    "user_functions: Set[Callable[..., Any]] = {\n",
    "    fetch_weather,\n",
    "}\n",
    "\n",
    "# Initialize function tool with user function\n",
    "functions = FunctionTool(functions=user_functions)\n",
    "\n",
    "with tracer.start_as_current_span(scenario):\n",
    "    with project_client:\n",
    "        # Create an agent and run user's request with function calls\n",
    "        agent = project_client.agents.create_agent(\n",
    "            model=openai_deployment_name,\n",
    "            name=\"my-assistant\",\n",
    "            instructions=\"You are a helpful assistant\",\n",
    "            tools=functions.definitions,\n",
    "        )\n",
    "        utils.print_ok(f\"Created agent, ID: {agent.id}\")\n",
    "\n",
    "        thread = project_client.agents.create_thread()\n",
    "        utils.print_ok(f\"Created thread, ID: {thread.id}\")\n",
    "\n",
    "        message = project_client.agents.create_message(\n",
    "            thread_id=thread.id,\n",
    "            role=\"user\",\n",
    "            content=\"Hello, what is the weather in New York and sister cities?\",\n",
    "        )\n",
    "        utils.print_ok(f\"Created message, ID: {message.id}\")\n",
    "\n",
    "        run = project_client.agents.create_run(thread_id=thread.id, assistant_id=agent.id)\n",
    "        utils.print_ok(f\"Created run, ID: {run.id}\")\n",
    "\n",
    "        while run.status in [\"queued\", \"in_progress\", \"requires_action\"]:\n",
    "            time.sleep(1)\n",
    "            run = project_client.agents.get_run(thread_id=thread.id, run_id=run.id)\n",
    "\n",
    "            if run.status == \"requires_action\" and isinstance(run.required_action, SubmitToolOutputsAction):\n",
    "                tool_calls = run.required_action.submit_tool_outputs.tool_calls\n",
    "                if not tool_calls:\n",
    "                    utils.print_error(\"No tool calls provided - cancelling run\")\n",
    "                    project_client.agents.cancel_run(thread_id=thread.id, run_id=run.id)\n",
    "                    break\n",
    "\n",
    "                tool_outputs = []\n",
    "                for tool_call in tool_calls:\n",
    "                    if isinstance(tool_call, RequiredFunctionToolCall):\n",
    "                        try:\n",
    "                            output = functions.execute(tool_call)\n",
    "                            tool_outputs.append(\n",
    "                                ToolOutput(\n",
    "                                    tool_call_id=tool_call.id,\n",
    "                                    output=output,\n",
    "                                )\n",
    "                            )\n",
    "                        except Exception as e:\n",
    "                            utils.print_error(f\"Error executing tool_call {tool_call.id}: {e}\")\n",
    "\n",
    "                utils.print_ok(f\"Tool outputs: {tool_outputs}\")\n",
    "                if tool_outputs:\n",
    "                    project_client.agents.submit_tool_outputs_to_run(\n",
    "                        thread_id=thread.id, run_id=run.id, tool_outputs=tool_outputs\n",
    "                    )\n",
    "\n",
    "            utils.print_ok(f\"Current run status: {run.status}\")\n",
    "\n",
    "        utils.print_ok(f\"Run completed with status: {run.status}\")\n",
    "\n",
    "        # Delete the agent when done\n",
    "        project_client.agents.delete_agent(agent.id)\n",
    "        utils.print_ok(\"Deleted agent\")\n",
    "\n",
    "        # Fetch and log all messages\n",
    "        messages = project_client.agents.list_messages(thread_id=thread.id)\n",
    "        print(f\"üó®Ô∏è {messages.data[0].content[0].text.value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='weatherapi'></a>\n",
    "### üß™ Run agent with Weather API from Azure API Management\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following code was copied from this sample:\n",
    "# https://github.com/Azure/azure-sdk-for-python/blob/main/sdk/ai/azure-ai-projects/samples/agents/sample_agents_openapi.py\n",
    "\n",
    "import jsonref\n",
    "from azure.ai.projects import AIProjectClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.ai.projects.models import OpenApiTool, OpenApiConnectionAuthDetails, OpenApiConnectionSecurityScheme\n",
    "from azure.monitor.opentelemetry import configure_azure_monitor\n",
    "\n",
    "\n",
    "project_client = AIProjectClient.from_connection_string(\n",
    "    credential=DefaultAzureCredential(),\n",
    "    conn_str=project_connection_string,\n",
    ")\n",
    "\n",
    "application_insights_connection_string = project_client.telemetry.get_connection_string()\n",
    "if not application_insights_connection_string:\n",
    "    utils.print_error(\"Application Insights was not enabled for this project.\")\n",
    "    utils.print_error(\"Enable it via the 'Tracing' tab in your AI Foundry project page.\")\n",
    "    raise RuntimeError(\"Application Insights was not enabled for this project.\")\n",
    "    \n",
    "configure_azure_monitor(connection_string=application_insights_connection_string)\n",
    "\n",
    "\n",
    "# [START create_agent_with_openapi]\n",
    "\n",
    "with open(\"./city-weather-openapi.json\", \"r\") as f:\n",
    "    openapi_weather = jsonref.loads(f.read())\n",
    "\n",
    "# Create Auth object for the OpenApiTool (note that connection or managed identity auth setup requires additional setup in Azure)\n",
    "auth = OpenApiConnectionAuthDetails(security_scheme=OpenApiConnectionSecurityScheme(connection_id=weather_api_connection_id))\n",
    "\n",
    "\n",
    "# Initialize agent OpenApi tool using the read in OpenAPI spec\n",
    "openapi_tool = OpenApiTool(\n",
    "    name=\"get_weather\", spec=openapi_weather, description=\"Retrieve weather information for a location\", auth=auth\n",
    ")\n",
    "\n",
    "\n",
    "# Create agent with OpenApi tool and process assistant run\n",
    "with project_client:\n",
    "    agent = project_client.agents.create_agent(\n",
    "        model=openai_deployment_name,\n",
    "        name=\"my-assistant\",\n",
    "        instructions=\"You are a helpful assistant\",\n",
    "        tools=openapi_tool.definitions,\n",
    "    )\n",
    "\n",
    "    # [END create_agent_with_openapi]\n",
    "\n",
    "    print(f\"Created agent, ID: {agent.id}\")\n",
    "\n",
    "    # Create thread for communication\n",
    "    thread = project_client.agents.create_thread()\n",
    "    print(f\"Created thread, ID: {thread.id}\")\n",
    "\n",
    "    # Create message to thread\n",
    "    message = project_client.agents.create_message(\n",
    "        thread_id=thread.id,\n",
    "        role=\"user\",\n",
    "        content=\"What's the weather in Seattle and sister cities?\",\n",
    "    )\n",
    "    print(f\"Created message, ID: {message.id}\")\n",
    "\n",
    "    # Create and process agent run in thread with tools\n",
    "    run = project_client.agents.create_and_process_run(thread_id=thread.id, assistant_id=agent.id)\n",
    "    print(f\"Run finished with status: {run.status}\")\n",
    "\n",
    "    if run.status == \"failed\":\n",
    "        print(f\"Run failed: {run.last_error}\")\n",
    "\n",
    "    run_steps = project_client.agents.list_run_steps(thread_id=thread.id, run_id=run.id)\n",
    "\n",
    "    # Loop through each step\n",
    "    for step in run_steps.data:\n",
    "        print(f\"Step {step['id']} status: {step['status']}\")\n",
    "\n",
    "        # Check if there are tool calls in the step details\n",
    "        step_details = step.get(\"step_details\", {})\n",
    "        tool_calls = step_details.get(\"tool_calls\", [])\n",
    "\n",
    "        if tool_calls:\n",
    "            print(\"  Tool calls:\")\n",
    "            for call in tool_calls:\n",
    "                print(f\"    Tool Call ID: {call.get('id')}\")\n",
    "                print(f\"    Type: {call.get('type')}\")\n",
    "\n",
    "                function_details = call.get(\"function\", {})\n",
    "                if function_details:\n",
    "                    print(f\"    Function name: {function_details.get('name')}\")\n",
    "        print()  # add an extra newline between steps\n",
    "\n",
    "    # Delete the assistant when done\n",
    "    project_client.agents.delete_agent(agent.id)\n",
    "    print(\"Deleted agent\")\n",
    "\n",
    "    # Fetch and log all messages\n",
    "    messages = project_client.agents.list_messages(thread_id=thread.id)\n",
    "    print(f\"Messages: {messages}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='bing'></a>\n",
    "### üß™ Grounding with Bing\n",
    "\n",
    "Check the official documentation for updates on this sample: https://learn.microsoft.com/en-us/azure/ai-services/agents/how-to/tools/bing-grounding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.projects import AIProjectClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.ai.projects.models import BingGroundingTool\n",
    "\n",
    "\n",
    "# Create an Azure AI Client from a connection string, copied from your Azure AI Foundry project.\n",
    "# At the moment, it should be in the format \"<HostName>;<AzureSubscriptionId>;<ResourceGroup>;<HubName>\"\n",
    "# Customer needs to login to Azure subscription via Azure CLI and set the environment variables\n",
    "\n",
    "project_client = AIProjectClient.from_connection_string(\n",
    "    credential=DefaultAzureCredential(),\n",
    "    conn_str=project_connection_string,\n",
    ")\n",
    "\n",
    "bing_connection = project_client.connections.get(\n",
    "    connection_name=bing_search_connection\n",
    ")\n",
    "conn_id = bing_connection.id\n",
    "\n",
    "# Initialize agent bing tool and add the connection id\n",
    "bing = BingGroundingTool(connection_id=conn_id)\n",
    "\n",
    "# Create agent with the bing tool and process assistant run\n",
    "with project_client:\n",
    "    agent = project_client.agents.create_agent(\n",
    "        model=openai_deployment_name,\n",
    "        name=\"my-assistant\",\n",
    "        instructions=\"You are a helpful assistant\",\n",
    "        tools=bing.definitions,\n",
    "        headers={\"x-ms-enable-preview\": \"true\"}\n",
    "    )\n",
    "    \n",
    "    utils.print_ok(f\"Created agent, ID: {agent.id}\")\n",
    "\n",
    "    thread = project_client.agents.create_thread()\n",
    "    utils.print_ok(f\"Created thread, ID: {thread.id}\")\n",
    "\n",
    "    # Create message to thread\n",
    "    message = project_client.agents.create_message(\n",
    "        thread_id=thread.id,\n",
    "        role=\"user\",\n",
    "        content=\"What are the top news today?\",\n",
    "    )\n",
    "    utils.print_ok(f\"Created message, ID: {message.id}\")\n",
    "\n",
    "    # Create and process agent run in thread with tools\n",
    "    run = project_client.agents.create_and_process_run(thread_id=thread.id, assistant_id=agent.id)\n",
    "    utils.print_ok(f\"Run finished with status: {run.status}\")\n",
    "\n",
    "    # Retrieve run step details to get Bing Search query link\n",
    "    # To render the webpage, we recommend you replace the endpoint of Bing search query URLs with `www.bing.com` and your Bing search query URL would look like \"https://www.bing.com/search?q={search query}\"\n",
    "    run_steps = project_client.agents.list_run_steps(run_id=run.id, thread_id=thread.id)\n",
    "    run_steps_data = run_steps['data']\n",
    "\n",
    "    if run.status == \"failed\":\n",
    "        utils.print_error(f\"Run failed: {run.last_error}\")\n",
    "\n",
    "    # Delete the assistant when done\n",
    "    project_client.agents.delete_agent(agent.id)\n",
    "    utils.print_ok(\"Deleted agent\")\n",
    "\n",
    "    # Fetch and log all messages\n",
    "    messages = project_client.agents.list_messages(thread_id=thread.id)\n",
    "    print(f\"üó®Ô∏è {messages.data[0].content[0].text.value}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='kql'></a>\n",
    "### üîç Analyze Application Insights custom metrics with a KQL query\n",
    "\n",
    "With this query you can get the custom metrics that were emitted by Azure APIM. Note that it may take a few minutes for data to become available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "query = \"\\\"\" + \"customMetrics \\\n",
    "| where name == 'Total Tokens' \\\n",
    "| where timestamp >= ago(1h) \\\n",
    "| extend parsedCustomDimensions = parse_json(customDimensions) \\\n",
    "| extend apimSubscription = tostring(parsedCustomDimensions.['Subscription ID']) \\\n",
    "| extend agentID = tostring(parsedCustomDimensions.['Agent ID']) \\\n",
    "| summarize TotalValue = sum(value) by apimSubscription, bin(timestamp, 1m), agentID \\\n",
    "| order by timestamp asc\" + \"\\\"\"\n",
    "\n",
    "output = utils.run(f\"az monitor app-insights query --app {app_insights_name} -g {resource_group_name} --analytics-query {query}\",\n",
    "    f\"App Insights query succeeded\", f\"App Insights query  failed\")\n",
    "\n",
    "table = output.json_data['tables'][0]\n",
    "df = pd.DataFrame(table.get(\"rows\"), columns = [col.get(\"name\") for col in table.get('columns')])\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp']).dt.strftime('%H:%M')\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='plot'></a>\n",
    "### üîç Plot the custom metrics results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.figsize'] = [15, 7]\n",
    "if df.empty:\n",
    "    print(\"No data to plot\")\n",
    "else:\n",
    "    df_pivot = df.pivot(index='timestamp', columns='apimSubscription', values='TotalValue')\n",
    "    ax = df_pivot.plot(kind='bar', stacked=True)\n",
    "    plt.title('Total token usage over time by APIM Subscription')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Tokens')\n",
    "    plt.legend(title='APIM Subscription')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='clean'></a>\n",
    "### üóëÔ∏è Clean up resources\n",
    "\n",
    "When you're finished with the lab, you should remove all your deployed resources from Azure to avoid extra charges and keep your Azure subscription uncluttered.\n",
    "Use the [clean-up-resources notebook](clean-up-resources.ipynb) for that."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
