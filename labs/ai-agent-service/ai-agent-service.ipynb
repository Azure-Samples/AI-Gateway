{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# APIM ‚ù§Ô∏è AI Agents\n",
    "\n",
    "## Azure AI Agent Service lab\n",
    "\n",
    "![flow](../../images/ai-agent-service.gif)\n",
    "\n",
    "Use this playground to explore the [Azure AI Agent Service](https://learn.microsoft.com/en-us/azure/ai-services/agents/overview), leveraging Azure API Management to control multiple services, including Azure OpenAI models, Bing Web Search, Logic Apps Workflows, and OpenAPI-based APIs. This enables limitless opportunities for AI agents while maintaining control through Azure API Management!\n",
    "\n",
    "### Prerequisites\n",
    "\n",
    "- [Python 3.12 or later version](https://www.python.org/) installed\n",
    "- [VS Code](https://code.visualstudio.com/) installed with the [Jupyter notebook extension](https://marketplace.visualstudio.com/items?itemName=ms-toolsai.jupyter) enabled\n",
    "- [Python environment](https://code.visualstudio.com/docs/python/environments#_creating-environments) with the [requirements.txt](../../requirements.txt) or run `pip install -r requirements.txt` in your terminal\n",
    "- [An Azure Subscription](https://azure.microsoft.com/free/) with [Contributor](https://learn.microsoft.com/en-us/azure/role-based-access-control/built-in-roles/privileged#contributor) + [RBAC Administrator](https://learn.microsoft.com/en-us/azure/role-based-access-control/built-in-roles/privileged#role-based-access-control-administrator) or [Owner](https://learn.microsoft.com/en-us/azure/role-based-access-control/built-in-roles/privileged#owner) roles\n",
    "- [Azure CLI](https://learn.microsoft.com/cli/azure/install-azure-cli) installed and [Signed into your Azure subscription](https://learn.microsoft.com/cli/azure/authenticate-azure-cli-interactively)\n",
    "\n",
    "‚ñ∂Ô∏è Click `Run All` to execute all steps sequentially, or execute them `Step by Step`..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='0'></a>\n",
    "### 0Ô∏è‚É£ Initialize notebook variables\n",
    "\n",
    "- Resources will be suffixed by a unique string based on your subscription id.\n",
    "- Adjust the location parameters according your preferences and on the [product availability by Azure region.](https://azure.microsoft.com/explore/global-infrastructure/products-by-region/?cdn=disable&products=cognitive-services,api-management) \n",
    "- Adjust the OpenAI model and version according the [availability by region.](https://learn.microsoft.com/azure/ai-services/openai/concepts/models) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import os, sys, json\n",
    "sys.path.insert(1, '../../shared')  # add the shared directory to the Python path\n",
    "import utils\n",
    "\n",
    "deployment_name = os.path.basename(os.path.dirname(globals()['__vsc_ipynb_file__']))\n",
    "resource_group_name = f\"lab-{deployment_name}\" # change the name to match your naming convention\n",
    "resource_group_location = \"eastus2\" # all the resources will be deployed in this location\n",
    "\n",
    "apim_sku = 'Basicv2'\n",
    "\n",
    "# Azure OpenAI configuration\n",
    "openai_resources = [ {\"name\": \"openai1\", \"location\": \"eastus2\"} ]\n",
    "openai_model_name = \"gpt-4o\"\n",
    "openai_model_version = \"2024-08-06\"\n",
    "openai_model_sku = \"GlobalStandard\"\n",
    "openai_model_capacity = 400\n",
    "openai_deployment_name = \"gpt-4o\"\n",
    "openai_api_version = \"2025-01-01-preview\"\n",
    "\n",
    "utils.print_ok('Notebook initialized')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='1'></a>\n",
    "### 1Ô∏è‚É£ Verify the Azure CLI and the connected Azure subscription\n",
    "\n",
    "The following commands ensure that you have the latest version of the Azure CLI and that the Azure CLI is connected to your Azure subscription."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = utils.run(\"az account show\", \"Retrieved az account\", \"Failed to get the current az account\")\n",
    "\n",
    "if output.success and output.json_data:\n",
    "    current_user = output.json_data['user']['name']\n",
    "    tenant_id = output.json_data['tenantId']\n",
    "    subscription_id = output.json_data['id']\n",
    "\n",
    "    utils.print_info(f\"Current user: {current_user}\")\n",
    "    utils.print_info(f\"Tenant ID: {tenant_id}\")\n",
    "    utils.print_info(f\"Subscription ID: {subscription_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='2'></a>\n",
    "### 2Ô∏è‚É£ Create deployment using ü¶æ Bicep\n",
    "\n",
    "This lab uses [Bicep](https://learn.microsoft.com/azure/azure-resource-manager/bicep/overview?tabs=bicep) to declarative define all the resources that will be deployed in the specified resource group. Change the parameters or the [main.bicep](main.bicep) directly to try different configurations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the resource group if doesn't exist\n",
    "utils.create_resource_group(resource_group_name, resource_group_location)\n",
    "\n",
    "# Define the Bicep parameters\n",
    "bicep_parameters = {\n",
    "    \"$schema\": \"https://schema.management.azure.com/schemas/2019-04-01/deploymentParameters.json#\",\n",
    "    \"contentVersion\": \"1.0.0.0\",\n",
    "    \"parameters\": {\n",
    "        \"apimSku\": { \"value\": apim_sku },\n",
    "        \"openAIConfig\": { \"value\": openai_resources },\n",
    "        \"openAIDeploymentName\": { \"value\": openai_deployment_name },\n",
    "        \"openAIModelName\": { \"value\": openai_model_name },\n",
    "        \"openAIModelVersion\": { \"value\": openai_model_version },\n",
    "        \"openAIModelSKU\": { \"value\": openai_model_sku },\n",
    "        \"openAIModelCapacity\": { \"value\": openai_model_capacity },\n",
    "        \"openAIAPIVersion\": { \"value\": openai_api_version }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Write the parameters to the params.json file\n",
    "with open('params.json', 'w') as bicep_parameters_file:\n",
    "    bicep_parameters_file.write(json.dumps(bicep_parameters))\n",
    "\n",
    "# Run the deployment\n",
    "output = utils.run(f\"az deployment group create --name {deployment_name} --resource-group {resource_group_name} --template-file main.bicep --parameters params.json\",\n",
    "    f\"Deployment '{deployment_name}' succeeded\", f\"Deployment '{deployment_name}' failed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='3'></a>\n",
    "### 3Ô∏è‚É£ Get the deployment outputs\n",
    "\n",
    "Retrieve the required outputs from the Bicep deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain all of the outputs from the deployment\n",
    "output = utils.run(f\"az deployment group show --name {deployment_name} -g {resource_group_name}\", f\"Retrieved deployment: {deployment_name}\", f\"Failed to retrieve deployment: {deployment_name}\")\n",
    "\n",
    "if output.success and output.json_data:\n",
    "    app_insights_name = utils.get_deployment_output(output, 'applicationInsightsName', 'Application Insights Name')    \n",
    "    apim_resource_gateway_url = utils.get_deployment_output(output, 'apimResourceGatewayURL', 'APIM API Gateway URL')\n",
    "    project_connection_string = utils.get_deployment_output(output, 'projectConnectionString', 'AI Foundry Project Connection String', True)\n",
    "    bing_search_connection = utils.get_deployment_output(output, 'bingSearchConnectionName', 'Bing Search Connection')\n",
    "    weather_api_connection_id = utils.get_deployment_output(output, 'weatherAPIConnectionId', 'Weather API Connection Id')\n",
    "    place_order_api_connection_id = utils.get_deployment_output(output, 'placeOrderAPIConnectionId', 'Place Order API Connection Id')\n",
    "    product_catalog_api_connection_id = utils.get_deployment_output(output, 'productCatalogAPIConnectionId', 'Product Catalog API Connection Id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='4'></a>\n",
    "### 4Ô∏è‚É£ List the connections\n",
    "\n",
    "Retrieve the connections managed in AI Foundry available for the Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.projects import AIProjectClient\n",
    "from azure.ai.projects.models import ConnectionType\n",
    "from azure.identity import DefaultAzureCredential\n",
    "\n",
    "project_client = AIProjectClient.from_connection_string(credential=DefaultAzureCredential(),\n",
    "    conn_str=project_connection_string)\n",
    "with project_client:\n",
    "    connections = project_client.connections.list()\n",
    "    utils.print_ok(f\"Listing all connections (found {len(connections)}):\")\n",
    "    for connection in connections:\n",
    "        utils.print_info(f\"Name: {connection.name}, Type: {connection.connection_type}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='quickstart'></a>\n",
    "### üß™ Create and run a Math Tutor Agent with OpenAI Assistants API\n",
    "\n",
    "Check the official documentation for updates on this quickstart:\n",
    "https://learn.microsoft.com/en-us/azure/ai-services/agents/quickstart\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, logging\n",
    "from azure.ai.projects import AIProjectClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "prompt_content = \"I need to solve the equation `3x + 11 = 14`. Can you help me?\"\n",
    "\n",
    "with AIProjectClient.from_connection_string(credential=DefaultAzureCredential(),\n",
    "    conn_str=project_connection_string,\n",
    "    logging_enable = True) as project_client:\n",
    "    client: AzureOpenAI = project_client.inference.get_azure_openai_client(api_version = openai_api_version)\n",
    "    with client:\n",
    "        agent = client.beta.assistants.create(model=openai_deployment_name, name=\"math-tutor\", \n",
    "            instructions=\"'You are a personal math tutor. Answer questions briefly, in a sentence or less.\")\n",
    "        utils.print_ok(f\"Created agent, agent ID: {agent.id}\")\n",
    "\n",
    "        thread = client.beta.threads.create()\n",
    "        utils.print_ok(f\"Created thread, thread ID: {thread.id}\")\n",
    "\n",
    "        message = client.beta.threads.messages.create(thread_id=thread.id, role=\"user\", content=prompt_content)\n",
    "        utils.print_ok(f\"Created message, message ID: {message.id}\")\n",
    "\n",
    "        run = client.beta.threads.runs.create(thread_id=thread.id, assistant_id=agent.id)\n",
    "\n",
    "        # Poll the run while run status is queued or in progress\n",
    "        while run.status in [\"queued\", \"in_progress\", \"requires_action\"]:\n",
    "            time.sleep(1)  # Wait for a second\n",
    "            run = client.beta.threads.runs.retrieve(thread_id=thread.id, run_id=run.id)\n",
    "            utils.print_ok(f\"Run status: {run.status}\")\n",
    "\n",
    "        client.beta.assistants.delete(agent.id)\n",
    "\n",
    "        messages = client.beta.threads.messages.list(thread_id=thread.id)\n",
    "        print(f\"üó®Ô∏è {messages.data[0].content[0].text.value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='weatherapi'></a>\n",
    "### üß™ Run agent with Weather API from Azure API Management\n",
    "\n",
    "üëâ Check the [Azure AI Foundry Tracing](https://learn.microsoft.com/en-us/azure/ai-studio/concepts/trace) information to understand the execution process.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following code was adapted from this sample:\n",
    "# https://github.com/Azure/azure-sdk-for-python/blob/main/sdk/ai/azure-ai-projects/samples/agents/sample_agents_openapi.py\n",
    "\n",
    "import jsonref\n",
    "from azure.ai.projects import AIProjectClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.ai.projects.models import OpenApiTool, OpenApiConnectionAuthDetails, OpenApiConnectionSecurityScheme\n",
    "from azure.monitor.opentelemetry import configure_azure_monitor\n",
    "\n",
    "prompt_content = \"Return a summary of the temperature in Seattle and 3 other sister cities in Europe?\"\n",
    "\n",
    "project_client = AIProjectClient.from_connection_string(credential=DefaultAzureCredential(),\n",
    "    conn_str=project_connection_string)\n",
    "application_insights_connection_string = project_client.telemetry.get_connection_string()    \n",
    "configure_azure_monitor(connection_string=application_insights_connection_string)\n",
    "\n",
    "with open(\"./city-weather-openapi.json\", \"r\") as f:\n",
    "    openapi_weather = jsonref.loads(f.read().replace(\"https://replace-me.local/weatherservice\", f\"{apim_resource_gateway_url}/weatherservice\"))\n",
    "openapi_tool = OpenApiTool(name=\"get_weather\", spec=openapi_weather, description=\"Retrieve weather information for a location\", \n",
    "    auth=OpenApiConnectionAuthDetails(security_scheme=OpenApiConnectionSecurityScheme(connection_id=weather_api_connection_id)))\n",
    "\n",
    "# Create agent with OpenApi tool and process assistant run\n",
    "with project_client:\n",
    "    agent = project_client.agents.create_agent(model=openai_deployment_name,\n",
    "        name=\"my-assistant\",\n",
    "        instructions=\"You are a helpful assistant that provides wheather information. Always provide the temperature in Celsius.\",\n",
    "        tools=openapi_tool.definitions)\n",
    "    utils.print_ok(f\"Created agent, ID: {agent.id}\")\n",
    "\n",
    "    # Create thread for communication\n",
    "    thread = project_client.agents.create_thread()\n",
    "    utils.print_ok(f\"Created thread, ID: {thread.id}\")\n",
    "\n",
    "    # Create message to thread\n",
    "    message = project_client.agents.create_message(thread_id=thread.id,\n",
    "        role=\"user\",\n",
    "        content=prompt_content)\n",
    "    utils.print_ok(f\"Created message, ID: {message.id}\")\n",
    "\n",
    "    # Create and process agent run in thread with tools\n",
    "    run = project_client.agents.create_and_process_run(thread_id=thread.id, assistant_id=agent.id)\n",
    "    utils.print_ok(f\"Run finished with status: {run.status}\")\n",
    "\n",
    "    if run.status == \"failed\":\n",
    "        utils.print_error(f\"Run failed: {run.last_error}\")\n",
    "\n",
    "    # Print steps and function/tool details\n",
    "    run_steps = project_client.agents.list_run_steps(thread_id=thread.id, run_id=run.id)\n",
    "    for step in reversed(run_steps.data):\n",
    "        utils.print_ok(f\"Step {step['id']} status: {step['status']}\")\n",
    "        step_details = step.get(\"step_details\", {})\n",
    "        tool_calls = step_details.get(\"tool_calls\", [])\n",
    "        if tool_calls:\n",
    "            for call in tool_calls:\n",
    "                function_details = call.get(\"function\", {})\n",
    "                if function_details:\n",
    "                    utils.print_info(f\"Function details: {function_details}\")\n",
    "\n",
    "    project_client.agents.delete_agent(agent.id)\n",
    "\n",
    "    messages = project_client.agents.list_messages(thread_id=thread.id)\n",
    "    print(f\"üó®Ô∏è {messages.data[0].content[0].text.value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='bing'></a>\n",
    "### üß™ Grounding with Bing\n",
    "\n",
    "Check the official documentation for updates on this sample: https://learn.microsoft.com/en-us/azure/ai-services/agents/how-to/tools/bing-grounding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.projects import AIProjectClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.ai.projects.models import BingGroundingTool\n",
    "\n",
    "prompt_content = \"What are the top news today?\"\n",
    "\n",
    "project_client = AIProjectClient.from_connection_string(credential=DefaultAzureCredential(),\n",
    "    conn_str=project_connection_string)\n",
    "bing_connection = project_client.connections.get(connection_name=bing_search_connection)\n",
    "conn_id = bing_connection.id\n",
    "\n",
    "# Initialize agent bing tool and add the connection id\n",
    "bing = BingGroundingTool(connection_id=conn_id)\n",
    "\n",
    "# Create agent with the bing tool and process assistant run\n",
    "with project_client:\n",
    "    agent = project_client.agents.create_agent(model=openai_deployment_name,\n",
    "        name=\"my-assistant\",\n",
    "        instructions=\"You are a helpful assistant\",\n",
    "        tools=bing.definitions,\n",
    "        headers={\"x-ms-enable-preview\": \"true\"})   \n",
    "    utils.print_ok(f\"Created agent, ID: {agent.id}\")\n",
    "\n",
    "    thread = project_client.agents.create_thread()\n",
    "    utils.print_ok(f\"Created thread, ID: {thread.id}\")\n",
    "\n",
    "    # Create message to thread\n",
    "    message = project_client.agents.create_message(thread_id=thread.id,\n",
    "        role=\"user\",\n",
    "        content=prompt_content)\n",
    "    utils.print_ok(f\"Created message, ID: {message.id}\")\n",
    "\n",
    "    # Create and process agent run in thread with tools\n",
    "    run = project_client.agents.create_and_process_run(thread_id=thread.id, assistant_id=agent.id)\n",
    "    utils.print_ok(f\"Run finished with status: {run.status}\")\n",
    "\n",
    "    # Retrieve run step details to get Bing Search query link\n",
    "    # To render the webpage, we recommend you replace the endpoint of Bing search query URLs with `www.bing.com` and your Bing search query URL would look like \"https://www.bing.com/search?q={search query}\"\n",
    "    run_steps = project_client.agents.list_run_steps(run_id=run.id, thread_id=thread.id)\n",
    "    run_steps_data = run_steps['data']\n",
    "\n",
    "    if run.status == \"failed\":\n",
    "        utils.print_error(f\"Run failed: {run.last_error}\")\n",
    "\n",
    "    project_client.agents.delete_agent(agent.id)\n",
    "\n",
    "    # Fetch and log all messages\n",
    "    messages = project_client.agents.list_messages(thread_id=thread.id)\n",
    "    print(f\"üó®Ô∏è {messages.data[0].content[0].text.value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='logicapp'></a>\n",
    "### üß™ Run agent operations with OpenAPI Backend and Logic Apps workflow\n",
    "\n",
    "‚öôÔ∏è **Tools**:\n",
    "- Get Product Catalog - OpenAPI Backend mocked with an APIM policy.\n",
    "- Place Order - A Logic Apps workflow that processes orders with a maximum of five items.\n",
    "\n",
    "‚ú® **Expected Behavior**:\n",
    "- The agent receives a user request to order 11 smartphones.\n",
    "- The agent calls the product catalog API to retrieve the product SKU and available stock quantity.\n",
    "- If the order quantity exceeds available stock, the agent will respond that the order cannot be processed due to insufficient stock.\n",
    "- If stock is available, the agent will initiate the order workflow, which will fail because the quantity exceeds the maximum limit of five items.\n",
    "- As the agent was instructed to recover from errors, it will place multiple orders, each with a quantity below the maximum limit, ensuring the total equals the desired order quantity.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following code was adapted from this sample:\n",
    "# https://github.com/Azure/azure-sdk-for-python/blob/main/sdk/ai/azure-ai-projects/samples/agents/sample_agents_openapi.py\n",
    "\n",
    "import jsonref\n",
    "from azure.ai.projects import AIProjectClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.ai.projects.models import OpenApiTool, OpenApiConnectionAuthDetails, OpenApiConnectionSecurityScheme, ToolSet\n",
    "from azure.monitor.opentelemetry import configure_azure_monitor\n",
    "\n",
    "prompt_content = \"Please order one smartphone for me and one for each of my ten friends.\"\n",
    "\n",
    "project_client = AIProjectClient.from_connection_string(credential=DefaultAzureCredential(),\n",
    "    conn_str=project_connection_string)\n",
    "application_insights_connection_string = project_client.telemetry.get_connection_string()\n",
    "configure_azure_monitor(connection_string=application_insights_connection_string)\n",
    "\n",
    "with open(\"./product-catalog-openapi.json\", \"r\") as f:\n",
    "    openapi_product_catalog = jsonref.loads(f.read().replace(\"https://replace-me.local/catalogservice\", f\"{apim_resource_gateway_url}/catalogservice\"))\n",
    "openapi_tools = OpenApiTool(name=\"get_product_catalog\", spec=openapi_product_catalog, description=\"Retrieve the list of products available in the catalog\", \n",
    "    auth=OpenApiConnectionAuthDetails(security_scheme=OpenApiConnectionSecurityScheme(connection_id=product_catalog_api_connection_id)))\n",
    "\n",
    "with open(\"./place-order-openapi.json\", \"r\") as f:\n",
    "    openapi_place_order = jsonref.loads(f.read().replace(\"https://replace-me.local/orderservice\", f\"{apim_resource_gateway_url}/orderservice\"))\n",
    "openapi_tools.add_definition(name=\"place_order\", spec=openapi_place_order, description=\"Place a product order\", \n",
    "    auth=OpenApiConnectionAuthDetails(security_scheme=OpenApiConnectionSecurityScheme(connection_id=place_order_api_connection_id)))\n",
    "\n",
    "# Create agent with OpenApi tool and process assistant run\n",
    "with project_client:\n",
    "    agent = project_client.agents.create_agent(model=openai_deployment_name,\n",
    "        name=\"my-assistant\",\n",
    "        instructions=\"You are a helpful sales assistant that helps users order products. Recover from errors if any and place multiple orders if needed.\",\n",
    "        tools=openapi_tools.definitions)\n",
    "    utils.print_ok(f\"Created agent, ID: {agent.id}\")\n",
    "\n",
    "    # Create thread for communication\n",
    "    thread = project_client.agents.create_thread()\n",
    "    utils.print_ok(f\"Created thread, ID: {thread.id}\")\n",
    "\n",
    "    # Create message to thread\n",
    "    message = project_client.agents.create_message(thread_id=thread.id,\n",
    "        role=\"user\",\n",
    "        content=prompt_content)\n",
    "    utils.print_ok(f\"Created message, ID: {message.id}\")\n",
    "\n",
    "    # Create and process agent run in thread with tools\n",
    "    run = project_client.agents.create_and_process_run(thread_id=thread.id, assistant_id=agent.id)\n",
    "    utils.print_ok(f\"Run finished with status: {run.status}\")\n",
    "\n",
    "    if run.status == \"failed\":\n",
    "        utils.print_error(f\"Run failed: {run.last_error}\")\n",
    "\n",
    "    # Print steps and function/tool details\n",
    "    run_steps = project_client.agents.list_run_steps(thread_id=thread.id, run_id=run.id)\n",
    "    for step in reversed(run_steps.data):\n",
    "        utils.print_ok(f\"Step {step['id']} status: {step['status']}\")\n",
    "        step_details = step.get(\"step_details\", {})\n",
    "        tool_calls = step_details.get(\"tool_calls\", [])\n",
    "        if tool_calls:\n",
    "            for call in tool_calls:\n",
    "                function_details = call.get(\"function\", {})\n",
    "                if function_details:\n",
    "                    utils.print_info(f\"Function details: {function_details}\")\n",
    "\n",
    "    project_client.agents.delete_agent(agent.id)\n",
    "\n",
    "    messages = project_client.agents.list_messages(thread_id=thread.id)\n",
    "    print(f\"üó®Ô∏è {messages.data[0].content[0].text.value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='kql'></a>\n",
    "### üîç Analyze Application Insights custom metrics with a KQL query\n",
    "\n",
    "With this query you can get the custom metrics that were emitted by Azure APIM. Note that it may take a few minutes for data to become available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "query = \"\\\"\" + \"customMetrics \\\n",
    "| where name == 'Total Tokens' \\\n",
    "| where timestamp >= ago(1h) \\\n",
    "| extend parsedCustomDimensions = parse_json(customDimensions) \\\n",
    "| extend apimSubscription = tostring(parsedCustomDimensions.['Subscription ID']) \\\n",
    "| extend agentID = tostring(parsedCustomDimensions.['Agent ID']) \\\n",
    "| summarize TotalValue = sum(value) by apimSubscription, bin(timestamp, 1m), agentID \\\n",
    "| order by timestamp asc\" + \"\\\"\"\n",
    "\n",
    "output = utils.run(f\"az monitor app-insights query --app {app_insights_name} -g {resource_group_name} --analytics-query {query}\",\n",
    "    f\"App Insights query succeeded\", f\"App Insights query  failed\")\n",
    "\n",
    "table = output.json_data['tables'][0]\n",
    "df = pd.DataFrame(table.get(\"rows\"), columns = [col.get(\"name\") for col in table.get('columns')])\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp']).dt.strftime('%H:%M')\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='plot'></a>\n",
    "### üîç Plot the custom metrics results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.figsize'] = [15, 7]\n",
    "if df.empty:\n",
    "    print(\"No data to plot\")\n",
    "else:\n",
    "    df_pivot = df.pivot(index='timestamp', columns='apimSubscription', values='TotalValue')\n",
    "    ax = df_pivot.plot(kind='bar', stacked=True)\n",
    "    plt.title('Total token usage over time by APIM Subscription')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Tokens')\n",
    "    plt.legend(title='APIM Subscription')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='clean'></a>\n",
    "### üóëÔ∏è Clean up resources\n",
    "\n",
    "When you're finished with the lab, you should remove all your deployed resources from Azure to avoid extra charges and keep your Azure subscription uncluttered.\n",
    "Use the [clean-up-resources notebook](clean-up-resources.ipynb) for that."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
