{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# APIM ‚ù§Ô∏è OpenAI\n",
    "\n",
    "## SLM self hosting lab\n",
    "![flow](../../images/slm-self-hosting.gif)\n",
    "\n",
    "Playground to try the self-hosted [phy-3 Small Language Model (SLM)](https://azure.microsoft.com/blog/introducing-phi-3-redefining-whats-possible-with-slms/) trough the [APIM self-hosted gateway](https://learn.microsoft.com/azure/api-management/self-hosted-gateway-overview) with OpenAI API compatibility.\n",
    "\n",
    "The Phi-3-Mini-4K-Instruct is a 3.8B parameters, lightweight, state-of-the-art open model trained with the Phi-3 datasets that includes both synthetic data and the filtered publicly available websites data with a focus on high-quality and reasoning dense properties. The model belongs to the Phi-3 family with the Mini version in two variants 4K and 128K which is the context length (in tokens) that it can support.\n",
    "\n",
    "The model has underwent a post-training process that incorporates both supervised fine-tuning and direct preference optimization for the instruction following and safety measures. When assessed against benchmarks testing common sense, language understanding, math, code, long context and logical reasoning, Phi-3 Mini-4K-Instruct showcased a robust and state-of-the-art performance among models with less than 13 billion parameters.\n",
    "\n",
    "The APIM self-hosted gateway is a containerized version of the default managed gateway. It's useful for scenarios such as placing gateways in the same environments where you host your APIs. Like in this experiment where we self-host the phi-3 API. This enable use cases where the SLM is running on-premises \n",
    "\n",
    "### Prerequisites\n",
    "\n",
    "- [Python 3.12 or later version](https://www.python.org/) installed\n",
    "- [VS Code](https://code.visualstudio.com/) installed with the [Jupyter notebook extension](https://marketplace.visualstudio.com/items?itemName=ms-toolsai.jupyter) enabled\n",
    "- [Python environment](https://code.visualstudio.com/docs/python/environments#_creating-environments) with the [requirements.txt](../../requirements.txt) or run `pip install -r requirements.txt` in your terminal\n",
    "- [An Azure Subscription](https://azure.microsoft.com/free/) with [Contributor](https://learn.microsoft.com/en-us/azure/role-based-access-control/built-in-roles/privileged#contributor) + [RBAC Administrator](https://learn.microsoft.com/en-us/azure/role-based-access-control/built-in-roles/privileged#role-based-access-control-administrator) or [Owner](https://learn.microsoft.com/en-us/azure/role-based-access-control/built-in-roles/privileged#owner) roles\n",
    "- [Azure CLI](https://learn.microsoft.com/cli/azure/install-azure-cli) installed and [Signed into your Azure subscription](https://learn.microsoft.com/cli/azure/authenticate-azure-cli-interactively)\n",
    "- [Docker Desktop](https://www.docker.com/products/docker-desktop/)\n",
    "\n",
    "‚ñ∂Ô∏è Click `Run All` to execute all steps sequentially, or execute them `Step by Step`..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='0'></a>\n",
    "### 0Ô∏è‚É£ Initialize notebook variables\n",
    "\n",
    "- Resources will be suffixed by a unique string based on your subscription id.\n",
    "- Adjust the location parameters according your preferences and on the [product availability by Azure region.](https://azure.microsoft.com/explore/global-infrastructure/products-by-region/?cdn=disable&products=cognitive-services,api-management) \n",
    "- Adjust the OpenAI model and version according the [availability by region.](https://learn.microsoft.com/azure/ai-services/openai/concepts/models) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, json\n",
    "sys.path.insert(1, '../../shared')  # add the shared directory to the Python path\n",
    "import utils\n",
    "\n",
    "deployment_name = os.path.basename(os.path.dirname(globals()['__vsc_ipynb_file__']))\n",
    "resource_group_name = f\"lab-{deployment_name}\" # change the name to match your naming style\n",
    "resource_group_location = \"westeurope\" \n",
    "\n",
    "apim_sku = 'Developer'\n",
    "self_hosted_gateway_name = \"self-hosted-gateway\"\n",
    "model = \"phi-3.5-mini\"\n",
    "openai_api_version = \"2024-10-21\"\n",
    "\n",
    "utils.print_ok('Notebook initialized')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='1'></a>\n",
    "### 1Ô∏è‚É£ Verify the Azure CLI and the connected Azure subscription\n",
    "\n",
    "The following commands ensure that you have the latest version of the Azure CLI and that the Azure CLI is connected to your Azure subscription."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = utils.run(\"az account show\", \"Retrieved az account\", \"Failed to get the current az account\")\n",
    "\n",
    "if output.success and output.json_data:\n",
    "    current_user = output.json_data['user']['name']\n",
    "    tenant_id = output.json_data['tenantId']\n",
    "    subscription_id = output.json_data['id']\n",
    "\n",
    "    utils.print_info(f\"Current user: {current_user}\")\n",
    "    utils.print_info(f\"Tenant ID: {tenant_id}\")\n",
    "    utils.print_info(f\"Subscription ID: {subscription_id}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='2'></a>\n",
    "### 2Ô∏è‚É£ Create deployment using ü¶æ Bicep\n",
    "\n",
    "This lab uses [Bicep](https://learn.microsoft.com/azure/azure-resource-manager/bicep/overview?tabs=bicep) to declarative define all the resources that will be deployed in the specified resource group. Change the parameters or the [main.bicep](main.bicep) directly to try different configurations. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the resource group if doesn't exist\n",
    "utils.create_resource_group(resource_group_name, resource_group_location)\n",
    "\n",
    "# Define the Bicep parameters\n",
    "bicep_parameters = {\n",
    "    \"$schema\": \"https://schema.management.azure.com/schemas/2019-04-01/deploymentParameters.json#\",\n",
    "    \"contentVersion\": \"1.0.0.0\",\n",
    "    \"parameters\": {\n",
    "        \"apimSku\": { \"value\": apim_sku },\n",
    "        \"selfHostedGatewayName\": { \"value\": self_hosted_gateway_name },\n",
    "        \"openAIAPIVersion\": { \"value\": openai_api_version }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Write the parameters to the params.json file\n",
    "with open('params.json', 'w') as bicep_parameters_file:\n",
    "    bicep_parameters_file.write(json.dumps(bicep_parameters))\n",
    "\n",
    "# Run the deployment\n",
    "output = utils.run(f\"az deployment group create --name {deployment_name} --resource-group {resource_group_name} --template-file main.bicep --parameters params.json\",\n",
    "    f\"Deployment '{deployment_name}' succeeded\", f\"Deployment '{deployment_name}' failed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='3'></a>\n",
    "### 3Ô∏è‚É£ Get the deployment outputs\n",
    "\n",
    "Retrieve the required outputs from the Bicep deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "# Obtain all of the outputs from the deployment\n",
    "output = utils.run(f\"az deployment group show --name {deployment_name} -g {resource_group_name}\", f\"Retrieved deployment: {deployment_name}\", f\"Failed to retrieve deployment: {deployment_name}\")\n",
    "\n",
    "if output.success and output.json_data:\n",
    "    apim_resource_name = utils.get_deployment_output(output, 'apimResourceName', 'APIM Resource Name')\n",
    "    apim_resource_id = utils.get_deployment_output(output, 'apimResourceId', 'APIM Resource Id')\n",
    "    apim_subscription_key = utils.get_deployment_output(output, 'apimSubscriptionKey', 'APIM Subscription Key (masked)', True)\n",
    "    apim_config_endpoint = f\"{apim_resource_name}.configuration.azure-api.net\"\n",
    "    apim_resource_gateway_url = \"http://localhost\"\n",
    "\n",
    "    print(\"üëâüèª API Gateway URL: \", apim_resource_gateway_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='41'></a>\n",
    "### 4Ô∏è‚É£ Option 1: Run phy-3.5-mini with [AI Foundry Local](https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/get-started)\n",
    "\n",
    "1. [Install Foundry Local](https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/get-started#quickstart) in your local environment\n",
    "2. Install the Foundry Local SDK: `pip install foundry-local-sdk`\n",
    "\n",
    "The following code is based on the [official docs](https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/how-to/how-to-integrate-with-inference-sdks?pivots=programming-language-python#use-openai-sdk-with-foundry-local)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from foundry_local import FoundryLocalManager\n",
    "\n",
    "# By using an alias, the most suitable model will be downloaded \n",
    "# to your end-user's device. \n",
    "alias = model\n",
    "# Create a FoundryLocalManager instance. This will start the Foundry\n",
    "# Local service if it is not already running and load the specified model.\n",
    "manager = FoundryLocalManager(alias)\n",
    "print(manager.endpoint)\n",
    "\n",
    "# The remaining code uses the OpenAI Python SDK to interact with the local model.\n",
    "# Configure the client to use the local Foundry service\n",
    "client = openai.OpenAI(\n",
    "    base_url=manager.endpoint,\n",
    "    api_key=manager.api_key  # API key is not required for local usage\n",
    ")\n",
    "# Set the model to use and generate a response\n",
    "response = client.chat.completions.create(\n",
    "    model=manager.get_model_info(alias).id,\n",
    "    messages=[{\"role\": \"user\", \"content\": \"What is the golden ratio?\"}]\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='41'></a>\n",
    "### 4Ô∏è‚É£ Option 2: Run phy-3 API locally with docker\n",
    "\n",
    "The following commands will build the container image and then create a container instance to run it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! docker build -t phi-3 phy-3/.\n",
    "# ! docker run -d -p 5000:5000 -v phi2-models:/model_cache phi-3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='42'></a>\n",
    "### 4Ô∏è‚É£ Option 3: Run phy-3 API locally without a container\n",
    "\n",
    "We recommend running the following commands in a separate terminal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! cd phy-3\n",
    "# ! pip install --no-cache-dir -r requirements.txt\n",
    "# ! flask --app app.py --debug run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='5'></a>\n",
    "### 5Ô∏è‚É£ Run the APIM self-hosted gateway with docker\n",
    "\n",
    "In a production environment we recommend using Kubernetes. Follow this [guide](https://learn.microsoft.com/azure/api-management/how-to-self-hosted-gateway-on-kubernetes-in-production) to run the APIM self-hosted gateway in production. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a token for the self-hosted gateway\n",
    "request = {\n",
    "    \"properties\": {    \n",
    "        \"keyType\": \"primary\",\n",
    "        \"expiry\": (datetime.datetime.now() + datetime.timedelta(days=29)).isoformat()\n",
    "    }\n",
    "}\n",
    "output = utils.run(f\"az rest --method post --uri {apim_resource_id}/gateways/{self_hosted_gateway_name}/generateToken?api-version=2023-05-01-preview --body \\\"{str(request)}\\\"\",\n",
    "        \"Generated gateway token \", \"Failed to generate gateway token\")            \n",
    "self_hosted_gateway_auth = output.json_data.get('value') if output.success and output.json_data else None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! docker run -d -p 80:8080 -p 443:8081 -e config.service.endpoint=\"{apim_config_endpoint}\" -e config.service.auth=\"GatewayKey {self_hosted_gateway_auth}\" -e runtime.deployment.artifact.source=\"Azure Portal\" -e runtime.deployment.mechanism=Docker --name {self_hosted_gateway_name} mcr.microsoft.com/azure-api-management/gateway:v2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='requests'></a>\n",
    "### üß™ Test the API using a direct HTTP call\n",
    "\n",
    "Requests is an elegant and simple HTTP library for Python that will be used here to make raw API requests and inspect the responses.\n",
    "\n",
    "‚ö†Ô∏è The requests might take some minutes depending on your running environment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "url = apim_resource_gateway_url + \"/inference/chat/completions?api-version=\" + openai_api_version\n",
    "\n",
    "manager = FoundryLocalManager(model)\n",
    "\n",
    "payload = {\n",
    "    \"model\": manager.get_model_info(model).id,\n",
    "    \"messages\": [\n",
    "        {\"role\": \"user\", \"content\": \"What's the capital of Portugal?\"}\n",
    "    ]\n",
    "}\n",
    "\n",
    "headers = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"api-key\": apim_subscription_key\n",
    "}\n",
    "\n",
    "response = requests.post(url, headers=headers, data=json.dumps(payload))\n",
    "print(response.json()[\"choices\"][0][\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='sdk'></a>\n",
    "### üß™ Test the API using the [Azure AI Inference library](https://learn.microsoft.com/en-us/python/api/overview/azure/ai-inference-readme?view=azure-python-preview)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.inference import ChatCompletionsClient\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.ai.inference.models import SystemMessage, UserMessage\n",
    "from foundry_local import FoundryLocalManager\n",
    "\n",
    "manager = FoundryLocalManager(model)\n",
    "\n",
    "client = ChatCompletionsClient(\n",
    "    endpoint=f\"{apim_resource_gateway_url}/inference\",\n",
    "    credential=AzureKeyCredential(apim_subscription_key),\n",
    "    api_version=openai_api_version\n",
    ")\n",
    "\n",
    "response = client.complete(\n",
    "    messages=[\n",
    "        UserMessage(\"What's the capital of Portugal?\"),\n",
    "    ],\n",
    "    model=manager.get_model_info(model).id\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='clean'></a>\n",
    "### üóëÔ∏è Clean up resources\n",
    "\n",
    "When you're finished with the lab, you should remove all your deployed resources from Azure to avoid extra charges and keep your Azure subscription uncluttered.\n",
    "Use the [clean-up-resources notebook](clean-up-resources.ipynb) for that."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
