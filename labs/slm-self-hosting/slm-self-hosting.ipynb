{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# APIM ‚ù§Ô∏è OpenAI\n",
    "\n",
    "## SLM self hosting lab\n",
    "![flow](../../images/slm-self-hosting.gif)\n",
    "\n",
    "Playground to try the self-hosted [phy-3 Small Language Model (SLM)](https://azure.microsoft.com/en-us/blog/introducing-phi-3-redefining-whats-possible-with-slms/) trough the [APIM self-hosted gateway](https://learn.microsoft.com/en-us/azure/api-management/self-hosted-gateway-overview) with OpenAI API compatibility.\n",
    "\n",
    "The Phi-3-Mini-4K-Instruct is a 3.8B parameters, lightweight, state-of-the-art open model trained with the Phi-3 datasets that includes both synthetic data and the filtered publicly available websites data with a focus on high-quality and reasoning dense properties. The model belongs to the Phi-3 family with the Mini version in two variants 4K and 128K which is the context length (in tokens) that it can support.\n",
    "\n",
    "The model has underwent a post-training process that incorporates both supervised fine-tuning and direct preference optimization for the instruction following and safety measures. When assessed against benchmarks testing common sense, language understanding, math, code, long context and logical reasoning, Phi-3 Mini-4K-Instruct showcased a robust and state-of-the-art performance among models with less than 13 billion parameters.\n",
    "\n",
    "The APIM self-hosted gateway is a containerized version of the default managed gateway. It's useful for scenarios such as placing gateways in the same environments where you host your APIs. Like in this experiment where we self-host the phi-3 API. This enable use cases where the SLM is running on-premises \n",
    "\n",
    "### TOC\n",
    "- [0Ô∏è‚É£ Initialize notebook variables](#0)\n",
    "- [1Ô∏è‚É£ Create the Azure Resource Group](#1)\n",
    "- [2Ô∏è‚É£ Create deployment using ü¶æ Bicep](#2)\n",
    "- [3Ô∏è‚É£ Get the deployment outputs](#3)\n",
    "- [4Ô∏è‚É£ Option 1: Run phy-3 API locally with docker](#3)\n",
    "- [4Ô∏è‚É£ Option 2: Run phy-3 API locally without a container](#3)\n",
    "- [5Ô∏è‚É£ Run the APIM self-hosted gateway with docker](#3)\n",
    "- [üß™ Test the API using a direct HTTP call](#requests)\n",
    "- [üß™ Test the API using the Azure OpenAI Python SDK](#sdk)\n",
    "- [üóëÔ∏è Clean up resources](#clean)\n",
    "\n",
    "### Prerequisites\n",
    "- [Python 3.8 or later version](https://www.python.org/) installed\n",
    "- [VS Code](https://code.visualstudio.com/) installed with the [Jupyter notebook extension](https://marketplace.visualstudio.com/items?itemName=ms-toolsai.jupyter) enabled\n",
    "- [Azure CLI](https://learn.microsoft.com/en-us/cli/azure/install-azure-cli) installed\n",
    "- [An Azure Subscription](https://azure.microsoft.com/en-us/free/) with Contributor permissions\n",
    "- [Access granted to Azure OpenAI](https://aka.ms/oai/access) or just enable the mock service\n",
    "- [Sign in to Azure with Azure CLI](https://learn.microsoft.com/en-us/cli/azure/authenticate-azure-cli-interactively)\n",
    "- [Docker Desktop](https://www.docker.com/products/docker-desktop/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='0'></a>\n",
    "### 0Ô∏è‚É£ Initialize notebook variables\n",
    "\n",
    "- Resources will be suffixed by a unique string based on your subscription id\n",
    "- Adjust the location parameters according your preferences and on the [product availability by Azure region.](https://azure.microsoft.com/en-us/explore/global-infrastructure/products-by-region/?cdn=disable&products=cognitive-services,api-management) \n",
    "- Adjust the OpenAI model and version according the [availability by region.](https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import datetime\n",
    "import requests\n",
    "\n",
    "deployment_name = os.path.basename(os.path.dirname(globals()['__vsc_ipynb_file__']))\n",
    "resource_group_name = f\"lab-{deployment_name}\" # change the name to match your naming style\n",
    "resource_group_location = \"westeurope\"\n",
    "apim_resource_name = \"apim\"\n",
    "apim_resource_location = \"westeurope\"\n",
    "apim_resource_sku = \"Developer\"\n",
    "openai_resources = [  ] # list of OpenAI resources to deploy. Clear this list to use only the mock resources\n",
    "openai_resources_sku = \"S0\"\n",
    "openai_model_name = \"gpt-35-turbo\"\n",
    "openai_model_version = \"0613\"\n",
    "openai_deployment_name = \"gpt-35-turbo\"\n",
    "openai_api_version = \"2024-02-01\"\n",
    "openai_specification_url='https://raw.githubusercontent.com/Azure/azure-rest-api-specs/main/specification/cognitiveservices/data-plane/AzureOpenAI/inference/stable/' + openai_api_version + '/inference.json'\n",
    "openai_backend_pool = \"openai-backend-pool\"\n",
    "mock_backend_pool = \"mock-backend-pool\"\n",
    "mock_webapps = [ {\"name\": \"phi-3\", \"endpoint\": \"http://host.docker.internal:5000\"} ] # this is the endpoint of the phy-3 API running locally\n",
    "\n",
    "self_hosted_gateway_name = \"self-hosted-gateway\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='1'></a>\n",
    "### 1Ô∏è‚É£ Create the Azure Resource Group\n",
    "All resources deployed in this lab will be created in the specified resource group. Skip this step if you want to use an existing resource group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resource_group_stdout = ! az group create --name {resource_group_name} --location {resource_group_location}\n",
    "if resource_group_stdout.n.startswith(\"ERROR\"):\n",
    "    print(resource_group_stdout)\n",
    "else:\n",
    "    print(\"‚úÖ Azure Resource Group \", resource_group_name, \" created ‚åö \", datetime.datetime.now().time())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='2'></a>\n",
    "### 2Ô∏è‚É£ Create deployment using ü¶æ Bicep\n",
    "\n",
    "This lab uses [Bicep](https://learn.microsoft.com/en-us/azure/azure-resource-manager/bicep/overview?tabs=bicep) to declarative define all the resources that will be deployed. Change the parameters or the [main.bicep](main.bicep) directly to try different configurations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(openai_resources) > 0:\n",
    "    backend_id = openai_backend_pool if len(openai_resources) > 1 else openai_resources[0].get(\"name\")\n",
    "elif len(mock_webapps) > 0:\n",
    "    backend_id = mock_backend_pool if len(mock_webapps) > 1 else mock_webapps[0].get(\"name\")\n",
    "\n",
    "with open(\"policy.xml\", 'r') as policy_xml_file:\n",
    "    policy_template_xml = policy_xml_file.read()\n",
    "    policy_xml = policy_template_xml.replace(\"{backend-id}\", backend_id)\n",
    "    policy_xml_file.close()\n",
    "open(\"policy.xml\", 'w').write(policy_xml)\n",
    "\n",
    "bicep_parameters = {\n",
    "  \"$schema\": \"https://schema.management.azure.com/schemas/2019-04-01/deploymentParameters.json#\",\n",
    "  \"contentVersion\": \"1.0.0.0\",\n",
    "  \"parameters\": {\n",
    "    \"mockWebApps\": { \"value\": mock_webapps },\n",
    "    \"mockBackendPoolName\": { \"value\": mock_backend_pool },\n",
    "    \"openAIBackendPoolName\": { \"value\": openai_backend_pool },\n",
    "    \"openAIConfig\": { \"value\": openai_resources },\n",
    "    \"openAIDeploymentName\": { \"value\": openai_deployment_name },\n",
    "    \"openAISku\": { \"value\": openai_resources_sku },\n",
    "    \"openAIModelName\": { \"value\": openai_model_name },\n",
    "    \"openAIModelVersion\": { \"value\": openai_model_version },\n",
    "    \"openAIAPISpecURL\": { \"value\": openai_specification_url },\n",
    "    \"apimResourceName\": { \"value\": apim_resource_name},\n",
    "    \"apimResourceLocation\": { \"value\": apim_resource_location},\n",
    "    \"apimSku\": { \"value\": apim_resource_sku},\n",
    "    \"selfHostedGatewayName\": { \"value\": self_hosted_gateway_name}\n",
    "  }\n",
    "}\n",
    "with open('params.json', 'w') as bicep_parameters_file:\n",
    "    bicep_parameters_file.write(json.dumps(bicep_parameters))\n",
    "\n",
    "! az deployment group create --name {deployment_name} --resource-group {resource_group_name} --template-file \"main.bicep\" --parameters \"params.json\"\n",
    "\n",
    "open(\"policy.xml\", 'w').write(policy_template_xml)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='3'></a>\n",
    "### 3Ô∏è‚É£ Get the deployment outputs\n",
    "\n",
    "We are now at the stage where we only need to retrieve the gateway URL and the subscription before we are ready for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deployment_stdout = ! az deployment group show --name {deployment_name} -g {resource_group_name} --query properties.outputs.apimResourceName.value -o tsv\n",
    "apim_config_endpoint = f\"{deployment_stdout.n}.configuration.azure-api.net\"\n",
    "deployment_stdout = ! az deployment group show --name {deployment_name} -g {resource_group_name} --query properties.outputs.apimResourceId.value -o tsv\n",
    "apim_resource_id = deployment_stdout.n\n",
    "uri = f\"{apim_resource_id}/gateways/{self_hosted_gateway_name}/generateToken?api-version=2023-05-01-preview\"\n",
    "body = {\n",
    "  \"properties\": {    \n",
    "    \"keyType\": \"primary\",\n",
    "    \"expiry\": (datetime.datetime.now() + datetime.timedelta(days=29)).isoformat()\n",
    "  }\n",
    "}\n",
    "body_text = \"\\\"\" + json.dumps(body).replace(\"\\\"\",\"\\\\\\\"\") + \"\\\"\"\n",
    "cli_stdout = ! az rest --method POST --uri {uri} --body {body_text} -o tsv\n",
    "self_hosted_gateway_auth = f\"GatewayKey {cli_stdout.n}\"\n",
    "deployment_stdout = ! az deployment group show --name {deployment_name} -g {resource_group_name} --query properties.outputs.apimSubscriptionKey.value -o tsv\n",
    "apim_subscription_key = deployment_stdout.n\n",
    "apim_resource_gateway_url = \"http://localhost\"\n",
    "print(\"üëâüèª API Gateway URL: \", apim_resource_gateway_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='41'></a>\n",
    "### 4Ô∏è‚É£ Option 1: Run phy-3 API locally with docker\n",
    "\n",
    "The following commands will build the container image and then create a container instance to run it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! docker build -t phi-3 phy-3/.\n",
    "! docker run -d -p 5000:5000 -v phi2-models:/model_cache phi-3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='42'></a>\n",
    "### 4Ô∏è‚É£ Option 2: Run phy-3 API locally without a container\n",
    "\n",
    "We recommend running the following commands in a separate terminal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! cd phy-3\n",
    "! pip install --no-cache-dir -r requirements.txt\n",
    "! flask --app app.py --debug run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='5'></a>\n",
    "### 5Ô∏è‚É£ Run the APIM self-hosted gateway with docker\n",
    "\n",
    "In a production environment we recommend using Kubernetes. Follow this [guide](https://learn.microsoft.com/en-us/azure/api-management/how-to-self-hosted-gateway-on-kubernetes-in-production) to run the APIM self-hosted gateway in production. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! docker run -d -p 80:8080 -p 443:8081 -e config.service.endpoint=\"{apim_config_endpoint}\" -e config.service.auth=\"{self_hosted_gateway_auth}\" -e runtime.deployment.artifact.source=\"Azure Portal\" -e runtime.deployment.mechanism=Docker --name {self_hosted_gateway_name} mcr.microsoft.com/azure-api-management/gateway:v2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='requests'></a>\n",
    "### üß™ Test the API using a direct HTTP call\n",
    "\n",
    "Requests is an elegant and simple HTTP library for Python that will be used here to make raw API requests and inspect the responses.\n",
    "\n",
    "‚ö†Ô∏è The requests might take some minutes depending on your running environment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = apim_resource_gateway_url + \"/openai/deployments/\" + openai_deployment_name + \"/chat/completions?api-version=\" + openai_api_version\n",
    "messages={\"messages\":[\n",
    "    {\"role\": \"user\", \"content\": \"write me a poem about the moon\"}\n",
    "]}\n",
    "response = requests.post(url, headers = {'api-key':apim_subscription_key}, json = messages)\n",
    "print(\"status code: \", response.status_code)\n",
    "print(\"headers \", response.headers)\n",
    "print(\"x-ms-region: \", response.headers.get(\"x-ms-region\")) # this header is useful to determine the region of the backend that served the request\n",
    "if (response.status_code == 200):\n",
    "    data = json.loads(response.text)\n",
    "    print(\"response: \", data.get(\"choices\")[0].get(\"message\").get(\"content\"))\n",
    "else:\n",
    "    print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='sdk'></a>\n",
    "### üß™ Test the API using the Azure OpenAI Python SDK\n",
    "OpenAPI provides a widely used [Python library](https://github.com/openai/openai-python). The library includes type definitions for all request params and response fields. The goal of this test is to assert that APIM can seamlessly proxy requests to OpenAI without disrupting its functionality.\n",
    "- Note: run ```pip install openai``` in a terminal before executing this step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import AzureOpenAI\n",
    "messages=[\n",
    "    {\"role\": \"user\", \"content\": \"write me a poem about the sea\"}\n",
    "]\n",
    "client = AzureOpenAI(\n",
    "    azure_endpoint=apim_resource_gateway_url,\n",
    "    api_key=apim_subscription_key,\n",
    "    api_version=openai_api_version\n",
    ")\n",
    "response = client.chat.completions.create(model=openai_model_name, messages=messages)\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='clean'></a>\n",
    "### üóëÔ∏è Clean up resources\n",
    "\n",
    "When you're finished with the lab, you should remove all your deployed resources from Azure to avoid extra charges and keep your Azure subscription uncluttered.\n",
    "Use the [clean-up-resources notebook](clean-up-resources.ipynb) for that."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
