{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7d95d3a",
   "metadata": {},
   "source": [
    "# APIM ‚ù§Ô∏è all the Models\n",
    "\n",
    "## Google Gemini API lab\n",
    "![flow](../../images/google-gemini-api.gif)\n",
    "\n",
    "Playground to try the [Google Gemini models](https://learn.microsoft.com/en-us/azure/api-management/openai-compatible-google-gemini-api) with the AI Gateway using the OpenAI-compatible endpoint.\n",
    "\n",
    "This lab demonstrates how to import an OpenAI-compatible Google Gemini API into Azure API Management, enabling you to:\n",
    "- Use the familiar OpenAI SDK and API format with Gemini models\n",
    "- Apply Azure API Management policies for rate limiting, caching, and security\n",
    "- Monitor token consumption and usage through Azure Monitor\n",
    "\n",
    "### Prerequisites\n",
    "\n",
    "- [Python 3.12 or later version](https://www.python.org/) installed\n",
    "- [VS Code](https://code.visualstudio.com/) installed with the [Jupyter notebook extension](https://marketplace.visualstudio.com/items?itemName=ms-toolsai.jupyter) enabled\n",
    "- [Python environment](https://code.visualstudio.com/docs/python/environments#_creating-environments) with the [requirements.txt](../../requirements.txt) or run `pip install -r requirements.txt` in your terminal\n",
    "- [An Azure Subscription](https://azure.microsoft.com/free/) with [Contributor](https://learn.microsoft.com/en-us/azure/role-based-access-control/built-in-roles/privileged#contributor) + [RBAC Administrator](https://learn.microsoft.com/en-us/azure/role-based-access-control/built-in-roles/privileged#role-based-access-control-administrator) or [Owner](https://learn.microsoft.com/en-us/azure/role-based-access-control/built-in-roles/privileged#owner) roles\n",
    "- [Azure CLI](https://learn.microsoft.com/cli/azure/install-azure-cli) installed and [Signed into your Azure subscription](https://learn.microsoft.com/cli/azure/authenticate-azure-cli-interactively)\n",
    "- [Google AI Studio API Key](https://aistudio.google.com/apikey) - Create a Gemini API key\n",
    "\n",
    "‚ñ∂Ô∏è Click `Run All` to execute all steps sequentially, or execute them `Step by Step`..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc8ad16e",
   "metadata": {},
   "source": [
    "<a id='0'></a>\n",
    "### 0Ô∏è‚É£ Initialize notebook variables\n",
    "\n",
    "- Resources will be suffixed by a unique string based on your subscription id.\n",
    "- Adjust the location parameters according your preferences and on the [product availability by Azure region.](https://azure.microsoft.com/explore/global-infrastructure/products-by-region/?cdn=disable&products=cognitive-services,api-management) \n",
    "- Obtain a [Gemini API Key](https://aistudio.google.com/apikey) to be able to use Gemini models\n",
    "\n",
    "**IMPORTANT:** Please DO NOT check in the Notebook with your API Key still in the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c38053",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, json\n",
    "sys.path.insert(1, '../../shared')  # add the shared directory to the Python path\n",
    "import utils\n",
    "\n",
    "deployment_name = os.path.basename(os.path.dirname(globals()['__vsc_ipynb_file__']))\n",
    "resource_group_name = f\"lab-{deployment_name}\" # change the name to match your naming style\n",
    "resource_group_location = \"eastus2\"\n",
    "\n",
    "# üîë Add your Gemini API key here (get one from https://aistudio.google.com/apikey)\n",
    "gemini_api_key = \"xxxxxxxxx\"  # Replace with your Gemini API key\n",
    "\n",
    "# Gemini model configuration\n",
    "gemini_model = \"gemini-3-flash-preview\"  # Available models: gemini-2.0-flash, gemini-1.5-pro, gemini-1.5-flash, etc.\n",
    "gemini_api_path = \"gemini/openai\"  # API path in APIM\n",
    "\n",
    "# APIM configuration\n",
    "apim_sku = \"Basicv2\"  # Change to your desired APIM SKU\n",
    "apim_subscriptions_config = [\n",
    "    {\"name\": \"subscription1\", \"displayName\": \"Subscription 1\"}, \n",
    "    {\"name\": \"subscription2\", \"displayName\": \"Subscription 2\"}\n",
    "]\n",
    "\n",
    "utils.print_ok('Notebook initialized')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e747c853",
   "metadata": {},
   "source": [
    "<a id='1'></a>\n",
    "### 1Ô∏è‚É£ Verify the Azure CLI and the connected Azure subscription\n",
    "\n",
    "The following commands ensure that you have the latest version of the Azure CLI and that the Azure CLI is connected to your Azure subscription."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d53a9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = utils.run(\"az account show\", \"Retrieved az account\", \"Failed to get the current az account\")\n",
    "\n",
    "if output.success and output.json_data:\n",
    "    current_user = output.json_data['user']['name']\n",
    "    tenant_id = output.json_data['tenantId']\n",
    "    subscription_id = output.json_data['id']\n",
    "\n",
    "    utils.print_info(f\"Current user: {current_user}\")\n",
    "    utils.print_info(f\"Tenant ID: {tenant_id}\")\n",
    "    utils.print_info(f\"Subscription ID: {subscription_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b30302c",
   "metadata": {},
   "source": [
    "<a id='2'></a>\n",
    "### 2Ô∏è‚É£ Create deployment using ü¶æ Bicep\n",
    "\n",
    "This lab uses [Bicep](https://learn.microsoft.com/azure/azure-resource-manager/bicep/overview?tabs=bicep) to declaratively define all the resources that will be deployed in the specified resource group. Change the parameters or the [main.bicep](main.bicep) directly to try different configurations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09111bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the resource group if doesn't exist\n",
    "utils.create_resource_group(resource_group_name, resource_group_location)\n",
    "\n",
    "# Define the Bicep parameters\n",
    "bicep_parameters = {\n",
    "    \"$schema\": \"https://schema.management.azure.com/schemas/2019-04-01/deploymentParameters.json#\",\n",
    "    \"contentVersion\": \"1.0.0.0\",\n",
    "    \"parameters\": {\n",
    "        \"apimSku\": { \"value\": apim_sku },\n",
    "        \"geminiApiKey\": { \"value\": gemini_api_key },\n",
    "        \"geminiAPIPath\": { \"value\": gemini_api_path },\n",
    "        \"apimSubscriptionsConfig\": { \"value\": apim_subscriptions_config },\n",
    "    }\n",
    "}\n",
    "\n",
    "# Write the parameters to the params.json file\n",
    "with open('params.json', 'w') as bicep_parameters_file:\n",
    "    bicep_parameters_file.write(json.dumps(bicep_parameters))\n",
    "\n",
    "# Run the deployment\n",
    "output = utils.run(f\"az deployment group create --name {deployment_name} --resource-group {resource_group_name} --template-file main.bicep --parameters params.json --verbose\",\n",
    "    f\"Deployment '{deployment_name}' succeeded\", f\"Deployment '{deployment_name}' failed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b5ca0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "92cd5531",
   "metadata": {},
   "source": [
    "<a id='3'></a>\n",
    "### 3Ô∏è‚É£ Get the deployment outputs\n",
    "\n",
    "Retrieve the required outputs from the Bicep deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a607c793",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain all of the outputs from the deployment\n",
    "output = utils.run(f\"az deployment group show --name {deployment_name} -g {resource_group_name}\", \n",
    "                   f\"Retrieved deployment: {deployment_name}\", \n",
    "                   f\"Failed to retrieve deployment: {deployment_name}\")\n",
    "\n",
    "if output.success and output.json_data:\n",
    "    log_analytics_id = utils.get_deployment_output(output, 'logAnalyticsWorkspaceId', 'Log Analytics Id')\n",
    "    apim_resource_name = utils.get_deployment_output(output, 'apimResourceName', 'APIM Resource Name')\n",
    "    apim_service_id = utils.get_deployment_output(output, 'apimServiceId', 'APIM Service Id')\n",
    "    apim_resource_gateway_url = utils.get_deployment_output(output, 'apimResourceGatewayURL', 'APIM API Gateway URL')\n",
    "    app_insights_name = utils.get_deployment_output(output, 'applicationInsightsName', 'Application Insights Name')\n",
    "    \n",
    "    apim_subscriptions = json.loads(utils.get_deployment_output(output, 'apimSubscriptions').replace(\"\\'\", \"\\\"\"))\n",
    "    for subscription in apim_subscriptions:\n",
    "        subscription_name = subscription['name']\n",
    "        subscription_key = subscription['key']\n",
    "        utils.print_info(f\"Subscription Name: {subscription_name}\")\n",
    "        utils.print_info(f\"Subscription Key: ****{subscription_key[-4:]}\")\n",
    "    api_key = apim_subscriptions[0].get(\"key\") # default api key to the first subscription key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cad58ea",
   "metadata": {},
   "source": [
    "<a id='4'></a>\n",
    "### üß™ Test the Gemini API with OpenAI SDK\n",
    "\n",
    "Test the Gemini API using the OpenAI Python SDK. Since Gemini provides an OpenAI-compatible endpoint, you can use the familiar OpenAI SDK to interact with Gemini models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaad6015",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "# Create the OpenAI client pointing to the APIM gateway\n",
    "# Note: We use the standard OpenAI client (not AzureOpenAI) since Gemini uses the standard OpenAI API format\n",
    "# We pass the APIM subscription key via the default_headers since APIM expects it in the 'api-key' header\n",
    "client = OpenAI(\n",
    "    base_url=f\"{apim_resource_gateway_url}/{gemini_api_path}\",\n",
    "    api_key=\"not-used\",  # Required by OpenAI client but we use default_headers for APIM\n",
    "    default_headers={\"api-key\": api_key}\n",
    ")\n",
    "\n",
    "# Make a chat completion request\n",
    "response = client.chat.completions.create(\n",
    "    model=gemini_model,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"What is Azure API Management and how can it help with AI workloads?\"}\n",
    "    ],\n",
    "    max_tokens=500\n",
    ")\n",
    "\n",
    "# Print the response\n",
    "print(\"üí¨ Response:\")\n",
    "print(response.choices[0].message.content)\n",
    "print(f\"\\nüíµ Usage - Prompt Tokens: {response.usage.prompt_tokens}, Completion Tokens: {response.usage.completion_tokens}, Total Tokens: {response.usage.total_tokens}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1550ca7",
   "metadata": {},
   "source": [
    "<a id='5'></a>\n",
    "### üß™ Test with Streaming\n",
    "\n",
    "With a streaming API call, the response is sent back incrementally in chunks via an [event stream](https://developer.mozilla.org/docs/Web/API/Server-sent_events/Using_server-sent_events#event_stream_format). In Python, you can iterate over these events with a for loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7477f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "# Create the OpenAI client pointing to the APIM gateway\n",
    "client = OpenAI(\n",
    "    base_url=f\"{apim_resource_gateway_url}/{gemini_api_path}\",\n",
    "    api_key=\"not-used\",\n",
    "    default_headers={\"api-key\": api_key}\n",
    ")\n",
    "\n",
    "# Make a streaming chat completion request\n",
    "stream = client.chat.completions.create(\n",
    "    model=gemini_model,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a creative storyteller.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Tell me a short story about a robot learning to paint.\"}\n",
    "    ],\n",
    "    max_tokens=300,\n",
    "    stream=True\n",
    ")\n",
    "\n",
    "print(\"üí¨ Streaming Response:\")\n",
    "for chunk in stream:\n",
    "    if chunk.choices and len(chunk.choices) > 0:\n",
    "        delta = chunk.choices[0].delta\n",
    "        if delta.content:\n",
    "            print(delta.content, end=\"\", flush=True)\n",
    "\n",
    "print(\"\\n\\n‚úÖ Streaming complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01fa062a",
   "metadata": {},
   "source": [
    "<a id='6'></a>\n",
    "### üß™ Test with direct HTTP requests\n",
    "\n",
    "You can also make direct HTTP requests to the Gemini API through APIM using the OpenAI-compatible chat completions endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2f1765",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# Construct the API URL\n",
    "api_url = f\"{apim_resource_gateway_url}/{gemini_api_path}/chat/completions\"\n",
    "\n",
    "# Set up headers\n",
    "headers = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"api-key\": api_key\n",
    "}\n",
    "\n",
    "# Request payload\n",
    "payload = {\n",
    "    \"model\": gemini_model,\n",
    "    \"messages\": [\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"How are you today?\"}\n",
    "    ],\n",
    "    \"max_tokens\": 100\n",
    "}\n",
    "\n",
    "# Make the request\n",
    "response = requests.post(api_url, headers=headers, json=payload)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    data = response.json()\n",
    "    print(\"üí¨ Response:\")\n",
    "    print(data['choices'][0]['message']['content'])\n",
    "    print(f\"\\nüíµ Total Tokens: {data['usage']['total_tokens']}\")\n",
    "else:\n",
    "    print(f\"‚ùå Error: {response.status_code}\")\n",
    "    print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ead195f",
   "metadata": {},
   "source": [
    "<a id='7'></a>\n",
    "### üìä View Token Metrics in Azure Monitor\n",
    "\n",
    "The API policy emits token metrics that can be viewed in Azure Monitor. Run the following query to see token usage over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b13569",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "# Wait a few seconds for metrics to be ingested\n",
    "print(\"‚è≥ Waiting for metrics to be ingested (this may take a few minutes)...\")\n",
    "time.sleep(10)\n",
    "\n",
    "# Query Application Insights for token metrics (emitted by azure-openai-emit-token-metric policy)\n",
    "query = \"\\\"\" + \"customMetrics \\\n",
    "| where name == 'Total Tokens' \\\n",
    "| extend parsedCustomDimensions = parse_json(customDimensions) \\\n",
    "| extend clientIP = tostring(parsedCustomDimensions.['Client IP']) \\\n",
    "| extend apiId = tostring(parsedCustomDimensions.['API ID']) \\\n",
    "| extend apimSubscription = tostring(parsedCustomDimensions.['Subscription ID']) \\\n",
    "| extend UserId = tostring(parsedCustomDimensions.['User ID']) \\\n",
    "| project timestamp, value, clientIP, apiId, apimSubscription, UserId \\\n",
    "| order by timestamp desc \\\n",
    "| take 20\" + \"\\\"\"\n",
    "\n",
    "output = utils.run(f\"az monitor app-insights query --app {app_insights_name} -g {resource_group_name} --analytics-query {query}\",\n",
    "    \"Retrieved token metrics\", \"Failed to retrieve token metrics (metrics may take a few minutes to appear)\")\n",
    "\n",
    "if output.success and output.json_data:\n",
    "    table = output.json_data['tables'][0]\n",
    "    df = pd.DataFrame(table.get(\"rows\"), columns=[col.get(\"name\") for col in table.get('columns')])\n",
    "    if not df.empty:\n",
    "        df['timestamp'] = pd.to_datetime(df['timestamp']).dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "        print(\"üìä Token Metrics:\")\n",
    "        print(df.to_string(index=False))\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è No token metrics found yet. Metrics may take a few minutes to appear in Application Insights.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a8d06f",
   "metadata": {},
   "source": [
    "### üóëÔ∏è Clean up resources\n",
    "\n",
    "When you're finished with the lab, you should remove all your deployed resources from Azure to avoid extra charges and keep your Azure subscription uncluttered.\n",
    "Use the [clean-up-resources notebook](clean-up-resources.ipynb) for that."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
