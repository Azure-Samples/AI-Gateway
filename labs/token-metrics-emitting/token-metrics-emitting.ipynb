{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# APIM ‚ù§Ô∏è OpenAI\n",
    "\n",
    "## Token Metrics Emitting lab\n",
    "![flow](../../images/token-metrics-emitting.gif)\n",
    "\n",
    "Playground to try the [emit token metric policy](https://learn.microsoft.com/en-us/azure/api-management/azure-openai-emit-token-metric-policy). The policy sends metrics to Application Insights about consumption of large language model tokens through Azure OpenAI Service APIs.\n",
    "\n",
    "Notes:\n",
    "- Token count metrics include: Total Tokens, Prompt Tokens, and Completion Tokens.\n",
    "- This policy supports OpenAI response streaming! Use the [streaming tool](../../tools/streaming.ipynb) to test and troubleshoot response streaming.\n",
    "- Use the [tracing tool](../../tools/tracing.ipynb) to track the behavior and troubleshoot the [policy](policy.xml).\n",
    "\n",
    "[View policy configuration](policy.xml)\n",
    "\n",
    "### Result\n",
    "![result](result.png)\n",
    "\n",
    "### TOC\n",
    "- [0Ô∏è‚É£ Initialize notebook variables](#0)\n",
    "- [1Ô∏è‚É£ Create the Azure Resource Group](#1)\n",
    "- [2Ô∏è‚É£ Create deployment using ü¶æ Bicep](#2)\n",
    "- [3Ô∏è‚É£ Get the deployment outputs](#3)\n",
    "- [üß™ Test the API using a direct HTTP call](#requests)\n",
    "- [üß™ Execute multiple runs for each subscription using the Azure OpenAI Python SDK](#sdk)\n",
    "- [üîç Analyze Application Insights custom metrics with a KQL query](#kql)\n",
    "- [üîç Plot the custom metrics results](#plot)\n",
    "- [üîç See the metrics on the Azure Portal](#portal)\n",
    "- [üóëÔ∏è Clean up resources](#clean)\n",
    "\n",
    "### Prerequisites\n",
    "- [Python 3.8 or later version](https://www.python.org/) installed\n",
    "- [Pandas Library](https://pandas.pydata.org/) and matplotlib installed\n",
    "- [VS Code](https://code.visualstudio.com/) installed with the [Jupyter notebook extension](https://marketplace.visualstudio.com/items?itemName=ms-toolsai.jupyter) enabled\n",
    "- [Azure CLI](https://learn.microsoft.com/en-us/cli/azure/install-azure-cli) installed\n",
    "- [An Azure Subscription](https://azure.microsoft.com/en-us/free/) with Contributor permissions\n",
    "- [Access granted to Azure OpenAI](https://aka.ms/oai/access) or just enable the mock service\n",
    "- [Sign in to Azure with Azure CLI](https://learn.microsoft.com/en-us/cli/azure/authenticate-azure-cli-interactively)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='0'></a>\n",
    "### 0Ô∏è‚É£ Initialize notebook variables\n",
    "\n",
    "- Resources will be suffixed by a unique string based on your subscription id\n",
    "- The ```mock_webapps``` variable sets the list of deployed Web Apps for the mocking functionality. Clean the ```openai_resources``` list to simulate the OpenAI behaviour with the mocking service.\n",
    "- Adjust the location parameters according your preferences and on the [product availability by Azure region.](https://azure.microsoft.com/en-us/explore/global-infrastructure/products-by-region/?cdn=disable&products=cognitive-services,api-management) \n",
    "- Adjust the OpenAI model and version according the [availability by region.](https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import datetime\n",
    "import requests\n",
    "\n",
    "deployment_name = os.path.basename(os.path.dirname(globals()['__vsc_ipynb_file__']))\n",
    "resource_group_name = f\"lab-{deployment_name}\" # change the name to match your naming style\n",
    "resource_group_location = \"westeurope\"\n",
    "apim_resource_name = \"apim\"\n",
    "apim_resource_location = \"westeurope\"\n",
    "apim_resource_sku = \"Basicv2\"\n",
    "openai_resources = [ {\"name\": \"openai1\", \"location\": \"swedencentral\"} ] # list of OpenAI resources to deploy. Clear this list to use only the mock resources\n",
    "openai_resources_sku = \"S0\"\n",
    "openai_model_name = \"gpt-35-turbo\"\n",
    "openai_model_version = \"0613\"\n",
    "openai_deployment_name = \"gpt-35-turbo\"\n",
    "openai_api_version = \"2024-02-01\"\n",
    "openai_specification_url='https://raw.githubusercontent.com/Azure/azure-rest-api-specs/main/specification/cognitiveservices/data-plane/AzureOpenAI/inference/stable/' + openai_api_version + '/inference.json'\n",
    "openai_backend_pool = \"openai-backend-pool\"\n",
    "mock_backend_pool = \"mock-backend-pool\"\n",
    "mock_webapps = [ {\"name\": \"openaimock1\", \"endpoint\": \"https://openaimock1.azurewebsites.net\"}, {\"name\": \"openaimock2\", \"endpoint\": \"https://openaimock2.azurewebsites.net\"} ]\n",
    "\n",
    "log_analytics_name = \"workspace\"\n",
    "app_insights_name = 'insights'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='1'></a>\n",
    "### 1Ô∏è‚É£ Create the Azure Resource Group\n",
    "All resources deployed in this lab will be created in the specified resource group. Skip this step if you want to use an existing resource group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resource_group_stdout = ! az group create --name {resource_group_name} --location {resource_group_location}\n",
    "if resource_group_stdout.n.startswith(\"ERROR\"):\n",
    "    print(resource_group_stdout)\n",
    "else:\n",
    "    print(\"‚úÖ Azure Resource Group \", resource_group_name, \" created ‚åö \", datetime.datetime.now().time())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='2'></a>\n",
    "### 2Ô∏è‚É£ Create deployment using ü¶æ Bicep\n",
    "\n",
    "This lab uses [Bicep](https://learn.microsoft.com/en-us/azure/azure-resource-manager/bicep/overview?tabs=bicep) to declarative define all the resources that will be deployed. Change the parameters or the [main.bicep](main.bicep) directly to try different configurations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(openai_resources) > 0:\n",
    "    backend_id = openai_backend_pool if len(openai_resources) > 1 else openai_resources[0].get(\"name\")\n",
    "elif len(mock_webapps) > 0:\n",
    "    backend_id = mock_backend_pool if len(mock_backend_pool) > 1 else mock_webapps[0].get(\"name\")\n",
    "\n",
    "with open(\"policy.xml\", 'r') as policy_xml_file:\n",
    "    policy_template_xml = policy_xml_file.read()\n",
    "    policy_xml = policy_template_xml.replace(\"{backend-id}\", backend_id)\n",
    "    policy_xml_file.close()\n",
    "open(\"policy.xml\", 'w').write(policy_xml)\n",
    "\n",
    "bicep_parameters = {\n",
    "  \"$schema\": \"https://schema.management.azure.com/schemas/2019-04-01/deploymentParameters.json#\",\n",
    "  \"contentVersion\": \"1.0.0.0\",\n",
    "  \"parameters\": {\n",
    "    \"mockWebApps\": { \"value\": mock_webapps },\n",
    "    \"mockBackendPoolName\": { \"value\": mock_backend_pool },\n",
    "    \"openAIBackendPoolName\": { \"value\": openai_backend_pool },\n",
    "    \"openAIConfig\": { \"value\": openai_resources },\n",
    "    \"openAIDeploymentName\": { \"value\": openai_deployment_name },\n",
    "    \"openAISku\": { \"value\": openai_resources_sku },\n",
    "    \"openAIModelName\": { \"value\": openai_model_name },\n",
    "    \"openAIModelVersion\": { \"value\": openai_model_version },\n",
    "    \"openAIAPISpecURL\": { \"value\": openai_specification_url },\n",
    "    \"apimResourceName\": { \"value\": apim_resource_name},\n",
    "    \"apimResourceLocation\": { \"value\": apim_resource_location},\n",
    "    \"apimSku\": { \"value\": apim_resource_sku},\n",
    "    \"logAnalyticsName\": { \"value\": log_analytics_name },\n",
    "    \"applicationInsightsName\": { \"value\": app_insights_name }\n",
    "  }\n",
    "}\n",
    "with open('params.json', 'w') as bicep_parameters_file:\n",
    "    bicep_parameters_file.write(json.dumps(bicep_parameters))\n",
    "\n",
    "! az deployment group create --name {deployment_name} --resource-group {resource_group_name} --template-file \"main.bicep\" --parameters \"params.json\"\n",
    "\n",
    "open(\"policy.xml\", 'w').write(policy_template_xml)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='3'></a>\n",
    "### 3Ô∏è‚É£ Get the deployment outputs\n",
    "\n",
    "We are now at the stage where we only need to retrieve the gateway URL and the subscription before we are ready for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deployment_stdout = ! az deployment group show --name {deployment_name} -g {resource_group_name} --query properties.outputs.apimServiceId.value -o tsv\n",
    "apim_service_id = deployment_stdout.n\n",
    "print(\"üëâüèª APIM Service Id: \", apim_service_id)\n",
    "\n",
    "deployment_stdout = ! az deployment group show --name {deployment_name} -g {resource_group_name} --query properties.outputs.apimSubscriptionKey.value -o tsv\n",
    "apim_subscription_key = deployment_stdout.n\n",
    "deployment_stdout = ! az deployment group show --name {deployment_name} -g {resource_group_name} --query properties.outputs.apimSubscription2Key.value -o tsv\n",
    "apim_subscription2_key = deployment_stdout.n\n",
    "deployment_stdout = ! az deployment group show --name {deployment_name} -g {resource_group_name} --query properties.outputs.apimSubscription3Key.value -o tsv\n",
    "apim_subscription3_key = deployment_stdout.n\n",
    "deployment_stdout = ! az deployment group show --name {deployment_name} -g {resource_group_name} --query properties.outputs.apimResourceGatewayURL.value -o tsv\n",
    "apim_resource_gateway_url = deployment_stdout.n\n",
    "print(\"üëâüèª API Gateway URL: \", apim_resource_gateway_url)\n",
    "\n",
    "deployment_stdout = ! az deployment group show --name {deployment_name} -g {resource_group_name} --query properties.outputs.logAnalyticsWorkspaceId.value -o tsv\n",
    "workspace_id = deployment_stdout.n\n",
    "print(\"üëâüèª Workspace ID: \", workspace_id)\n",
    "\n",
    "deployment_stdout = ! az deployment group show --name {deployment_name} -g {resource_group_name} --query properties.outputs.applicationInsightsResourceName.value -o tsv\n",
    "app_insights_resource_name = deployment_stdout.n\n",
    "print(\"üëâüèª Application Insights Resource Name: \", app_insights_resource_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='requests'></a>\n",
    "### üß™ Test the API using a direct HTTP call\n",
    "\n",
    "Tip: Use the [tracing tool](../../tools/tracing.ipynb) to track the behavior and troubleshoot the [policy](policy.xml)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = apim_resource_gateway_url + \"/openai/deployments/\" + openai_deployment_name + \"/chat/completions?api-version=\" + openai_api_version\n",
    "\n",
    "messages={\"messages\":[\n",
    "    {\"role\": \"system\", \"content\": \"You are a sarcastic unhelpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Can you tell me the time, please?\"}\n",
    "]}\n",
    "response = requests.post(url, headers = {'api-key':apim_subscription3_key, 'x-user-id': 'alex'}, json = messages)\n",
    "print(\"status code: \", response.status_code)\n",
    "if (response.status_code == 200):\n",
    "    data = json.loads(response.text)\n",
    "    print(\"response: \", data.get(\"choices\")[0].get(\"message\").get(\"content\"))\n",
    "else:\n",
    "    print(response.text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='sdk'></a>\n",
    "### üß™ Execute multiple runs for each subscription using the Azure OpenAI Python SDK\n",
    "\n",
    "We will send requests for each subscription. Adjust the `sleep_time_ms` and the number of `runs` to your test scenario.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from openai import AzureOpenAI\n",
    "runs = 15\n",
    "sleep_time_ms = 60000\n",
    "for i in range(runs):\n",
    "    print(\"‚ñ∂Ô∏è Run: \", i+1)\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a sarcastic unhelpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Can you tell me the time, please?\"}\n",
    "    ]\n",
    "    client = AzureOpenAI(azure_endpoint=apim_resource_gateway_url, api_key=apim_subscription_key, api_version=openai_api_version)\n",
    "    response = client.chat.completions.create(model=openai_model_name, messages=messages, extra_headers={\"x-user-id\": \"alex\"})\n",
    "    print(\"üí¨ \",\"for subscription 1: \", response.choices[0].message.content)\n",
    "\n",
    "    client = AzureOpenAI(azure_endpoint=apim_resource_gateway_url, api_key=apim_subscription2_key, api_version=openai_api_version)\n",
    "    response = client.chat.completions.create(model=openai_model_name, messages=messages, extra_headers={\"x-user-id\": \"alex\"})\n",
    "    print(\"üí¨ \",\"for subscription 2: \", response.choices[0].message.content)\n",
    "\n",
    "    client = AzureOpenAI(azure_endpoint=apim_resource_gateway_url, api_key=apim_subscription3_key, api_version=openai_api_version)\n",
    "    response = client.chat.completions.create(model=openai_model_name, messages=messages, extra_headers={\"x-user-id\": \"alex\"})\n",
    "    print(\"üí¨ \",\"for subscription 3: \", response.choices[0].message.content)\n",
    "\n",
    "    time.sleep(sleep_time_ms/1000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='kql'></a>\n",
    "### üîç Analyze Application Insights custom metrics with a KQL query\n",
    "\n",
    "With this query you can get the custom metrics that were emitted by Azure APIM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "query = \"\\\"\" + \"customMetrics  \\\n",
    "| where name == 'Total Tokens' \\\n",
    "| extend parsedCustomDimensions = parse_json(customDimensions) \\\n",
    "| extend clientIP = tostring(parsedCustomDimensions.['Client IP']) \\\n",
    "| extend apiId = tostring(parsedCustomDimensions.['API ID']) \\\n",
    "| extend apimSubscription = tostring(parsedCustomDimensions.['Subscription ID']) \\\n",
    "| extend UserId = tostring(parsedCustomDimensions.['User ID']) \\\n",
    "| project timestamp, value, clientIP, apiId, apimSubscription, UserId \\\n",
    "| order by timestamp asc\" + \"\\\"\"\n",
    "\n",
    "result_stdout = ! az monitor app-insights query --app {app_insights_resource_name} -g {resource_group_name} --analytics-query {query} \n",
    "result = json.loads(result_stdout.n)\n",
    "\n",
    "table = result.get('tables')[0]\n",
    "df = pd.DataFrame(table.get(\"rows\"), columns=[col.get(\"name\") for col in table.get('columns')])\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp']).dt.strftime('%H:%M')\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='plot'></a>\n",
    "### üîç Plot the custom metrics results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the results\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "mpl.rcParams['figure.figsize'] = [15, 7]\n",
    "ax = df.plot(kind='line', x='timestamp', y='value', legend=False)\n",
    "plt.title('Total token usage over time')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Tokens')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='portal'></a>\n",
    "### üîç See the metrics on the Azure Portal\n",
    "\n",
    "Open the Application Insights resource, navigate to the metrics blade, and select the defined namespace (openai). Choose the metric \"Total Tokens\" with a Sum aggregation. Then, apply splitting by 'Subscription Id' to view values for each dimension.\n",
    "\n",
    "![result](result.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='clean'></a>\n",
    "### üóëÔ∏è Clean up resources\n",
    "\n",
    "When you're finished with the lab, you should remove all your deployed resources from Azure to avoid extra charges and keep your Azure subscription uncluttered.\n",
    "Use the [clean-up-resources notebook](clean-up-resources.ipynb) for that."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
