{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# APIM ‚ù§Ô∏è OpenAI\n",
    "\n",
    "## Advanced Load Balancing lab\n",
    "![flow](../../images/advanced-load-balancing.gif)\n",
    "\n",
    "Playground to try the advanced load balancing (based on a custom [APIM policy](https://learn.microsoft.com/en-us/azure/api-management/api-management-howto-policies)) to either a list of Azure OpenAI endpoints or mock servers.\n",
    "\n",
    "This load balancer is based on a custom policy configuration forked from this great [smart load balancer repo](https://github.com/andredewes/apim-aoai-smart-loadbalancing) and adds the following enhancements:\n",
    "- Loads the load balancer configuration from a named value\n",
    "- Uses backends to enable the combination with the built-in circuit breaking feature\n",
    "- The policy doesn't have to be changed to add/modify endpoints or configure the load balancer \n",
    "- Dynamicly supports any number of OpenAI endpoints\n",
    "\n",
    "### Prerequisites\n",
    "- [Python 3.8 or later version](https://www.python.org/) installed\n",
    "- [VS Code](https://code.visualstudio.com/) installed with the [Jupyter notebook extension](https://marketplace.visualstudio.com/items?itemName=ms-toolsai.jupyter) enabled\n",
    "- [Azure CLI](https://learn.microsoft.com/en-us/cli/azure/install-azure-cli) installed\n",
    "- [An Azure Subscription](https://azure.microsoft.com/en-us/free/) with Contributor permissions\n",
    "- [Access granted to Azure OpenAI](https://aka.ms/oai/access) or just enable the mock service\n",
    "- [Sign in to Azure with Azure CLI](https://learn.microsoft.com/en-us/cli/azure/authenticate-azure-cli-interactively)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0Ô∏è‚É£ Initialize notebook variables\n",
    "\n",
    "- Resources will be suffixed by a unique string based on your subscription id\n",
    "- The ```mock_webapps``` variable sets the list of deployed Web Apps for the mocking functionality. Clean the ```openai_resources``` list to simulate the OpenAI behaviour with the mocking service.\n",
    "- Adjust the location parameters according your preferences and on the [product availability by Azure region.](https://azure.microsoft.com/en-us/explore/global-infrastructure/products-by-region/?cdn=disable&products=cognitive-services,api-management) \n",
    "- Adjust the OpenAI model and version according the [availability by region.](https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import datetime\n",
    "import requests\n",
    "\n",
    "resource_group_name = \"lab-ai-gateway\" # change the name to match your naming style\n",
    "resource_group_location = \"westeurope\"\n",
    "apim_resource_name = \"apim\"\n",
    "apim_resource_location = \"westeurope\"\n",
    "apim_resource_sku = \"Basicv2\"\n",
    "openai_resources = [ {\"name\": \"openai1\", \"location\": \"swedencentral\"}, {\"name\": \"openai2\", \"location\": \"francecentral\"}  ] # list of OpenAI resources to deploy. Clear this list to use only the mock resources\n",
    "openai_lb_config = [ {\"name\": \"openai1\", \"priority\": 1, \"weight\": 100}, {\"name\": \"openai2\", \"priority\": 2, \"weight\": 300}  ] # advanced load balancer configuration for OpenAI resources that will be stored as a named value\n",
    "openai_resources_sku = \"S0\"\n",
    "openai_model_name = \"gpt-35-turbo\"\n",
    "openai_model_version = \"0613\"\n",
    "openai_deployment_name = \"gpt-35-turbo\"\n",
    "openai_api_version = \"2024-02-01\"\n",
    "openai_specification_url='https://raw.githubusercontent.com/Azure/azure-rest-api-specs/main/specification/cognitiveservices/data-plane/AzureOpenAI/inference/stable/' + openai_api_version + '/inference.json'\n",
    "openai_backend_pool = \"openai-backend-pool\"\n",
    "mock_backend_pool = \"mock-backend-pool\"\n",
    "mock_webapps = [ {\"name\": \"openaimock1\", \"endpoint\": \"https://openaimock1.azurewebsites.net\"}, {\"name\": \"openaimock2\", \"endpoint\": \"https://openaimock2.azurewebsites.net\"} ]\n",
    "mock_lb_config = [ {\"name\": \"openaimock1\", \"priority\": 1, \"weight\": 100}, {\"name\": \"openaimock2\", \"priority\": 2, \"weight\": 300}  ] # advanced load balancer configuration for mock services that will be stored as a named value\n",
    "deployment_name = os.path.basename(globals()['__vsc_ipynb_file__']).replace(\".ipynb\", \"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1Ô∏è‚É£ Create the Azure Resource Group\n",
    "All resources deployed in this lab will be created in the specified resource group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resource_group_stdout = ! az group create --name {resource_group_name} --location {resource_group_location}\n",
    "if resource_group_stdout.n.startswith(\"ERROR\"):\n",
    "    print(resource_group_stdout)\n",
    "else:\n",
    "    print(\"‚úÖ Azure Resource Grpup \", resource_group_name, \" created ‚åö \", datetime.datetime.now().time())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2Ô∏è‚É£ Create deployment using ü¶æ Bicep\n",
    "\n",
    "This lab uses [Bicep](https://learn.microsoft.com/en-us/azure/azure-resource-manager/bicep/overview?tabs=bicep) to declarative define all the resources that will be deployed. Change the parameters or the [main.bicep](main.bicep) directly to try different configurations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_spec = requests.get(openai_specification_url)\n",
    "open(\"openai.json\", \"wb\").write(openai_spec.content) # the openai.json will be saved with the latest OpenAI API specification for the version specified\n",
    "\n",
    "with open(\"policy.xml\", 'r') as policy_xml_file:\n",
    "    policy_template_xml = policy_xml_file.read()\n",
    "    policy_xml = policy_template_xml.replace(\"{backend-id}\", openai_backend_pool if len(openai_resources) > 0 else mock_backend_pool)\n",
    "    policy_xml_file.close()\n",
    "open(\"policy.xml\", 'w').write(policy_xml)\n",
    "\n",
    "loadbalancer_config = openai_lb_config if len(openai_resources) > 0 else mock_lb_config\n",
    "loadbalancer_config = json.dumps(loadbalancer_config).replace(\"\\\"\", \"'\")\n",
    "\n",
    "bicep_parameters = {\n",
    "  \"$schema\": \"https://schema.management.azure.com/schemas/2019-04-01/deploymentParameters.json#\",\n",
    "  \"contentVersion\": \"1.0.0.0\",\n",
    "  \"parameters\": {\n",
    "    \"mockWebApps\": { \"value\": mock_webapps },\n",
    "    \"mockBackendPoolName\": { \"value\": mock_backend_pool },\n",
    "    \"openAIBackendPoolName\": { \"value\": openai_backend_pool },\n",
    "    \"openAIConfig\": { \"value\": openai_resources },\n",
    "    \"openAILoadBalancingConfigValue\": { \"value\": loadbalancer_config },\n",
    "    \"openAIDeploymentName\": { \"value\": openai_deployment_name },\n",
    "    \"openAISku\": { \"value\": openai_resources_sku },\n",
    "    \"openAIModelName\": { \"value\": openai_model_name },\n",
    "    \"openAIModelVersion\": { \"value\": openai_model_version },\n",
    "    \"apimResourceName\": { \"value\": apim_resource_name},\n",
    "    \"apimResourceLocation\": { \"value\": apim_resource_location},\n",
    "    \"apimSku\": { \"value\": apim_resource_sku}\n",
    "  }\n",
    "}\n",
    "with open('params.json', 'w') as bicep_parameters_file:\n",
    "    bicep_parameters_file.write(json.dumps(bicep_parameters))\n",
    "\n",
    "deployment_stdout = ! az deployment group create --name {deployment_name} --resource-group {resource_group_name} --template-file \"main.bicep\" --parameters \"params.json\"\n",
    "if deployment_stdout.n.find(\"ERROR\"):\n",
    "    print(deployment_stdout)\n",
    "else:\n",
    "    print(\"‚úÖ Deployment finished on the resource group \", resource_group_name, \" ‚åö \", datetime.datetime.now().time())\n",
    "open(\"policy.xml\", 'w').write(policy_template_xml)\n",
    "os.remove('params.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3Ô∏è‚É£ Get the deployment outputs\n",
    "\n",
    "We are now at the stage where we only need to retrieve the gateway URL and the subscription before we are ready for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deployment_stdout = ! az deployment group show --name {deployment_name} -g {resource_group_name} --query properties.outputs.apimResourceGatewayURL.value -o tsv\n",
    "apim_resource_gateway_url = deployment_stdout.n\n",
    "deployment_stdout = ! az deployment group show --name {deployment_name} -g {resource_group_name} --query properties.outputs.apimSubscriptionKey.value -o tsv\n",
    "apim_subscription_key = deployment_stdout.n\n",
    "print(\"üëâüèª API Gateway URL: \", apim_resource_gateway_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üß™ Test the API using a direct HTTP call\n",
    "Requests is an elegant and simple HTTP library for Python that will be used here to make raw API requests and inspect the responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = apim_resource_gateway_url + \"/openai/deployments/\" + openai_deployment_name + \"/chat/completions?api-version=\" + openai_api_version\n",
    "if len(openai_resources) > 0:\n",
    "    messages={\"messages\":[\n",
    "        {\"role\": \"system\", \"content\": \"You are a sarcastic unhelpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Can you tell me the time, please?\"}\n",
    "    ]}\n",
    "elif len(mock_webapps) > 0:\n",
    "    messages={\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"system\", \n",
    "                \"content\": {\n",
    "                    \"simulation\": {\n",
    "                        \"default\": {\"response_status_code\": 200, \"wait_time_ms\": 0},\n",
    "                        \"openaimock1.azurewebsites.net\": {\"response_status_code\": 429}\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "response = requests.post(url, headers = {'api-key':apim_subscription_key}, json = messages)\n",
    "print(\"status code: \", response.status_code)\n",
    "print(\"headers \", response.headers)\n",
    "print(\"x-ms-region: \", response.headers.get(\"x-ms-region\")) # this header is useful to determine the region of the backend that served the request\n",
    "print(\"x-ms-openai: \", response.headers.get(\"x-ms-openai\")) \n",
    "\n",
    "if (response.status_code == 200):\n",
    "    data = json.loads(response.text)\n",
    "    print(\"response: \", data.get(\"choices\")[0].get(\"message\").get(\"content\"))\n",
    "else:\n",
    "    print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üß™ Test the API using the Azure OpenAI Python SDK\n",
    "OpenAPI provides a widely used [Python library](https://github.com/openai/openai-python). The library includes type definitions for all request params and response fields. The goal of this test is to assert that APIM can seamlessly proxy requests to OpenAI without disrupting its functionality.\n",
    "- Note: run ```pip install openai``` in a terminal before executing this step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import AzureOpenAI\n",
    "if len(openai_resources) > 0:\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a sarcastic unhelpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Can you tell me the time, please?\"}\n",
    "    ]\n",
    "elif len(mock_webapps) > 0:\n",
    "    messages=[\n",
    "            {\n",
    "                \"role\": \"system\", \n",
    "                \"content\": {\n",
    "                    \"simulation\": {\n",
    "                        \"default\": {\"response_status_code\": 200, \"wait_time_ms\": 0},\n",
    "                        \"openaimock1.azurewebsites.net\": {\"response_status_code\": 429}\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "client = AzureOpenAI(\n",
    "    azure_endpoint=apim_resource_gateway_url,\n",
    "    api_key=apim_subscription_key,\n",
    "    api_version=openai_api_version\n",
    ")\n",
    "response = client.chat.completions.create(model=openai_model_name, messages=messages)\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üóëÔ∏è Clean up resources\n",
    "\n",
    "When you're finished with the lab, you should remove all your deployed resources from Azure to avoid extra charges and keep your Azure subscription uncluttered. Removing the resource group is the fastest way to remove all Azure resources that you have created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_cell = False # Set to False to avoid running this cell when executing the Run All command\n",
    "\n",
    "if run_cell:\n",
    "    def log(stdout, name, action):\n",
    "        if stdout.n.startswith(\"ERROR\"):\n",
    "            print(\"üëéüèª \", name, \" was NOT \", action, \": \", stdout)\n",
    "        else:\n",
    "            print(\"üëçüèª \", name, \" was \", action, \" ‚åö \", datetime.datetime.now().time())\n",
    "    deployment_stdout = ! az deployment group show --name {deployment_name} -g {resource_group_name} -o json    \n",
    "    deployment = json.loads(deployment_stdout.n)\n",
    "    for resource in deployment.get(\"properties\").get(\"outputResources\"):\n",
    "        resource_id = resource.get(\"id\")\n",
    "        try:\n",
    "            query = \"\\\"{type:type, name:name, location:location}\\\"\"\n",
    "            resource_stdout = ! az resource show --id {resource_id} --query {query} -o json\n",
    "            resource = json.loads(resource_stdout.n)\n",
    "            resource_name = resource.get(\"name\")\n",
    "            resource_type = resource.get(\"type\")  \n",
    "            if resource_type == \"Microsoft.CognitiveServices/accounts\":\n",
    "                resource_location = \"\\\"\" + resource.get(\"location\") + \"\\\"\"\n",
    "                delete_stdout = ! az cognitiveservices account delete -g {resource_group_name} -n {resource_name}\n",
    "                log(delete_stdout, resource_name, \"deleted\")\n",
    "                delete_stdout = ! az cognitiveservices account purge -g {resource_group_name} -n {resource_name} -l {resource_location}\n",
    "                log(delete_stdout, resource_name, \"purged\")\n",
    "            elif resource_type == \"Microsoft.ApiManagement/service\":\n",
    "                resource_location = \"\\\"\" + resource.get(\"location\") + \"\\\"\"\n",
    "                delete_stdout = ! az apim delete -n {resource_name} -g {resource_group_name} -y\n",
    "                log(delete_stdout, resource_name, \"deleted\")\n",
    "                delete_stdout = ! az apim deletedservice purge --service-name {resource_name} --location {resource_location}\n",
    "                log(delete_stdout, resource_name, \"purged\")\n",
    "        except:\n",
    "            print(\"‚úåüèª \", resource_id, \" ignored\")\n",
    "    delete_stdout = ! az group delete --name {resource_group_name} -y\n",
    "    log(delete_stdout, resource_group_name, \"deleted\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
