{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# APIM ‚ù§Ô∏è OpenAI\n",
    "\n",
    "## AI Foundry Deepseek lab\n",
    "![flow](../../images/ai-foundry-deepseek.gif)\n",
    "\n",
    "Playground to try the [Deepseek R1 model](https://azure.microsoft.com/en-us/blog/deepseek-r1-is-now-available-on-azure-ai-foundry-and-github/) via the AI Model Inference from [Azure AI Foundry](https://azure.microsoft.com/en-us/products/ai-foundry). This lab uses the [Azure AI Model Inference API](https://learn.microsoft.com/en-us/azure/ai-foundry/model-inference/how-to/inference?tabs=python) and two APIM LLM policies: [llm-token-limit](https://learn.microsoft.com/en-us/azure/api-management/llm-token-limit-policy) and [llm-emit-token-metric](https://learn.microsoft.com/en-us/azure/api-management/llm-emit-token-metric-policy).\n",
    "\n",
    "[View policy configuration](policy.xml)\n",
    "\n",
    "### Result\n",
    "\n",
    "![result](result.png)\n",
    "\n",
    "### Prerequisites\n",
    "- [Python 3.12 or later version](https://www.python.org/) installed\n",
    "- [Pandas Library](https://pandas.pydata.org/) and matplotlib installed\n",
    "- [VS Code](https://code.visualstudio.com/) installed with the [Jupyter notebook extension](https://marketplace.visualstudio.com/items?itemName=ms-toolsai.jupyter) enabled\n",
    "- [Azure CLI](https://learn.microsoft.com/cli/azure/install-azure-cli) installed\n",
    "- [An Azure Subscription](https://azure.microsoft.com/free/) with Contributor permissions\n",
    "- [Sign in to Azure with Azure CLI](https://learn.microsoft.com/cli/azure/authenticate-azure-cli-interactively)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='0'></a>\n",
    "### 0Ô∏è‚É£ Initialize notebook variables\n",
    "\n",
    "- Resources will be suffixed by a unique string based on your subscription id.\n",
    "- Adjust the location parameters according your preferences and on the [product availability by Azure region.](https://azure.microsoft.com/explore/global-infrastructure/products-by-region/?cdn=disable&products=cognitive-services,api-management) \n",
    "- Adjust the OpenAI model and version according the [availability by region.](https://learn.microsoft.com/azure/ai-services/openai/concepts/models) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import os, sys, json\n",
    "sys.path.insert(1, '../../shared')  # add the shared directory to the Python path\n",
    "import utils\n",
    "\n",
    "deployment_name = os.path.basename(os.path.dirname(globals()['__vsc_ipynb_file__']))\n",
    "resource_group_name = f\"lab-{deployment_name}\" # change the name to match your naming convention\n",
    "resource_group_location = \"eastus2\" # all the resources will be deployed in this location\n",
    "\n",
    "apim_sku = 'Basicv2'\n",
    "apim_subscriptions_config = [{\"name\": \"subscription1\", \"displayName\": \"Subscription 1\"}, \n",
    "                             {\"name\": \"subscription2\", \"displayName\": \"Subscription 2\"}, \n",
    "                             {\"name\": \"subscription3\", \"displayName\": \"Subscription 3\"}]\n",
    "\n",
    "# https://learn.microsoft.com/en-us/azure/ai-foundry/model-inference/concepts/models\n",
    "models_config = [{\"name\": \"DeepSeek-R1\", \"publisher\": \"DeepSeek\", \"version\": \"1\", \"sku\": \"GlobalStandard\", \"capacity\": 1},\n",
    "                 {\"name\": \"Phi-4\", \"publisher\": \"Microsoft\", \"version\": \"3\", \"sku\": \"GlobalStandard\", \"capacity\": 1}]\n",
    "\n",
    "utils.print_ok('Notebook initialized')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='1'></a>\n",
    "### 1Ô∏è‚É£ Verify the Azure CLI and the connected Azure subscription\n",
    "\n",
    "The following commands ensure that you have the latest version of the Azure CLI and that the Azure CLI is connected to your Azure subscription."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = utils.run(\"az account show\", \"Retrieved az account\", \"Failed to get the current az account\")\n",
    "\n",
    "if output.success and output.json_data:\n",
    "    current_user = output.json_data['user']['name']\n",
    "    tenant_id = output.json_data['tenantId']\n",
    "    subscription_id = output.json_data['id']\n",
    "\n",
    "    utils.print_info(f\"Current user: {current_user}\")\n",
    "    utils.print_info(f\"Tenant ID: {tenant_id}\")\n",
    "    utils.print_info(f\"Subscription ID: {subscription_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='2'></a>\n",
    "### 2Ô∏è‚É£ Create deployment using ü¶æ Bicep\n",
    "\n",
    "This lab uses [Bicep](https://learn.microsoft.com/azure/azure-resource-manager/bicep/overview?tabs=bicep) to declarative define all the resources that will be deployed in the specified resource group. Change the parameters or the [main.bicep](main.bicep) directly to try different configurations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the resource group if doesn't exist\n",
    "utils.create_resource_group(resource_group_name, resource_group_location)\n",
    "\n",
    "# Define the Bicep parameters\n",
    "bicep_parameters = {\n",
    "    \"$schema\": \"https://schema.management.azure.com/schemas/2019-04-01/deploymentParameters.json#\",\n",
    "    \"contentVersion\": \"1.0.0.0\",\n",
    "    \"parameters\": {\n",
    "        \"apimSku\": { \"value\": apim_sku },\n",
    "        \"apimSubscriptionsConfig\": { \"value\": apim_subscriptions_config },\n",
    "        \"modelsConfig\": { \"value\": models_config }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Write the parameters to the params.json file\n",
    "with open('params.json', 'w') as bicep_parameters_file:\n",
    "    bicep_parameters_file.write(json.dumps(bicep_parameters))\n",
    "\n",
    "# Run the deployment\n",
    "output = utils.run(f\"az deployment group create --name {deployment_name} --resource-group {resource_group_name} --template-file main.bicep --parameters params.json\",\n",
    "    f\"Deployment '{deployment_name}' succeeded\", f\"Deployment '{deployment_name}' failed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='3'></a>\n",
    "### 3Ô∏è‚É£ Get the deployment outputs\n",
    "\n",
    "Retrieve the required outputs from the Bicep deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain all of the outputs from the deployment\n",
    "output = utils.run(f\"az deployment group show --name {deployment_name} -g {resource_group_name}\", f\"Retrieved deployment: {deployment_name}\", f\"Failed to retrieve deployment: {deployment_name}\")\n",
    "\n",
    "if output.success and output.json_data:\n",
    "    app_insights_name = utils.get_deployment_output(output, 'applicationInsightsName', 'Application Insights Name')    \n",
    "    apim_resource_gateway_url = utils.get_deployment_output(output, 'apimResourceGatewayURL', 'APIM API Gateway URL')\n",
    "    apim_subscriptions = json.loads(utils.get_deployment_output(output, 'apimSubscriptions').replace(\"\\'\", \"\\\"\"))\n",
    "    for subscription in apim_subscriptions:\n",
    "        subscription_name = subscription['name']\n",
    "        subscription_key = subscription['key']\n",
    "        utils.print_info(f\"Subscription Name: {subscription_name}\")\n",
    "        utils.print_info(f\"Subscription Key: ****{subscription_key[-4:]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='sdk'></a>\n",
    "### üß™ Test the API using the Inference SDK\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.inference import ChatCompletionsClient\n",
    "from azure.ai.inference.models import SystemMessage, UserMessage\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "\n",
    "client = ChatCompletionsClient(\n",
    "    endpoint=f\"{apim_resource_gateway_url}/models\",\n",
    "    credential=AzureKeyCredential(apim_subscriptions[0]['key']),\n",
    ")\n",
    "\n",
    "response = client.complete(\n",
    "    messages=[\n",
    "        SystemMessage(content=\"You are a sarcastic, unhelpful assistant.\"),\n",
    "        UserMessage(content=\"Can you tell me the time, please?\")\n",
    "    ],\n",
    "    max_tokens=2048,\n",
    "    model=models_config[0]['name']\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='ratelimit'></a>\n",
    "### üß™ Test the token rate limit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "url = apim_resource_gateway_url + \"/models/chat/completions?api-version=2024-05-01-preview\"\n",
    "api_runs = []\n",
    "for i in range(10):\n",
    "    messages={\"messages\":[\n",
    "            {\"role\": \"system\", \"content\": \"You are a sarcastic, unhelpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": \"Can you tell me the time, please?\"}\n",
    "        ],\n",
    "        \"model\": models_config[0]['name']\n",
    "    }\n",
    "    response = requests.post(url, headers={'api-key': apim_subscriptions[0]['key']}, json=messages)\n",
    "    if (response.status_code == 200):\n",
    "        data = json.loads(response.text)\n",
    "        total_tokens = data.get(\"usage\").get(\"total_tokens\")\n",
    "        print(\"‚ñ∂Ô∏è Run: \", i+1, \"status code: \", response.status_code, \"‚úÖ\", \" tokens: \", total_tokens)\n",
    "        print(\"üí¨ \", data.get(\"choices\")[0].get(\"message\").get(\"content\"))\n",
    "    else:\n",
    "        print(\"‚ñ∂Ô∏è Run: \", i+1, \"status code: \", response.status_code, \"‚õî\")\n",
    "        print(response.text)\n",
    "        total_tokens = 0\n",
    "    api_runs.append((total_tokens, response.status_code))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='plot'></a>\n",
    "### üîç Analyze Token Rate limiting results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the results\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.figsize'] = [15, 7]\n",
    "df = pd.DataFrame(api_runs, columns=['Tokens', 'Status Code'])\n",
    "df['Run'] = range(1, len(df) + 1)\n",
    "colors = ['red' if str(code).startswith('5') else 'yellow' if str(code).startswith('4') else 'lightblue' for code in df['Status Code']]\n",
    "ax = df.plot(kind='bar', x='Run', y='Tokens', color=colors, legend=False)\n",
    "plt.title('Rate Limiting results')\n",
    "plt.xlabel('Runs')\n",
    "plt.ylabel('Tokens')\n",
    "plt.xticks(df['Run'], rotation=0)\n",
    "for i, val in enumerate(df['Status Code']):\n",
    "    ax.text(i, 20, '' if int(val) == 200 else 'Status:429', ha='center', va='bottom')\n",
    "for i, val in enumerate(df['Tokens']):\n",
    "    ax.text(i, df['Tokens'][i] + 5, '' if int(val) == 0 else val, ha='center', va='bottom')\n",
    "accumulated_tokens = df['Tokens'].cumsum()\n",
    "ax.plot(df['Run']-1, accumulated_tokens, color='green', label='Accumulated Tokens')\n",
    "for i, val in enumerate(accumulated_tokens):\n",
    "    ax.text(i, val + 6, str(int(val)), ha='center', va='bottom', label='Accumulated Tokens')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='ratelimit'></a>\n",
    "### üß™ Test the emit token metric with the configured subscriptions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from azure.ai.inference import ChatCompletionsClient\n",
    "from azure.ai.inference.models import SystemMessage, UserMessage\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "\n",
    "for i in range(10):\n",
    "    client = ChatCompletionsClient(\n",
    "        endpoint=f\"{apim_resource_gateway_url}/models\",\n",
    "        credential=AzureKeyCredential(random.choice(apim_subscriptions)['key']),\n",
    "    )\n",
    "    response = client.complete(\n",
    "        messages=[\n",
    "            SystemMessage(content=\"You are a sarcastic, unhelpful assistant.\"),\n",
    "            UserMessage(content=\"Can you tell me the time, please?\")\n",
    "        ],\n",
    "        max_tokens=2048,\n",
    "        model=models_config[0]['name']\n",
    "    )\n",
    "    print(\"‚ñ∂Ô∏è Run: \", i+1, \"üó®Ô∏è\\n\", response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='kql'></a>\n",
    "### üîç Analyze Application Insights custom metrics with a KQL query\n",
    "\n",
    "With this query you can get the custom metrics that were emitted by Azure APIM. Note that it may take a few minutes for data to become available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "query = \"\\\"\" + \"customMetrics \\\n",
    "| where name == 'Total Tokens' \\\n",
    "| where timestamp >= ago(1h) \\\n",
    "| extend parsedCustomDimensions = parse_json(customDimensions) \\\n",
    "| extend apimSubscription = tostring(parsedCustomDimensions.['Subscription ID']) \\\n",
    "| summarize TotalValue = sum(value) by apimSubscription, bin(timestamp, 1m) \\\n",
    "| order by timestamp asc\" + \"\\\"\"\n",
    "\n",
    "output = utils.run(f\"az monitor app-insights query --app {app_insights_name} -g {resource_group_name} --analytics-query {query}\",\n",
    "    f\"App Insights query succeeded\", f\"App Insights query  failed\")\n",
    "\n",
    "table = output.json_data['tables'][0]\n",
    "df = pd.DataFrame(table.get(\"rows\"), columns = [col.get(\"name\") for col in table.get('columns')])\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp']).dt.strftime('%H:%M')\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='plot'></a>\n",
    "### üîç Plot the custom metrics results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.figsize'] = [15, 7]\n",
    "if df.empty:\n",
    "    print(\"No data to plot\")\n",
    "else:\n",
    "    df_pivot = df.pivot(index='timestamp', columns='apimSubscription', values='TotalValue')\n",
    "    ax = df_pivot.plot(kind='bar', stacked=True)\n",
    "    plt.title('Total token usage over time by APIM Subscription')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Tokens')\n",
    "    plt.legend(title='APIM Subscription')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='portal'></a>\n",
    "### üîç See the metrics on the Azure Portal\n",
    "\n",
    "Open the Application Insights resource, navigate to the Metrics blade, then select the defined namespace (llm). Choose the metric \"Total Tokens\" with a Sum aggregation. Then, apply splitting by 'Subscription Id' to view values for each dimension.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='clean'></a>\n",
    "### üóëÔ∏è Clean up resources\n",
    "\n",
    "When you're finished with the lab, you should remove all your deployed resources from Azure to avoid extra charges and keep your Azure subscription uncluttered.\n",
    "Use the [clean-up-resources notebook](clean-up-resources.ipynb) for that."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
