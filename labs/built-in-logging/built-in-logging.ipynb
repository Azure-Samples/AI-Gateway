{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# APIM ‚ù§Ô∏è OpenAI\n",
    "\n",
    "## Built-in logging lab\n",
    "![flow](../../images/built-in-logging.gif)\n",
    "\n",
    "Playground to try the [built-in logging capabilities of API Management](https://learn.microsoft.com/azure/api-management/observability). The requests are logged into Application Insights, and it's easy to track request/response details and token usage with the provided [notebook](openai-usage-analysis-workbook.json).\n",
    "\n",
    "### TOC\n",
    "- [0Ô∏è‚É£ Initialize notebook variables](#0)\n",
    "- [1Ô∏è‚É£ Create the Azure Resource Group](#1)\n",
    "- [2Ô∏è‚É£ Create deployment using ü¶æ Bicep](#2)\n",
    "- [3Ô∏è‚É£ Get the deployment outputs](#3)\n",
    "- [üß™ Test the API using a direct HTTP call](#requests)\n",
    "- [üß™ Test the API using the Azure OpenAI Python SDK](#sdk)\n",
    "- [üîç Analyze Application Insights requests](#kql)\n",
    "- [üîç Open the workbook in the Azure Portal](#portal)\n",
    "- [üóëÔ∏è Clean up resources](#clean)\n",
    "\n",
    "### Backlog\n",
    "- Improve the notebook\n",
    "- Use the [trace policy](https://learn.microsoft.com/azure/api-management/trace-policy) to send aditional info within the policy\n",
    "- Add OpenAI diagnostics\n",
    "\n",
    "### Prerequisites\n",
    "- [Python 3.9 or later version](https://www.python.org/) installed\n",
    "- [Pandas Library](https://pandas.pydata.org/) installed\n",
    "- [VS Code](https://code.visualstudio.com/) installed with the [Jupyter notebook extension](https://marketplace.visualstudio.com/items?itemName=ms-toolsai.jupyter) enabled\n",
    "- [Azure CLI](https://learn.microsoft.com/cli/azure/install-azure-cli) installed\n",
    "- [An Azure Subscription](https://azure.microsoft.com/free/) with Contributor permissions\n",
    "- [Access granted to Azure OpenAI](https://aka.ms/oai/access) or just enable the mock service\n",
    "- [Sign in to Azure with Azure CLI](https://learn.microsoft.com/cli/azure/authenticate-azure-cli-interactively)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='0'></a>\n",
    "### 0Ô∏è‚É£ Initialize notebook variables\n",
    "\n",
    "- Resources will be suffixed by a unique string based on your subscription id.\n",
    "- Adjust the location parameters according your preferences and on the [product availability by Azure region.](https://azure.microsoft.com/explore/global-infrastructure/products-by-region/?cdn=disable&products=cognitive-services,api-management) \n",
    "- Adjust the OpenAI model and version according the [availability by region.](https://learn.microsoft.com/azure/ai-services/openai/concepts/models) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "deployment_name = os.path.basename(os.path.dirname(globals()['__vsc_ipynb_file__']))\n",
    "resource_group_name = f\"lab-{deployment_name}\" # change the name to match your naming style\n",
    "resource_group_location = \"westeurope\"\n",
    "\n",
    "openai_resources = [\n",
    "    {\"name\": \"openai1\", \"location\": \"swedencentral\"},\n",
    "    {\"name\": \"openai2\", \"location\": \"francecentral\"}\n",
    "]\n",
    "openai_model_name = \"gpt-35-turbo\"\n",
    "openai_model_version = \"0613\"\n",
    "openai_deployment_name = \"gpt-35-turbo\"\n",
    "openai_api_version = \"2024-02-01\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='1'></a>\n",
    "### 1Ô∏è‚É£ Create the Azure Resource Group\n",
    "All resources deployed in this lab will be created in the specified resource group. Skip this step if you want to use an existing resource group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ../../shared/snippets/create-az-resource-group.py\n",
    "# type: ignore\n",
    "\n",
    "import datetime\n",
    "\n",
    "resource_group_stdout = ! az group create --name {resource_group_name} --location {resource_group_location}\n",
    "\n",
    "if resource_group_stdout.n.startswith(\"ERROR\"):\n",
    "    print(resource_group_stdout)\n",
    "else:\n",
    "    print(f\"‚úÖ Azure Resource Group {resource_group_name} created ‚åö {datetime.datetime.now().time()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='2'></a>\n",
    "### 2Ô∏è‚É£ Create deployment using ü¶æ Bicep\n",
    "\n",
    "This lab uses [Bicep](https://learn.microsoft.com/azure/azure-resource-manager/bicep/overview?tabs=bicep) to declarative define all the resources that will be deployed. Change the parameters or the [main.bicep](main.bicep) directly to try different configurations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ../../shared/snippets/create-az-deployment.py\n",
    "# type: ignore\n",
    "\n",
    "import json\n",
    "\n",
    "backend_id = \"openai-backend-pool\" if len(openai_resources) > 1 else openai_resources[0].get(\"name\")\n",
    "\n",
    "with open(\"policy.xml\", 'r') as policy_xml_file:\n",
    "    policy_xml = policy_xml_file.read()\n",
    "\n",
    "    if \"{backend-id}\" in policy_xml:\n",
    "        policy_xml = policy_xml.replace(\"{backend-id}\", backend_id)\n",
    "\n",
    "    if \"{aad-client-application-id}\" in policy_xml:\n",
    "        policy_xml = policy_xml.replace(\"{aad-client-application-id}\", client_id)\n",
    "\n",
    "    if \"{aad-tenant-id}\" in policy_xml:\n",
    "        policy_xml = policy_xml.replace(\"{aad-tenant-id}\", tenant_id)\n",
    "\n",
    "    policy_xml_file.close()\n",
    "open(\"policy-updated.xml\", 'w').write(policy_xml)\n",
    "\n",
    "bicep_parameters = {\n",
    "    \"$schema\": \"https://schema.management.azure.com/schemas/2019-04-01/deploymentParameters.json#\",\n",
    "    \"contentVersion\": \"1.0.0.0\",\n",
    "    \"parameters\": {\n",
    "        \"openAIConfig\": { \"value\": openai_resources },\n",
    "        \"openAIDeploymentName\": { \"value\": openai_deployment_name },\n",
    "        \"openAIModelName\": { \"value\": openai_model_name },\n",
    "        \"openAIModelVersion\": { \"value\": openai_model_version },\n",
    "        \"openAIAPIVersion\": { \"value\": openai_api_version }\n",
    "    }\n",
    "}\n",
    "\n",
    "with open('params.json', 'w') as bicep_parameters_file:\n",
    "    bicep_parameters_file.write(json.dumps(bicep_parameters))\n",
    "\n",
    "! az deployment group create --name {deployment_name} --resource-group {resource_group_name} --template-file \"main.bicep\" --parameters \"params.json\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='3'></a>\n",
    "### 3Ô∏è‚É£ Get the deployment outputs\n",
    "\n",
    "We are now at the stage where we only need to retrieve the gateway URL and the subscription before we are ready for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ../../shared/snippets/deployment-outputs.py\n",
    "# type: ignore\n",
    "\n",
    "# Obtain all of the outputs from the deployment\n",
    "stdout = ! az deployment group show --name {deployment_name} -g {resource_group_name} --query properties.outputs -o json\n",
    "outputs = json.loads(stdout.n)\n",
    "\n",
    "# Extract the individual properties\n",
    "apim_service_id = outputs.get('apimServiceId', {}).get('value', '')\n",
    "apim_subscription_key = outputs.get('apimSubscriptionKey', {}).get('value', '')\n",
    "apim_subscription1_key = outputs.get('apimSubscription1Key', {}).get('value', '')\n",
    "apim_subscription2_key = outputs.get('apimSubscription2Key', {}).get('value', '')\n",
    "apim_subscription3_key = outputs.get('apimSubscription3Key', {}).get('value', '')\n",
    "apim_resource_gateway_url = outputs.get('apimResourceGatewayURL', {}).get('value', '')\n",
    "workspace_id = outputs.get('logAnalyticsWorkspaceId', {}).get('value', '')\n",
    "app_id = outputs.get('applicationInsightsAppId', {}).get('value', '')\n",
    "function_app_resource_name = outputs.get('functionAppResourceName', {}).get('value', '')\n",
    "cosmosdb_connection_string = outputs.get('cosmosDBConnectionString', {}).get('value', '')\n",
    "\n",
    "# Print the extracted properties if they are not empty\n",
    "if apim_service_id:\n",
    "    print(f\"üëâüèª APIM Service Id: {apim_service_id}\")\n",
    "\n",
    "if apim_subscription_key:\n",
    "    print(f\"üëâüèª APIM Subscription Key (masked): ****{apim_subscription_key[-4:]}\")\n",
    "\n",
    "if apim_subscription1_key:\n",
    "    print(f\"üëâüèª APIM Subscription Key 1 (masked): ****{apim_subscription1_key[-4:]}\")\n",
    "\n",
    "if apim_subscription2_key:\n",
    "    print(f\"üëâüèª APIM Subscription Key 2 (masked): ****{apim_subscription2_key[-4:]}\")\n",
    "\n",
    "if apim_subscription3_key:\n",
    "    print(f\"üëâüèª APIM Subscription Key 3 (masked): ****{apim_subscription3_key[-4:]}\")\n",
    "\n",
    "if apim_resource_gateway_url:\n",
    "    print(f\"üëâüèª APIM API Gateway URL: {apim_resource_gateway_url}\")\n",
    "\n",
    "if workspace_id:\n",
    "    print(f\"üëâüèª Workspace ID: {workspace_id}\")\n",
    "\n",
    "if app_id:\n",
    "    print(f\"üëâüèª App ID: {app_id}\")\n",
    "\n",
    "if function_app_resource_name:\n",
    "    print(f\"üëâüèª Function Name: {function_app_resource_name}\")\n",
    "\n",
    "if cosmosdb_connection_string:\n",
    "    print(f\"üëâüèª Cosmos DB Connection String: {cosmosdb_connection_string}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='requests'></a>\n",
    "### üß™ Test the API using a direct HTTP call\n",
    "Requests is an elegant and simple HTTP library for Python that will be used here to make raw API requests and inspect the responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ../../shared/snippets/api-http-requests.py\n",
    "import json\n",
    "import requests\n",
    "import time\n",
    "\n",
    "runs = 10\n",
    "sleep_time_ms = 100\n",
    "url = f\"{apim_resource_gateway_url}/openai/deployments/{openai_deployment_name}/chat/completions?api-version={openai_api_version}\"\n",
    "api_runs = []\n",
    "messages = {\"messages\": [\n",
    "    {\"role\": \"system\", \"content\": \"You are a sarcastic, unhelpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Can you tell me the time, please?\"}\n",
    "]}\n",
    "\n",
    "# Initialize a session for connection pooling\n",
    "session = requests.Session()\n",
    "# Set default headers\n",
    "session.headers.update({'api-key': apim_subscription_key})\n",
    "\n",
    "try:\n",
    "    for i in range(runs):\n",
    "        print(f\"‚ñ∂Ô∏è Run {i+1}/{runs}:\")\n",
    "\n",
    "        start_time = time.time()\n",
    "        response = session.post(url, json = messages)\n",
    "        response_time = time.time() - start_time\n",
    "        print(f\"‚åö {response_time:.2f} seconds\")\n",
    "\n",
    "        # Check the response status code and apply formatting\n",
    "        if 200 <= response.status_code < 300:\n",
    "            status_code_str = f\"\\x1b[1;32m{response.status_code} - {response.reason}\\x1b[0m\" # Bold and green\n",
    "        elif response.status_code >= 400:\n",
    "            status_code_str = f\"\\x1b[1;31m{response.status_code} - {response.reason}\\x1b[0m\" # Bold and red\n",
    "        else:\n",
    "            status_code_str = str(response.status_code)  # No formatting\n",
    "\n",
    "        # Print the response status with the appropriate formatting\n",
    "        print(f\"Response status: {status_code_str}\")\n",
    "        print(f\"Response headers: {json.dumps(dict(response.headers), indent = 4)}\")\n",
    "\n",
    "        if \"x-ms-region\" in response.headers:\n",
    "            print(f\"x-ms-region: \\x1b[1;32m{response.headers.get(\"x-ms-region\")}\\x1b[0m\") # this header is useful to determine the region of the backend that served the request\n",
    "            api_runs.append((response_time, response.headers.get(\"x-ms-region\")))\n",
    "\n",
    "        if (response.status_code == 200):\n",
    "            data = json.loads(response.text)\n",
    "            print(f\"Token usage: {json.dumps(dict(data.get(\"usage\")), indent = 4)}\\n\")\n",
    "            print(f\"üí¨ {data.get(\"choices\")[0].get(\"message\").get(\"content\")}\\n\")\n",
    "        else:\n",
    "            print(response.text)\n",
    "\n",
    "        time.sleep(sleep_time_ms/1000)\n",
    "finally:\n",
    "    # Close the session to release the connection\n",
    "    session.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='sdk'></a>\n",
    "### üß™ Test the API using the Azure OpenAI Python SDK\n",
    "OpenAPI provides a widely used [Python library](https://github.com/openai/openai-python). The library includes type definitions for all request params and response fields. The goal of this test is to assert that APIM can seamlessly proxy requests to OpenAI without disrupting its functionality.\n",
    "- Note: run ```pip install openai``` in a terminal before executing this step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ../../shared/snippets/openai-api-requests.py\n",
    "\n",
    "import time\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "runs = 10\n",
    "sleep_time_ms = 100\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    azure_endpoint = apim_resource_gateway_url,\n",
    "    api_key = apim_subscription_key,\n",
    "    api_version = openai_api_version\n",
    ")\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a sarcastic, unhelpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Can you tell me the time, please?\"}\n",
    "]\n",
    "\n",
    "for i in range(runs):\n",
    "    print(f\"‚ñ∂Ô∏è Run {i+1}/{runs}:\")\n",
    "\n",
    "    start_time = time.time()\n",
    "    response = client.chat.completions.create(model = openai_model_name, messages = messages) # type: ignore\n",
    "    response_time = time.time() - start_time\n",
    "    print(f\"‚åö {response_time:.2f} seconds\")\n",
    "    if response.usage:\n",
    "        print(f\"Token usage: Total tokens: {response.usage.total_tokens} (Prompt tokens: {response.usage.prompt_tokens} & Completion tokens: {response.usage.completion_tokens})\")\n",
    "    print(f\"üí¨ {response.choices[0].message.content}\\n\")\n",
    "\n",
    "    time.sleep(sleep_time_ms/1000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='kql'></a>\n",
    "### üîç Analyze Application Insights requests\n",
    "\n",
    "With this query you can get the request and response details including the prompt and the OpenAI completion. It also returns token counters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# type: ignore\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "query = \"\\\"\" + \"requests  \\\n",
    "| project timestamp, duration, customDimensions \\\n",
    "| extend duration = round(duration, 2) \\\n",
    "| extend parsedCustomDimensions = parse_json(customDimensions) \\\n",
    "| extend apiName = tostring(parsedCustomDimensions.['API Name']) \\\n",
    "| extend apimSubscription = tostring(parsedCustomDimensions.['Subscription Name']) \\\n",
    "| extend userAgent = tostring(parsedCustomDimensions.['Request-User-agent']) \\\n",
    "| extend request_json = tostring(parsedCustomDimensions.['Request-Body']) \\\n",
    "| extend request = parse_json(request_json) \\\n",
    "| extend model = tostring(request.['model']) \\\n",
    "| extend messages = tostring(request.['messages']) \\\n",
    "| extend region = tostring(parsedCustomDimensions.['Response-x-ms-region']) \\\n",
    "| extend remainingTokens = tostring(parsedCustomDimensions.['Response-x-ratelimit-remaining-tokens']) \\\n",
    "| extend remainingRequests = tostring(parsedCustomDimensions.['Response-x-ratelimit-remaining-requests']) \\\n",
    "| extend response_json = tostring(parsedCustomDimensions.['Response-Body']) \\\n",
    "| extend response = parse_json(response_json) \\\n",
    "| extend promptTokens = tostring(response.['usage'].['prompt_tokens']) \\\n",
    "| extend completionTokens = tostring(response.['usage'].['completion_tokens']) \\\n",
    "| extend totalTokens = tostring(response.['usage'].['total_tokens']) \\\n",
    "| extend completion = tostring(response.['choices'][0].['message'].['content']) \\\n",
    "| project timestamp, apiName, apimSubscription, duration, userAgent, model, messages, completion, region, promptTokens, completionTokens, totalTokens, remainingTokens, remainingRequests \\\n",
    "| order by timestamp desc\" + \"\\\"\"\n",
    "\n",
    "result_stdout = ! az monitor app-insights query --app {app_id} --analytics-query {query}\n",
    "result = json.loads(result_stdout.n)\n",
    "\n",
    "table = result.get('tables')[0]\n",
    "pd.DataFrame(table.get(\"rows\"), columns=[col.get(\"name\") for col in table.get('columns')])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='portal'></a>\n",
    "### üîç Open the workbook in the Azure Portal\n",
    "\n",
    "Go to the application insights resource and under the Monitoring section select the Workbooks blade. You should see the OpenAI Usage Analysis workbook with the above query and some others to check token counts, performance, failures, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='clean'></a>\n",
    "### üóëÔ∏è Clean up resources\n",
    "\n",
    "When you're finished with the lab, you should remove all your deployed resources from Azure to avoid extra charges and keep your Azure subscription uncluttered.\n",
    "Use the [clean-up-resources notebook](clean-up-resources.ipynb) for that."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
